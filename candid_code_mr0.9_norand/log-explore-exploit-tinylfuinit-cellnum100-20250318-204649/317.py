# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.

# Put tunable constant parameters below
LATENCY_WEIGHT = 0.4
FREQUENCY_WEIGHT = 0.3
SYNC_STATUS_WEIGHT = 0.2
LOAD_BALANCE_WEIGHT = 0.1

# Put the metadata specifically maintained by the policy below. The policy maintains metadata including access frequency, last access time, data synchronization status, and load distribution metrics across cache nodes.
access_frequency = {}
last_access_time = {}
sync_status = {}
load_distribution = {}

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy chooses the eviction victim based on a weighted score combining low access frequency, high access latency, outdated synchronization status, and load balancing needs to ensure even distribution across nodes.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    min_score = float('inf')
    
    for key, cached_obj in cache_snapshot.cache.items():
        latency = cache_snapshot.access_count - last_access_time[key]
        frequency = access_frequency[key]
        sync = sync_status[key]
        load = load_distribution[key]
        
        score = (LATENCY_WEIGHT * latency) - (FREQUENCY_WEIGHT * frequency) + (SYNC_STATUS_WEIGHT * (not sync)) + (LOAD_BALANCE_WEIGHT * load)
        
        if score < min_score:
            min_score = score
            candid_obj_key = key
    
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    After a cache hit, the policy updates the access frequency by incrementing it, refreshes the last access time to the current time, and checks the synchronization status to ensure data consistency.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    key = obj.key
    access_frequency[key] += 1
    last_access_time[key] = cache_snapshot.access_count
    sync_status[key] = True  # Assuming the sync status is checked and updated to True

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the policy initializes the access frequency to one, sets the last access time to the current time, marks the synchronization status as up-to-date, and updates load distribution metrics to reflect the new object.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    key = obj.key
    access_frequency[key] = 1
    last_access_time[key] = cache_snapshot.access_count
    sync_status[key] = True
    load_distribution[key] = 1  # Assuming initial load distribution metric is set to 1

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    After evicting a victim, the policy removes the metadata associated with the evicted object, recalculates load distribution metrics to maintain balance, and ensures that the synchronization status of remaining objects is still valid.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    evicted_key = evicted_obj.key
    del access_frequency[evicted_key]
    del last_access_time[evicted_key]
    del sync_status[evicted_key]
    del load_distribution[evicted_key]
    
    # Recalculate load distribution metrics
    total_load = sum(load_distribution.values())
    for key in load_distribution:
        load_distribution[key] = load_distribution[key] / total_load