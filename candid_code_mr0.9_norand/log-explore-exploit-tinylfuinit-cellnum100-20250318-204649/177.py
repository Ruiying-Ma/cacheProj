# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
from collections import deque, defaultdict

# Put tunable constant parameters below
NUM_LRU_QUEUES = 3
GHOST_QUEUE_SIZE = 100

# Put the metadata specifically maintained by the policy below. The policy maintains multiple LRU queues with recency timestamps, two FIFO ghost queues, access frequency, last access time, replication status, load balancing metrics, cache hit rate, and storage capacity utilization for each cache entry.
lru_queues = [deque() for _ in range(NUM_LRU_QUEUES)]
ghost_queues = [deque(), deque()]
access_frequency = defaultdict(int)
last_access_time = defaultdict(int)
replication_status = defaultdict(bool)
load_balancing_metrics = defaultdict(float)
cache_hit_rate = 0.0
storage_capacity_utilization = 0.0

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    During eviction, if the first LRU queue is not empty, the object at its least-recently-used end is evicted. Otherwise, the object at the least-recently-used end of the non-empty LRU queue with the smallest subscript is evicted. The eviction victim is chosen based on a weighted score combining least frequently accessed, oldest access time, replication status, load balancing needs, and storage capacity utilization.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    # Your code below
    if lru_queues[0]:
        candid_obj_key = lru_queues[0].pop()
    else:
        for queue in lru_queues:
            if queue:
                candid_obj_key = queue.pop()
                break
    
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    Immediately after a hit, set the hit object's recency as current timestamp. If it is in an LRU queue, move it to the most-recently-used end of the next higher subscript queue. If the hit object is in a ghost queue, move it to the most-recently-used end of the highest subscript LRU queue. Increment the access frequency counter, update the last access timestamp, adjust load balancing metrics, and recalculate the cache hit rate.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    # Your code below
    current_time = cache_snapshot.access_count
    obj_key = obj.key
    
    # Update recency timestamp
    last_access_time[obj_key] = current_time
    
    # Move object in LRU queues
    for i in range(NUM_LRU_QUEUES):
        if obj_key in lru_queues[i]:
            lru_queues[i].remove(obj_key)
            if i < NUM_LRU_QUEUES - 1:
                lru_queues[i + 1].appendleft(obj_key)
            else:
                lru_queues[i].appendleft(obj_key)
            break
    
    # Move object from ghost queues to highest LRU queue
    for ghost_queue in ghost_queues:
        if obj_key in ghost_queue:
            ghost_queue.remove(obj_key)
            lru_queues[-1].appendleft(obj_key)
            break
    
    # Increment access frequency counter
    access_frequency[obj_key] += 1
    
    # Adjust load balancing metrics
    load_balancing_metrics[obj_key] = calculate_load_balancing_metric(obj_key)
    
    # Recalculate cache hit rate
    cache_hit_rate = cache_snapshot.hit_count / cache_snapshot.access_count

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    Immediately after insertion, set the inserted object's recency as current timestamp. If it used to be in a ghost queue, put it at the most-recently-used end of the highest subscript LRU queue. Otherwise, put it at the most-recently-used end of the first LRU queue. Initialize the access frequency counter, last access timestamp, replication status, and load balancing metrics. Update storage capacity utilization and recalculate the cache hit rate.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    # Your code below
    current_time = cache_snapshot.access_count
    obj_key = obj.key
    
    # Update recency timestamp
    last_access_time[obj_key] = current_time
    
    # Move object from ghost queues to highest LRU queue
    for ghost_queue in ghost_queues:
        if obj_key in ghost_queue:
            ghost_queue.remove(obj_key)
            lru_queues[-1].appendleft(obj_key)
            break
    else:
        lru_queues[0].appendleft(obj_key)
    
    # Initialize access frequency counter
    access_frequency[obj_key] = 1
    
    # Initialize replication status
    replication_status[obj_key] = False
    
    # Initialize load balancing metrics
    load_balancing_metrics[obj_key] = calculate_load_balancing_metric(obj_key)
    
    # Update storage capacity utilization
    storage_capacity_utilization = cache_snapshot.size / cache_snapshot.capacity
    
    # Recalculate cache hit rate
    cache_hit_rate = cache_snapshot.hit_count / cache_snapshot.access_count

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    Immediately after eviction, remove the evicted object from the queue it resides in and move it to the rear of the first ghost queue if it was from the first LRU queue, or to the rear of the second ghost queue if it was from any other LRU queue. Remove redundant objects from the front of the ghost queues if full. Remove the metadata associated with the evicted entry, recalculate load balancing metrics, adjust storage capacity utilization, and recalculate the cache hit rate.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    # Your code below
    evicted_key = evicted_obj.key
    
    # Remove evicted object from LRU queues
    for queue in lru_queues:
        if evicted_key in queue:
            queue.remove(evicted_key)
            break
    
    # Move evicted object to ghost queue
    if evicted_key in lru_queues[0]:
        ghost_queues[0].append(evicted_key)
    else:
        ghost_queues[1].append(evicted_key)
    
    # Remove redundant objects from ghost queues if full
    for ghost_queue in ghost_queues:
        while len(ghost_queue) > GHOST_QUEUE_SIZE:
            ghost_queue.popleft()
    
    # Remove metadata associated with evicted entry
    del access_frequency[evicted_key]
    del last_access_time[evicted_key]
    del replication_status[evicted_key]
    del load_balancing_metrics[evicted_key]
    
    # Recalculate load balancing metrics
    for key in load_balancing_metrics:
        load_balancing_metrics[key] = calculate_load_balancing_metric(key)
    
    # Adjust storage capacity utilization
    storage_capacity_utilization = cache_snapshot.size / cache_snapshot.capacity
    
    # Recalculate cache hit rate
    cache_hit_rate = cache_snapshot.hit_count / cache_snapshot.access_count

def calculate_load_balancing_metric(obj_key):
    # Placeholder function to calculate load balancing metric
    return 0.0