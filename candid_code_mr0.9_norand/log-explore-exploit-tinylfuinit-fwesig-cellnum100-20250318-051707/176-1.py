# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
from collections import defaultdict, deque
from heapq import heappush, heappop
import time

# Put tunable constant parameters below

# Put the metadata specifically maintained by the policy below. The policy maintains access frequency, recency of access, memory allocation size, coherence status, disk scheduling priorities, LRU queue position, last access time, write status, data locality score, latency impact score, and a circular pointer for traversal.

class CachePolicy:
    def __init__(self):
        self.access_frequency = defaultdict(int)
        self.recency_of_access = {}
        self.memory_allocation_size = {}
        self.coherence_status = {}
        self.disk_scheduling_priority = {}
        self.lru_queue = deque()
        self.last_access_time = {}
        self.write_status = {}
        self.data_locality_score = {}
        self.latency_impact_score = {}
        self.pointer = 0

    def evict(self, cache_snapshot, obj):
        '''
        This function defines how the policy chooses the eviction victim.
        The policy uses the circular pointer to traverse the cache and calculates a composite score for each entry based on access frequency, recency of access, memory allocation size, coherence status, disk scheduling priorities, last access time, write status, data locality score, and latency impact score. It evicts the entry with the lowest composite score, preferring clean entries and considering disk scheduling priorities.
        - Args:
            - `cache_snapshot`: A snapshot of the current cache state.
            - `obj`: The new object that needs to be inserted into the cache.
        - Return:
            - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
        '''
        candid_obj_key = None
        lowest_score = float('inf')

        for i in range(len(self.lru_queue)):
            candidate_key = self.lru_queue[(self.pointer + i) % len(self.lru_queue)]
            candidate_obj = cache_snapshot.cache[candidate_key]
            score = (self.access_frequency[candidate_key] +
                     self.recency_of_access[candidate_key] +
                     self.memory_allocation_size[candidate_key] +
                     self.coherence_status[candidate_key] +
                     self.disk_scheduling_priority[candidate_key] +
                     self.last_access_time[candidate_key] +
                     self.write_status[candidate_key] +
                     self.data_locality_score[candidate_key] +
                     self.latency_impact_score[candidate_key])

            if score < lowest_score and self.write_status[candidate_key] == "clean":
                lowest_score = score
                candid_obj_key = candidate_key

        return candid_obj_key

    def update_after_hit(self, cache_snapshot, obj):
        '''
        This function defines how the policy update the metadata it maintains immediately after a cache hit.
        Immediately after a hit, the policy increments the access frequency, updates the recency of access and last access time to the current time, recalculates the data locality score and latency impact score, updates the coherence status if necessary, adjusts disk scheduling priorities, moves the hit object to the most-recently-used end of the LRU queue, and keeps the pointer at its current position.
        - Args:
            - `cache_snapshot`: A snapshot of the current cache state.
            - `obj`: The object accessed during the cache hit.
        - Return: `None`
        '''
        self.access_frequency[obj.key] += 1
        self.recency_of_access[obj.key] = cache_snapshot.access_count
        self.last_access_time[obj.key] = cache_snapshot.access_count
        self.calculate_scores(obj)
        self.lru_queue.remove(obj.key)
        self.lru_queue.append(obj.key)

    def update_after_insert(self, cache_snapshot, obj):
        '''
        This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
        Immediately after inserting a new object, the policy initializes the access frequency to 1, sets the recency of access and last access time to the current time, sets the initial memory allocation size and coherence status, marks the write status as clean, calculates initial data locality and latency impact scores, assigns a disk scheduling priority based on expected usage patterns, places the object at the current pointer location without moving the pointer, and moves the object to the most-recently-used end of the LRU queue.
        - Args:
            - `cache_snapshot`: A snapshot of the current cache state.
            - `obj`: The object that was just inserted into the cache.
        - Return: `None`
        '''
        self.access_frequency[obj.key] = 1
        self.recency_of_access[obj.key] = cache_snapshot.access_count
        self.memory_allocation_size[obj.key] = obj.size
        self.coherence_status[obj.key] = self.default_coherence_status(obj)
        self.disk_scheduling_priority[obj.key] = self.default_disk_scheduling_priority(obj)
        self.last_access_time[obj.key] = cache_snapshot.access_count
        self.write_status[obj.key] = "clean"
        self.calculate_scores(obj)
        self.lru_queue.insert(self.pointer, obj.key)
        self.lru_queue.append(obj.key)

    def update_after_evict(self, cache_snapshot, obj, evicted_obj):
        '''
        This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
        Immediately after evicting a victim, the policy removes all associated metadata for the evicted entry, adjusts the data locality and latency impact scores of remaining entries if influenced, updates disk scheduling priorities for remaining objects, removes the evicted object from the LRU queue, and keeps the pointer at its current position.
        - Args:
            - `cache_snapshot`: A snapshot of the current cache state.
            - `obj`: The object to be inserted into the cache.
            - `evicted_obj`: The object that was just evicted from the cache.
        - Return: `None`
        '''
        del self.access_frequency[evicted_obj.key]
        del self.recency_of_access[evicted_obj.key]
        del self.memory_allocation_size[evicted_obj.key]
        del self.coherence_status[evicted_obj.key]
        del self.disk_scheduling_priority[evicted_obj.key]
        del self.last_access_time[evicted_obj.key]
        del self.write_status[evicted_obj.key]
        del self.data_locality_score[evicted_obj.key]
        del self.latency_impact_score[evicted_obj.key]
        self.lru_queue.remove(evicted_obj.key)

    def calculate_scores(self, obj):
        self.data_locality_score[obj.key] = self.calculate_data_locality_score(obj)
        self.latency_impact_score[obj.key] = self.calculate_latency_impact_score(obj)

    def default_coherence_status(self, obj):
        # Implement default coherence status logic
        return 0

    def default_disk_scheduling_priority(self, obj):
        # Implement default disk scheduling priority logic
        return 0

    def calculate_data_locality_score(self, obj):
        # Implement data locality score calculation
        return 0

    def calculate_latency_impact_score(self, obj):
        # Implement latency impact score calculation
        return 0