# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
import time

# Put tunable constant parameters below
FETCH_COST_DECREASE = 0.9
LATENCY_IMPACT_BASE = 1.0

# Put the metadata specifically maintained by the policy below. The policy maintains access frequency, last access timestamp, fetch cost score, write-back status, latency impact score, replication factor, load distribution, and queue position (FIFO or LRU).
metadata = {
    'access_frequency': {},
    'last_access_timestamp': {},
    'fetch_cost_score': {},
    'write_back_status': {},
    'latency_impact_score': {},
    'replication_factor': {},
    'load_distribution': {},
    'queue_position': {}
}

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy first checks the FIFO queue for an object with zero frequency and evicts it. If no such object is found, it calculates a composite weighted score based on low access frequency, oldest timestamp, high fetch cost, high latency impact, and low replication factor, ensuring balanced load across cache nodes, and evicts the object with the lowest score.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    # Check FIFO queue for an object with zero frequency
    for key, cached_obj in cache_snapshot.cache.items():
        if metadata['access_frequency'][key] == 0:
            candid_obj_key = key
            break
    
    if candid_obj_key is None:
        # Calculate composite weighted score for eviction
        min_score = float('inf')
        for key, cached_obj in cache_snapshot.cache.items():
            score = (
                metadata['access_frequency'][key] * 0.2 +
                (cache_snapshot.access_count - metadata['last_access_timestamp'][key]) * 0.2 +
                metadata['fetch_cost_score'][key] * 0.2 +
                metadata['latency_impact_score'][key] * 0.2 +
                metadata['replication_factor'][key] * 0.2
            )
            if score < min_score:
                min_score = score
                candid_obj_key = key
    
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    After a cache hit, the policy increments the access frequency, updates the last access timestamp to the current time, slightly decreases the fetch cost score, recalculates the latency impact score based on recent access patterns, adjusts the load distribution metadata, and moves the object to the most-recently-used end of the next higher LRU queue.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    key = obj.key
    metadata['access_frequency'][key] += 1
    metadata['last_access_timestamp'][key] = cache_snapshot.access_count
    metadata['fetch_cost_score'][key] *= FETCH_COST_DECREASE
    metadata['latency_impact_score'][key] = LATENCY_IMPACT_BASE / metadata['access_frequency'][key]
    # Adjust load distribution and move to higher LRU queue (not implemented in detail)
    metadata['queue_position'][key] = 'LRU'

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the policy initializes the access frequency to 1, sets the last access timestamp to the current time, calculates the fetch cost score, marks the write-back status as clean, assigns an initial latency impact score, assigns an initial replication factor, updates the load distribution, and places the object at the most-recently-used end of L1.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    key = obj.key
    metadata['access_frequency'][key] = 1
    metadata['last_access_timestamp'][key] = cache_snapshot.access_count
    metadata['fetch_cost_score'][key] = obj.size
    metadata['write_back_status'][key] = 'clean'
    metadata['latency_impact_score'][key] = LATENCY_IMPACT_BASE
    metadata['replication_factor'][key] = 1
    metadata['load_distribution'][key] = 1
    metadata['queue_position'][key] = 'L1'

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    After evicting the victim, the policy removes all associated metadata for the evicted entry, adjusts the latency impact scores of remaining entries, recalculates the load distribution to ensure balance, adjusts the replication factors of remaining objects, and moves objects behind the evicted object in the FIFO queue one step forward to fill the vacancy.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    evicted_key = evicted_obj.key
    # Remove all associated metadata for the evicted entry
    del metadata['access_frequency'][evicted_key]
    del metadata['last_access_timestamp'][evicted_key]
    del metadata['fetch_cost_score'][evicted_key]
    del metadata['write_back_status'][evicted_key]
    del metadata['latency_impact_score'][evicted_key]
    del metadata['replication_factor'][evicted_key]
    del metadata['load_distribution'][evicted_key]
    del metadata['queue_position'][evicted_key]
    
    # Adjust latency impact scores and replication factors of remaining entries
    for key in cache_snapshot.cache.keys():
        metadata['latency_impact_score'][key] = LATENCY_IMPACT_BASE / metadata['access_frequency'][key]
        metadata['replication_factor'][key] = 1  # Simplified adjustment
    
    # Recalculate load distribution to ensure balance (not implemented in detail)
    # Move objects behind the evicted object in the FIFO queue one step forward to fill the vacancy (not implemented in detail)