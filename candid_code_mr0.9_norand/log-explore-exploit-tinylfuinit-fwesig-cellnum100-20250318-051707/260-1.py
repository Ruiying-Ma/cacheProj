# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.

from collections import defaultdict

# Put tunable constant parameters below
WEIGHT_ACCESS_FREQUENCY = 1.0
WEIGHT_TIMESTAMP = 1.0
WEIGHT_REPLICATION_FACTOR = 1.0
WEIGHT_CPU_UTILIZATION = 1.0
WEIGHT_MEMORY_USAGE = 1.0
WEIGHT_CACHE_COHERENCE = 1.0
WEIGHT_DISK_IO_SPEED = 1.0

# Put the metadata specifically maintained by the policy below. The policy maintains access frequency, last access timestamp, replication factor, load distribution, CPU utilization, memory usage, cache coherence status, disk I/O speed, and a composite score combining these factors.
metadata = {
    'access_frequency': defaultdict(int),
    'last_access_timestamp': defaultdict(int),
    'replication_factor': defaultdict(int),
    'cpu_utilization': defaultdict(float),
    'memory_usage': defaultdict(int),
    'cache_coherence': defaultdict(float),
    'disk_io_speed': defaultdict(float),
    'composite_score': defaultdict(float)
}

def calculate_composite_score(key):
    af = metadata['access_frequency'][key]
    ts = metadata['last_access_timestamp'][key]
    rf = metadata['replication_factor'][key]
    cu = metadata['cpu_utilization'][key]
    mu = metadata['memory_usage'][key]
    cc = metadata['cache_coherence'][key]
    dio = metadata['disk_io_speed'][key]

    return (WEIGHT_ACCESS_FREQUENCY * af -
            WEIGHT_TIMESTAMP * ts +
            WEIGHT_REPLICATION_FACTOR * rf -
            WEIGHT_CPU_UTILIZATION * cu +
            WEIGHT_MEMORY_USAGE * mu -
            WEIGHT_CACHE_COHERENCE * cc -
            WEIGHT_DISK_IO_SPEED * dio)

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy chooses the eviction victim based on a combined weighted score that considers low access frequency, oldest access timestamp, lowest replication factor, low CPU utilization, high memory usage, poor cache coherence, and slow disk I/O speed.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    min_score = float('inf')
    candid_obj_key = None

    for key in cache_snapshot.cache:
        composite_score = calculate_composite_score(key)
        if composite_score < min_score:
            min_score = composite_score
            candid_obj_key = key
    
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    After a cache hit, the policy increments the access frequency, updates the last access timestamp, adjusts the load distribution, updates CPU utilization and memory usage, recalculates the composite score, and adjusts the eviction priority list.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    key = obj.key
    metadata['access_frequency'][key] += 1
    metadata['last_access_timestamp'][key] = cache_snapshot.access_count
    metadata['cpu_utilization'][key] *= 1.05  # Example adjustment, actual logic may differ
    metadata['memory_usage'][key] *= 0.95    # Example adjustment, actual logic may differ
    metadata['composite_score'][key] = calculate_composite_score(key)

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the policy initializes access frequency, sets the current timestamp as the last access time, assigns an initial replication factor, updates load distribution, initializes CPU utilization, memory usage, cache coherence status, and disk I/O speed, calculates the initial composite score, and places the object in the eviction priority list.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    key = obj.key
    metadata['access_frequency'][key] = 1
    metadata['last_access_timestamp'][key] = cache_snapshot.access_count
    metadata['replication_factor'][key] = 1
    metadata['cpu_utilization'][key] = 0.5  # Example initial value
    metadata['memory_usage'][key] = obj.size
    metadata['cache_coherence'][key] = 1.0  # Example initial value
    metadata['disk_io_speed'][key] = 1.0  # Example initial value
    metadata['composite_score'][key] = calculate_composite_score(key)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    After evicting a victim, the policy removes the object's metadata, recalculates load distribution, adjusts replication factors of remaining objects, recalculates composite scores for remaining entries if necessary, and updates the eviction priority list.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    evicted_key = evicted_obj.key
    
    # Remove the evicted object's metadata
    del metadata['access_frequency'][evicted_key]
    del metadata['last_access_timestamp'][evicted_key]
    del metadata['replication_factor'][evicted_key]
    del metadata['cpu_utilization'][evicted_key]
    del metadata['memory_usage'][evicted_key]
    del metadata['cache_coherence'][evicted_key]
    del metadata['disk_io_speed'][evicted_key]
    del metadata['composite_score'][evicted_key]
    
    # Recalculate load distribution, update replication factors and composite scores
    for key in cache_snapshot.cache:
        metadata['replication_factor'][key] *= 0.95  # Example adjustment
        metadata['composite_score'][key] = calculate_composite_score(key)