# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
from collections import defaultdict

# Put tunable constant parameters below
HIT_INCREMENT = 1
INITIAL_LATENCY_IMPACT_SCORE = 10
REPLACEMENT_SCORE_WEIGHT_RESIDENCY = 0.2
REPLACEMENT_SCORE_WEIGHT_FREQUENCY = 0.3
REPLACEMENT_SCORE_WEIGHT_TIMESTAMP = 0.2
REPLACEMENT_SCORE_WEIGHT_LATENCY = 0.3

# Put the metadata specifically maintained by the policy below. The policy maintains hit ratio, cache residency time, access frequency, last access timestamp, write-back status, latency impact score, and replacement score for each cache line.
cache_metadata = defaultdict(lambda: {
    'hit_ratio': 0,
    'residency_time': 0,
    'access_frequency': 0,
    'last_access_timestamp': 0,
    'write_back_status': 'clean',
    'latency_impact_score': 0,
    'replacement_score': 0,
})

def calculate_replacement_score(metadata, current_time):
    hit_ratio = metadata['hit_ratio']
    residency_time = current_time - metadata['residency_time']
    access_frequency = metadata['access_frequency']
    timestamp = current_time - metadata['last_access_timestamp']
    latency_impact_score = metadata['latency_impact_score']
    
    replacement_score = (
        REPLACEMENT_SCORE_WEIGHT_RESIDENCY * residency_time +
        REPLACEMENT_SCORE_WEIGHT_FREQUENCY * access_frequency +
        REPLACEMENT_SCORE_WEIGHT_TIMESTAMP * timestamp +
        REPLACEMENT_SCORE_WEIGHT_LATENCY * latency_impact_score
    )
    
    return replacement_score

def evict(cache_snapshot, obj):
    candid_obj_key = None
    lowest_replacement_score = float('inf')
    
    for key, cached_obj in cache_snapshot.cache.items():
        metadata = cache_metadata[key]
        replacement_score = calculate_replacement_score(metadata, cache_snapshot.access_count)
        
        if replacement_score < lowest_replacement_score:
            lowest_replacement_score = replacement_score
            candid_obj_key = key
    
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    metadata = cache_metadata[obj.key]
    metadata['hit_ratio'] += HIT_INCREMENT / (cache_snapshot.hit_count + 1)
    metadata['residency_time'] = cache_snapshot.access_count
    metadata['access_frequency'] += 1
    metadata['last_access_timestamp'] = cache_snapshot.access_count
    metadata['latency_impact_score'] = metadata['access_frequency'] / (cache_snapshot.access_count + 1)
    metadata['replacement_score'] = calculate_replacement_score(metadata, cache_snapshot.access_count)

def update_after_insert(cache_snapshot, obj):
    metadata = cache_metadata[obj.key]
    metadata['hit_ratio'] = 0
    metadata['residency_time'] = cache_snapshot.access_count
    metadata['access_frequency'] = 1
    metadata['last_access_timestamp'] = cache_snapshot.access_count
    metadata['write_back_status'] = 'clean'
    metadata['latency_impact_score'] = INITIAL_LATENCY_IMPACT_SCORE
    metadata['replacement_score'] = calculate_replacement_score(metadata, cache_snapshot.access_count)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    del cache_metadata[evicted_obj.key]
    
    for key, cached_obj in cache_snapshot.cache.items():
        metadata = cache_metadata[key]
        metadata['latency_impact_score'] = calculate_replacement_score(metadata, cache_snapshot.access_count)
        metadata['replacement_score'] = calculate_replacement_score(metadata, cache_snapshot.access_count)