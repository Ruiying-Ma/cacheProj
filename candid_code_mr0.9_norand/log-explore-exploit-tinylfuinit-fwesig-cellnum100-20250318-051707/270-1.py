# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
from collections import deque, defaultdict
import time

# Put tunable constant parameters below
DEFAULT_FETCH_COST = 1
DEFAULT_DATA_LOCALITY = 1
DEFAULT_LOAD_BALANCE = 1

# Put the metadata specifically maintained by the policy below. The policy maintains latency measurement, last access time, insertion time, load balancing score, global cache hit rate, dynamic threshold for data retention period, access frequency, write status, data locality score, fetch cost score, queue position, and uses a Hash Map, Binary Tree, Linked List, and Array for cache management.
metadata = {
    'latency_measurement': {},
    'last_access_time': {},
    'insertion_time': {},
    'load_balancing_score': {},
    'global_cache_hit_rate': 0,
    'dynamic_threshold': time.time(),
    'access_frequency': defaultdict(int),
    'write_status': {},
    'data_locality_score': {},
    'fetch_cost_score': {},
    'queue_position': deque(),
    'hash_map': {},
    'binary_tree': {},
    'linked_list': [],
    'cache_array': []
}

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy first checks the FIFO queue for an object with zero frequency and evicts it. If no such object is found, it identifies entries with the highest latency measurements and lowest load balancing scores, then calculates a combined score based on low access frequency, low recency of access, high fetch cost, and low data locality score, evicting the object with the lowest score.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    # Check FIFO queue for any object with zero frequency
    for key in metadata['queue_position']:
        if metadata['access_frequency'][key] == 0:
            candid_obj_key = key
            break

    if candid_obj_key is None:
        # Identify entry with the highest latency measurements and lowest load balancing scores
        min_score = float('inf')
        for key, obj in cache_snapshot.cache.items():
            score = (
                -metadata['access_frequency'][key] +
                (cache_snapshot.access_count - metadata['last_access_time'][key]) +
                metadata['fetch_cost_score'][key] -
                metadata['data_locality_score'][key]
            )
            if score < min_score:
                min_score = score
                candid_obj_key = key

    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    Upon a cache hit, the policy updates the last access time to the current time, increments the access frequency in the Binary Tree, recalculates the load balancing score, updates the data locality score, slightly decreases the fetch cost score, moves the accessed item to the front of the Linked List, and updates the global cache hit rate.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    key = obj.key
    current_time = cache_snapshot.access_count
    metadata['last_access_time'][key] = current_time
    metadata['access_frequency'][key] += 1
    metadata['load_balancing_score'][key] += 1
    metadata['data_locality_score'][key] += 1
    metadata['fetch_cost_score'][key] -= 1
    metadata['linked_list'].remove(key)
    metadata['linked_list'].insert(0, key)
    metadata['global_cache_hit_rate'] = cache_snapshot.hit_count / cache_snapshot.access_count

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the policy sets the initial latency measurement, insertion time, and last access time to the current time, initializes the load balancing score, access frequency to 1, marks the write status as clean, calculates an initial data locality score and fetch cost score, adjusts the dynamic threshold for data retention period, adds the object to the Hash Map, Binary Tree, Linked List, and Array, and places it at the most-recently-used end of L1.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    key = obj.key
    current_time = cache_snapshot.access_count
    metadata['latency_measurement'][key] = 0
    metadata['insertion_time'][key] = current_time
    metadata['last_access_time'][key] = current_time
    metadata['load_balancing_score'][key] = DEFAULT_LOAD_BALANCE
    metadata['access_frequency'][key] = 1
    metadata['write_status'][key] = 'clean'
    metadata['data_locality_score'][key] = DEFAULT_DATA_LOCALITY
    metadata['fetch_cost_score'][key] = DEFAULT_FETCH_COST
    metadata['dynamic_threshold'] = time.time()
    metadata['hash_map'][key] = obj
    metadata['binary_tree'][key] = obj
    metadata['linked_list'].insert(0, key)
    metadata['cache_array'].append(key)
    metadata['queue_position'].append(key)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    Following an eviction, the policy recalculates the global cache hit rate, adjusts the dynamic threshold for data retention period, updates the load balancing scores and data locality scores of remaining entries, removes all associated metadata for the evicted entry, deletes the object from the Hash Map, Binary Tree, Linked List, and Array, and adjusts the remaining cache lines' metadata to maintain relative rankings for eviction decisions.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    key = evicted_obj.key
    del metadata['latency_measurement'][key]
    del metadata['last_access_time'][key]
    del metadata['insertion_time'][key]
    del metadata['load_balancing_score'][key]
    del metadata['access_frequency'][key]
    del metadata['write_status'][key]
    del metadata['data_locality_score'][key]
    del metadata['fetch_cost_score'][key]
    del metadata['hash_map'][key]
    del metadata['binary_tree'][key]
    metadata['linked_list'].remove(key)
    metadata['cache_array'].remove(key)
    metadata['queue_position'].remove(key)
    metadata['global_cache_hit_rate'] = cache_snapshot.hit_count / cache_snapshot.access_count
    metadata['dynamic_threshold'] = time.time()

# Implement the deterministic cache replacement policy using the code provided above.