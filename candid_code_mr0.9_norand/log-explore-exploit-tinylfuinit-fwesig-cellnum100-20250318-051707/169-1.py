# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.

# Put tunable constant parameters below
DEFAULT_EXPIRATION_TIME = 1000  # Some default expiration time
DEFAULT_WRITE_AMP_COUNT = 1     # Default write amplification count
DEFAULT_LATENCY_IMPACT = 0.1    # Some default latency impact score

# Put the metadata specifically maintained by the policy below. The policy maintains metadata for each cache entry including usage frequency, last access time, expiration time, data freshness score, access frequency, recency of access, write amplification count, and latency impact score.
metadata = {}

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy chooses the eviction victim by first checking for any expired entries. If none are found, it selects the entry with the lowest composite score derived from data freshness score, access frequency, recency, write amplification count, and latency impact score.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    # Your code below
    # First, check for any expired entries
    min_composite_score = float('inf')
    current_time = cache_snapshot.access_count

    for key, cache_obj in cache_snapshot.cache.items():
        obj_metadata = metadata[key]
        if obj_metadata['expiration_time'] <= current_time:
            return key

        # Calculate composite score
        composite_score = (
            1 / (1 + obj_metadata['data_freshness_score']) +
            obj_metadata['access_frequency'] +
            current_time - obj_metadata['recency'] +
            obj_metadata['write_amplification_count'] +
            obj_metadata['latency_impact_score']
        )

        if composite_score < min_composite_score:
            min_composite_score = composite_score
            candid_obj_key = key
    
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    Upon a cache hit, the policy updates the last access time to the current time, increments the usage frequency and access frequency, refreshes the recency timestamp, recalculates the data freshness score based on the new access time and usage pattern, and recalculates the latency impact score based on the current hit latency.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    # Your code below
    current_time = cache_snapshot.access_count
    key = obj.key
    if key in metadata:
        obj_metadata = metadata[key]
        obj_metadata['last_access_time'] = current_time
        obj_metadata['usage_frequency'] += 1
        obj_metadata['access_frequency'] += 1
        obj_metadata['recency'] = current_time
        obj_metadata['data_freshness_score'] = 1 / (1 + obj_metadata['usage_frequency'])
        obj_metadata['latency_impact_score'] = obj_metadata['latency_impact_score'] * 0.9  # Mock update

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the policy sets the initial usage frequency and access frequency to 1, the last access time and recency timestamp to the current time, assigns an expiration time based on the data type, calculates the initial data freshness score, assigns a default write amplification count, and calculates an initial latency impact score based on expected hit latency.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    # Your code below
    current_time = cache_snapshot.access_count
    metadata[obj.key] = {
        'usage_frequency': 1,
        'access_frequency': 1,
        'last_access_time': current_time,
        'recency': current_time,
        'expiration_time': current_time + DEFAULT_EXPIRATION_TIME,
        'data_freshness_score': 1.0,
        'write_amplification_count': DEFAULT_WRITE_AMP_COUNT,
        'latency_impact_score': DEFAULT_LATENCY_IMPACT,
    }

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    After evicting an entry, the policy logs the eviction event for usage pattern analysis, removes all associated metadata for the evicted object, adjusts the overall cache usage statistics, recalculates the data freshness scores for the remaining entries if necessary, and adjusts the write amplification count for remaining objects to reflect the reduced cache size.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    # Your code below
    evicted_key = evicted_obj.key
    if evicted_key in metadata:
        del metadata[evicted_key]

    # Update write amplification count for the remaining objects
    for key in cache_snapshot.cache.keys():
        obj_metadata = metadata[key]
        obj_metadata['write_amplification_count'] = max(1, obj_metadata['write_amplification_count'] - 1)

    # Recalculate data freshness scores if necessary
    for key in cache_snapshot.cache.keys():
        obj_metadata = metadata[key]
        obj_metadata['data_freshness_score'] = 1 / (1 + obj_metadata['usage_frequency'])