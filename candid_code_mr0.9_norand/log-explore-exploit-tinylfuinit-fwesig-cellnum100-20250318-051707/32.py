# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.

# Put tunable constant parameters below
LATENCY_WEIGHT = 1.0
LOAD_BALANCE_WEIGHT = 1.0
DATA_LOCALITY_WEIGHT = 1.0

# Put the metadata specifically maintained by the policy below. The policy maintains latency measurement, last access time, insertion time, load balancing score, global cache hit rate, dynamic threshold for data retention period, access frequency, write status, and data locality score for each cache entry.
metadata = {
    'latency': {},
    'last_access_time': {},
    'insertion_time': {},
    'load_balance_score': {},
    'access_frequency': {},
    'write_status': {},
    'data_locality_score': {},
    'global_cache_hit_rate': 0.0,
    'dynamic_threshold': 0.0
}

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy chooses the eviction victim by first identifying entries with the highest latency measurements and lowest load balancing scores. Among these, it selects the entry with the oldest insertion time and lowest data locality score, with a preference for clean entries to minimize write-backs.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    max_latency = -1
    min_load_balance = float('inf')
    oldest_insertion_time = float('inf')
    min_data_locality = float('inf')
    
    for key, cached_obj in cache_snapshot.cache.items():
        latency = metadata['latency'][key]
        load_balance = metadata['load_balance_score'][key]
        insertion_time = metadata['insertion_time'][key]
        data_locality = metadata['data_locality_score'][key]
        write_status = metadata['write_status'][key]
        
        if (latency > max_latency or
            (latency == max_latency and load_balance < min_load_balance) or
            (latency == max_latency and load_balance == min_load_balance and insertion_time < oldest_insertion_time) or
            (latency == max_latency and load_balance == min_load_balance and insertion_time == oldest_insertion_time and data_locality < min_data_locality) or
            (latency == max_latency and load_balance == min_load_balance and insertion_time == oldest_insertion_time and data_locality == min_data_locality and write_status == 'clean')):
            
            max_latency = latency
            min_load_balance = load_balance
            oldest_insertion_time = insertion_time
            min_data_locality = data_locality
            candid_obj_key = key
    
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    Upon a cache hit, the policy updates the last access time to the current time, increments the access frequency, recalculates the load balancing score based on frequency of access and latency measurement, and updates the data locality score based on the access pattern. The global cache hit rate is also updated.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    key = obj.key
    current_time = cache_snapshot.access_count
    
    metadata['last_access_time'][key] = current_time
    metadata['access_frequency'][key] += 1
    metadata['load_balance_score'][key] = (metadata['access_frequency'][key] / (current_time - metadata['insertion_time'][key] + 1)) * LATENCY_WEIGHT
    metadata['data_locality_score'][key] = (metadata['access_frequency'][key] / (current_time - metadata['last_access_time'][key] + 1)) * DATA_LOCALITY_WEIGHT
    
    metadata['global_cache_hit_rate'] = cache_snapshot.hit_count / (cache_snapshot.hit_count + cache_snapshot.miss_count)

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the policy sets the initial latency measurement, insertion time, and last access time to the current time, initializes the load balancing score, access frequency to 1, marks the write status as clean, calculates an initial data locality score, and adjusts the dynamic threshold for data retention period based on the current cache hit rate.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    key = obj.key
    current_time = cache_snapshot.access_count
    
    metadata['latency'][key] = 0  # Initial latency measurement
    metadata['insertion_time'][key] = current_time
    metadata['last_access_time'][key] = current_time
    metadata['load_balance_score'][key] = 0  # Initial load balancing score
    metadata['access_frequency'][key] = 1
    metadata['write_status'][key] = 'clean'
    metadata['data_locality_score'][key] = 0  # Initial data locality score
    
    metadata['global_cache_hit_rate'] = cache_snapshot.hit_count / (cache_snapshot.hit_count + cache_snapshot.miss_count)
    metadata['dynamic_threshold'] = metadata['global_cache_hit_rate'] * 100  # Example adjustment

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    Following an eviction, the policy recalculates the global cache hit rate, adjusts the dynamic threshold for data retention period, updates the load balancing scores and data locality scores of remaining entries, and removes all associated metadata for the evicted entry.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    evicted_key = evicted_obj.key
    
    # Remove metadata for the evicted entry
    del metadata['latency'][evicted_key]
    del metadata['last_access_time'][evicted_key]
    del metadata['insertion_time'][evicted_key]
    del metadata['load_balance_score'][evicted_key]
    del metadata['access_frequency'][evicted_key]
    del metadata['write_status'][evicted_key]
    del metadata['data_locality_score'][evicted_key]
    
    # Recalculate global cache hit rate
    metadata['global_cache_hit_rate'] = cache_snapshot.hit_count / (cache_snapshot.hit_count + cache_snapshot.miss_count)
    
    # Adjust dynamic threshold for data retention period
    metadata['dynamic_threshold'] = metadata['global_cache_hit_rate'] * 100  # Example adjustment
    
    # Update load balancing scores and data locality scores of remaining entries
    current_time = cache_snapshot.access_count
    for key in cache_snapshot.cache:
        metadata['load_balance_score'][key] = (metadata['access_frequency'][key] / (current_time - metadata['insertion_time'][key] + 1)) * LATENCY_WEIGHT
        metadata['data_locality_score'][key] = (metadata['access_frequency'][key] / (current_time - metadata['last_access_time'][key] + 1)) * DATA_LOCALITY_WEIGHT