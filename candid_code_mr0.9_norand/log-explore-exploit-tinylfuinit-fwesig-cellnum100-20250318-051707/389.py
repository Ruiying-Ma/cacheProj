# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
import time

# Put tunable constant parameters below
FETCH_COST_DECREASE = 0.1
INITIAL_FETCH_COST = 10
INITIAL_LATENCY_IMPACT = 5

# Put the metadata specifically maintained by the policy below. The policy maintains access frequency, last access timestamp, fetch cost score, write-back status, latency impact score, data source, and a blockchain ledger for tracking data integrity and access history.
metadata = {
    'access_frequency': {},
    'last_access_timestamp': {},
    'fetch_cost_score': {},
    'write_back_status': {},
    'latency_impact_score': {},
    'data_source': {},
    'blockchain_ledger': [],
    'pointer': 0
}

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy uses a circular pointer to traverse the cache and calculates a composite score for each entry based on access frequency, last access timestamp, fetch cost score, write-back necessity, latency impact, and data source priority, with a preference for evicting cloud-sourced data over edge-sourced data. It evicts the entry with the lowest composite score.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    min_score = float('inf')
    
    keys = list(cache_snapshot.cache.keys())
    n = len(keys)
    
    for i in range(n):
        key = keys[(metadata['pointer'] + i) % n]
        composite_score = (
            metadata['access_frequency'][key] * 0.2 +
            (cache_snapshot.access_count - metadata['last_access_timestamp'][key]) * 0.2 +
            metadata['fetch_cost_score'][key] * 0.2 +
            (1 if metadata['write_back_status'][key] == 'dirty' else 0) * 0.2 +
            metadata['latency_impact_score'][key] * 0.1 +
            (1 if metadata['data_source'][key] == 'cloud' else 0) * 0.1
        )
        
        if composite_score < min_score:
            min_score = composite_score
            candid_obj_key = key
    
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    After a cache hit, the policy increments the access frequency, updates the last access timestamp to the current time, slightly decreases the fetch cost score, recalculates the latency impact score based on recent access patterns, keeps the pointer at its current position, and appends an entry to the blockchain ledger recording the access event.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    key = obj.key
    metadata['access_frequency'][key] += 1
    metadata['last_access_timestamp'][key] = cache_snapshot.access_count
    metadata['fetch_cost_score'][key] -= FETCH_COST_DECREASE
    metadata['latency_impact_score'][key] = metadata['access_frequency'][key] * 0.5
    metadata['blockchain_ledger'].append({
        'event': 'hit',
        'key': key,
        'timestamp': cache_snapshot.access_count
    })

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the policy initializes the access frequency to 1, sets the last access timestamp to the current time, calculates the fetch cost score based on the estimated miss penalty, marks the write-back status as clean, assigns an initial latency impact score based on expected access latency, records the data source, places the object at the current pointer location without moving the pointer, and appends an entry to the blockchain ledger recording the insertion event.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    key = obj.key
    metadata['access_frequency'][key] = 1
    metadata['last_access_timestamp'][key] = cache_snapshot.access_count
    metadata['fetch_cost_score'][key] = INITIAL_FETCH_COST
    metadata['write_back_status'][key] = 'clean'
    metadata['latency_impact_score'][key] = INITIAL_LATENCY_IMPACT
    metadata['data_source'][key] = 'cloud'  # Assuming cloud as default data source
    metadata['blockchain_ledger'].append({
        'event': 'insert',
        'key': key,
        'timestamp': cache_snapshot.access_count
    })

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    After evicting the victim, the policy removes all associated metadata for the evicted entry, adjusts the latency impact scores of remaining entries to reflect the change in cache composition, keeps the pointer at its current position, and appends an entry to the blockchain ledger recording the eviction event.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    key = evicted_obj.key
    del metadata['access_frequency'][key]
    del metadata['last_access_timestamp'][key]
    del metadata['fetch_cost_score'][key]
    del metadata['write_back_status'][key]
    del metadata['latency_impact_score'][key]
    del metadata['data_source'][key]
    metadata['blockchain_ledger'].append({
        'event': 'evict',
        'key': key,
        'timestamp': cache_snapshot.access_count
    })
    
    # Adjust latency impact scores of remaining entries
    for remaining_key in cache_snapshot.cache.keys():
        metadata['latency_impact_score'][remaining_key] = metadata['access_frequency'][remaining_key] * 0.5