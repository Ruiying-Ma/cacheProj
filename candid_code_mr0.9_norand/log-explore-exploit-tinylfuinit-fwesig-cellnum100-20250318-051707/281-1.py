# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
import collections

# Put tunable constant parameters below
LATENCY_DECAY = 0.95
EFFICIENCY_INCREASE = 1.1
EFFICIENCY_DECAY = 0.9

# Put the metadata specifically maintained by the policy below. The policy maintains metadata including data redundancy levels, access latency records, parallel processing efficiency scores, and network topology awareness.
latency_records = {}
efficiency_scores = {}
network_topology = {}
data_redundancy = {}

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy chooses the eviction victim based on a combination of lowest redundancy, highest latency, least parallel processing efficiency, and least critical position in the network topology.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    min_score = float('inf')
    
    for key, cached_obj in cache_snapshot.cache.items():
        redundancy = data_redundancy.get(key, 1)
        latency = latency_records.get(key, float('inf'))
        efficiency = efficiency_scores.get(key, 1)
        topology_criticality = network_topology.get(key, 1)
        
        score = (redundancy) + (latency) - (efficiency) + (topology_criticality)
        if score < min_score:
            min_score = score
            candid_obj_key = key
            
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    After a cache hit, the policy updates the access latency records to reflect the improved latency, increases the parallel processing efficiency score, and adjusts the network topology awareness to prioritize frequently accessed nodes.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    key = obj.key
    
    # Update latency
    latency_records[key] = latency_records.get(key, 0) * LATENCY_DECAY
    
    # Increase efficiency score
    efficiency_scores[key] = efficiency_scores.get(key, 1) * EFFICIENCY_INCREASE
    
    # Boost network topology criticality score
    network_topology[key] = network_topology.get(key, 1) - 1

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the policy updates the data redundancy levels to ensure optimal redundancy, recalculates access latency records, updates parallel processing efficiency scores, and integrates the new object into the network topology awareness.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    
    key = obj.key
    
    # Set initial redundancy
    data_redundancy[key] = 1
    
    # Recalculate initial latency records
    latency_records[key] = cache_snapshot.access_count
    
    # Initialize efficiency scores
    efficiency_scores[key] = 1.0
    
    # Integrate into network topology awareness
    network_topology[key] = 0

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    After evicting a victim, the policy recalculates data redundancy levels to maintain balance, updates access latency records to reflect the removal, adjusts parallel processing efficiency scores, and reconfigures network topology awareness to optimize remaining cache objects.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    evicted_key = evicted_obj.key
    
    # Remove metadata of the evicted object
    if evicted_key in data_redundancy:
        del data_redundancy[evicted_key]
    
    if evicted_key in latency_records:
        del latency_records[evicted_key]
    
    if evicted_key in efficiency_scores:
        del efficiency_scores[evicted_key]
    
    if evicted_key in network_topology:
        del network_topology[evicted_key]

    # Update existing object metadata to maintain balance
    for key in cache_snapshot.cache.keys():
        latency_records[key] = latency_records[key] * LATENCY_DECAY
        efficiency_scores[key] = efficiency_scores[key] * EFFICIENCY_DECAY
        network_topology[key] = network_topology[key] + 1