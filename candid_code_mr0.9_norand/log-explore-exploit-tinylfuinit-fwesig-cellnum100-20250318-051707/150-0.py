# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.

from collections import defaultdict

# Put tunable constant parameters below
FETCH_COST_DECAY = 0.95
LATENCY_IMPACT_DECAY = 0.9

# Put the metadata specifically maintained by the policy below. The policy maintains access frequency, last access timestamp, fetch cost score, write-back status, latency impact score, and a circular pointer for each cache entry.
access_frequency = defaultdict(int)
last_access_timestamp = defaultdict(int)
fetch_cost_score = defaultdict(lambda: 100)
write_back_status = defaultdict(lambda: False)
latency_impact_score = defaultdict(lambda: 100)
circular_pointer = 0

# Track the list of keys to maintain the circular pointer logic
cache_keys = []

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy uses the circular pointer to traverse the cache and calculates a composite score for each entry based on access frequency, last access timestamp, fetch cost score, write-back necessity, and latency impact. It evicts the entry with the lowest composite score.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    global circular_pointer, cache_keys
    cache = cache_snapshot.cache

    def composite_score(key):
        # Calculate composite score based on maintained metadata
        return (
            access_frequency[key] * -1
            + last_access_timestamp[key] * -1
            + fetch_cost_score[key]
            + (1 if write_back_status[key] else 0)
            + latency_impact_score[key]
        )

    lowest_score = float('inf')
    candid_obj_key = None

    # Traverse the cache circularly to find the object with the lowest score
    for _ in range(len(cache)):
        key = cache_keys[circular_pointer]
        score = composite_score(key)
        if score < lowest_score:
            lowest_score = score
            candid_obj_key = key
        
        circular_pointer = (circular_pointer + 1) % len(cache_keys)

    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    After a cache hit, the policy increments the access frequency, updates the last access timestamp to the current time, slightly decreases the fetch cost score, recalculates the latency impact score based on recent access patterns, and keeps the pointer at its current position.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    key = obj.key
    access_frequency[key] += 1
    last_access_timestamp[key] = cache_snapshot.access_count
    fetch_cost_score[key] *= FETCH_COST_DECAY
    latency_impact_score[key] = cache_snapshot.access_count - last_access_timestamp[key]

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the policy initializes the access frequency to 1, sets the last access timestamp to the current time, calculates the fetch cost score based on the estimated miss penalty, marks the write-back status as clean, assigns an initial latency impact score based on expected access latency, and places the object at the current pointer location without moving the pointer.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    global cache_keys
    key = obj.key
    access_frequency[key] = 1
    last_access_timestamp[key] = cache_snapshot.access_count
    fetch_cost_score[key] = 100  # Example fetch cost score
    write_back_status[key] = False
    latency_impact_score[key] = 100  # Example latency impact score
    cache_keys.append(key)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    After evicting the victim, the policy removes all associated metadata for the evicted entry, adjusts the latency impact scores of remaining entries to reflect the change in cache composition, and keeps the pointer at its current position.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    global cache_keys
    key = evicted_obj.key
    # Remove metadata of the evicted object
    del access_frequency[key]
    del last_access_timestamp[key]
    del fetch_cost_score[key]
    del write_back_status[key]
    del latency_impact_score[key]
    
    # Update cache key list and circular pointer
    cache_keys.remove(key)
    
    # Adjust latency impact scores of the remaining entries
    for k in cache_keys:
        latency_impact_score[k] *= LATENCY_IMPACT_DECAY