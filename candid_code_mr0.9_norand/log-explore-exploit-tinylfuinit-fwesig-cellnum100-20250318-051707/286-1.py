# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
import math

# Put tunable constant parameters below
default_write_amplification = 1
default_latency_impact = 1

# Put the metadata specifically maintained by the policy below. The policy maintains access frequency, recency of access, write amplification count, latency impact score, temporal access patterns, and synthetic data profiles generated using GANs for each cached object.
metadata = {
    'access_frequency': {},    # Key -> Access frequency
    'recency_access': {},      # Key -> Recency timestamp
    'write_amplification': {}, # Key -> Write amplification count
    'latency_impact': {},      # Key -> Latency impact score
    'temporal_patterns': {},   # Key -> Temporal access patterns
    'synthetic_data_profiles': {}, # Key -> Synthetic data profiles
}

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy chooses the eviction victim based on a composite score derived from access frequency, recency, write amplification count, latency impact score, and predicted future access patterns using GANs, prioritizing objects with low access frequency, high write amplification, minimal latency impact, and least likelihood of being accessed soon.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    lowest_composite_score = math.inf

    for key in cache_snapshot.cache:
        # Calculate composite score
        composite_score = (
            metadata['access_frequency'][key] * 0.2 +
            (cache_snapshot.access_count - metadata['recency_access'][key]) * 0.3 +
            metadata['write_amplification'][key] * 0.2 +
            metadata['latency_impact'][key] * 0.2 +
            metadata['synthetic_data_profiles'][key] * 0.1
        )
        if composite_score < lowest_composite_score:
            lowest_composite_score = composite_score
            candid_obj_key = key

    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    After a cache hit, the policy increments the access frequency, refreshes the recency timestamp, recalculates the latency impact score based on current hit latency, updates temporal access patterns, and refines the synthetic data profile using the latest access information.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    key = obj.key

    # Increment access frequency
    metadata['access_frequency'][key] += 1

    # Refresh recency timestamp
    metadata['recency_access'][key] = cache_snapshot.access_count

    # Recalculate latency impact score (keeping it simple here)
    metadata['latency_impact'][key] = 1.0 / metadata['access_frequency'][key]

    # Update temporal access patterns
    metadata['temporal_patterns'][key] = (metadata['temporal_patterns'][key] + 1) / 2

    # Refine the synthetic data profile
    metadata['synthetic_data_profiles'][key] = predict_future_access_probability(key)

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the policy initializes access frequency to 1, sets the recency timestamp to the current time, assigns a default write amplification count, calculates an initial latency impact score based on expected hit latency, initializes temporal access patterns, and generates an initial synthetic data profile using GANs based on similar objects' access patterns.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    key = obj.key

    # Initialize access frequency to 1
    metadata['access_frequency'][key] = 1

    # Set recency timestamp to the current time
    metadata['recency_access'][key] = cache_snapshot.access_count

    # Assign a default write amplification count
    metadata['write_amplification'][key] = default_write_amplification

    # Calculate an initial latency impact score based on expected hit latency
    metadata['latency_impact'][key] = default_latency_impact

    # Initialize temporal access patterns
    metadata['temporal_patterns'][key] = 0

    # Generate an initial synthetic data profile using GANs based on similar objects' access patterns
    metadata['synthetic_data_profiles'][key] = generate_initial_profile(obj)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    After evicting an object, the policy removes all associated metadata for the evicted object, adjusts the write amplification count for remaining objects to reflect the reduced cache size, recalibrates the synthetic data profiles of remaining objects to ensure accurate future access predictions, and adjusts overall access frequency trends.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    evicted_key = evicted_obj.key

    # Remove all associated metadata for the evicted object
    del metadata['access_frequency'][evicted_key]
    del metadata['recency_access'][evicted_key]
    del metadata['write_amplification'][evicted_key]
    del metadata['latency_impact'][evicted_key]
    del metadata['temporal_patterns'][evicted_key]
    del metadata['synthetic_data_profiles'][evicted_key]

    # Adjust the write amplification count for remaining objects to reflect the reduced cache size
    for key in cache_snapshot.cache:
        if key != evicted_key:
            metadata['write_amplification'][key] *= 0.9  # example adjustment factor

    # Recalibrate the synthetic data profiles
    for key in cache_snapshot.cache:
        metadata['synthetic_data_profiles'][key] = predict_future_access_probability(key)

    # Adjust overall access frequency trends, if needed
    # This part is optional based on detailed policy requirements

def generate_initial_profile(obj):
    # Placeholder for generating initial synthetic data profile based on GANs
    # As GANs functionality is not detailed, using a placeholder value
    return 0.5

def predict_future_access_probability(key):
    # Placeholder for predicting future access probability using GANs
    # As GANs functionality is not detailed, using a placeholder value
    return 0.5