# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.

# Put tunable constant parameters below
FAULT_ISOLATION_THRESHOLD = 5
RESILIENCY_SCORE_MIN = 0.5
FREQUENCY_THRESHOLD = 3
DISK_ACCESS_LIMIT = 10

# Put the metadata specifically maintained by the policy below. The policy maintains a hash table for data deduplication, a fault isolation counter, a resiliency score, a backup timestamp, a hash map for frequency of access and last access timestamp, and a counter for total disk accesses.
hash_table = set()
fault_isolation_counter = 0
resiliency_score = 1.0
backup_timestamp = 0
frequency_map = {}
last_access_timestamp = {}
disk_access_counter = 0

def admit(cache_snapshot, obj, key_to_be_evicted):
    '''
    This function defines how the policy determines whether an object should be admitted into the cache.
    The policy admits an object if it is not a duplicate, has a fault isolation counter below a threshold, a resiliency score above a minimum value, and either its frequency of access exceeds a threshold or the total number of disk accesses since the last admission exceeds a predefined limit.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object being requested.
        - `key_to_be_evicted`: The key of the object in the cache that may be evicted if the currently requested object is admitted and triggers an eviction. If no admission occurs or if admission does not cause an eviction, this is set to `None`.
    - Return:
        - `should_admit`: A boolean value indicating whether the requested object should be admitted into the cache. If `True`, the object is admitted; if `False`, it is not.
    '''
    global fault_isolation_counter, resiliency_score, disk_access_counter

    # Check if the object is a duplicate
    if obj.key in hash_table:
        return False

    # Check fault isolation counter
    if fault_isolation_counter >= FAULT_ISOLATION_THRESHOLD:
        return False

    # Check resiliency score
    if resiliency_score < RESILIENCY_SCORE_MIN:
        return False

    # Check frequency of access
    frequency = frequency_map.get(obj.key, 0)
    if frequency >= FREQUENCY_THRESHOLD:
        return True

    # Check disk access counter
    if disk_access_counter >= DISK_ACCESS_LIMIT:
        return True

    return False

def update_after_admit(cache_snapshot, obj):
    '''
    This function defines how the policy update **each** of the metadata it maintains immediately after it decides to admit an object into the cache.
    Upon admitting an object, the policy updates the hash table with the object's hash, resets the fault isolation counter, calculates and stores the resiliency score, sets the backup timestamp to the current time, sets the frequency of access to 1, updates the last access timestamp to the current time, and resets the disk access counter to zero.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just admitted into the cache.
    - Return: `None`
    '''
    global hash_table, fault_isolation_counter, resiliency_score, backup_timestamp, frequency_map, last_access_timestamp, disk_access_counter

    hash_table.add(obj.key)
    fault_isolation_counter = 0
    resiliency_score = 1.0  # Assuming a fixed resiliency score for simplicity
    backup_timestamp = cache_snapshot.access_count
    frequency_map[obj.key] = 1
    last_access_timestamp[obj.key] = cache_snapshot.access_count
    disk_access_counter = 0

def update_after_not_admit(cache_snapshot, obj):
    '''
    This function defines how the policy updates **each** of the metadata it maintains immediately after it decides **not** to admit an object into the cache.
    If an object is not admitted, the policy increments the fault isolation counter, slightly decreases the resiliency score, increments the disk access counter by one, and updates the hash map to increment the frequency of access for the data block identifier if it exists.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just denied admission to the cache.
    - Return: `None`
    '''
    global fault_isolation_counter, resiliency_score, disk_access_counter, frequency_map

    fault_isolation_counter += 1
    resiliency_score = max(0, resiliency_score - 0.1)  # Decrease resiliency score slightly
    disk_access_counter += 1
    if obj.key in frequency_map:
        frequency_map[obj.key] += 1
    else:
        frequency_map[obj.key] = 1

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy updates **each** of the metadata it maintains immediately after a cache hit.
    Upon a cache hit, the policy resets the fault isolation counter, increases the resiliency score, updates the backup timestamp to the current time, increments the frequency of access for the data block identifier, and updates the last access timestamp to the current time.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    global fault_isolation_counter, resiliency_score, backup_timestamp, frequency_map, last_access_timestamp

    fault_isolation_counter = 0
    resiliency_score = min(1.0, resiliency_score + 0.1)  # Increase resiliency score slightly
    backup_timestamp = cache_snapshot.access_count
    if obj.key in frequency_map:
        frequency_map[obj.key] += 1
    else:
        frequency_map[obj.key] = 1
    last_access_timestamp[obj.key] = cache_snapshot.access_count