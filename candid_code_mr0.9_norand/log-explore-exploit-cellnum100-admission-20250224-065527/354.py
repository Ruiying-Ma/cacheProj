# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.

# Put tunable constant parameters below
ACCESS_FREQUENCY_THRESHOLD = 5
SIZE_THRESHOLD = 1024  # 1 KB
PROCESSING_TIME_THRESHOLD = 10  # Arbitrary units

# Put the metadata specifically maintained by the policy below. The policy maintains metadata including access frequency, data size, and processing time for each object. It also keeps track of the current load on parallel processing units and memory usage statistics.
metadata = {
    'access_frequency': {},  # {obj.key: frequency}
    'data_size': {},  # {obj.key: size}
    'processing_time': {},  # {obj.key: processing_time}
    'parallel_processing_load': 0,  # Total load on parallel processing units
    'memory_usage': 0  # Current memory usage
}

def admit(cache_snapshot, obj, key_to_be_evicted):
    '''
    This function defines how the policy determines whether an object should be admitted into the cache.
    The policy admits an object into the cache if it has a high access frequency, a small data size, and a low processing time. Additionally, it considers the current load on parallel processing units and memory usage to ensure optimal performance and latency reduction.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object being requested.
        - `key_to_be_evicted`: The key of the object in the cache that may be evicted if the currently requested object is admitted and triggers an eviction. If no admission occurs or if admission does not cause an eviction, this is set to `None`.
    - Return:
        - `should_admit`: A boolean value indicating whether the requested object should be admitted into the cache. If `True`, the object is admitted; if `False`, it is not.
    '''
    should_admit = False
    
    # Check if the object meets the admission criteria
    access_frequency = metadata['access_frequency'].get(obj.key, 0)
    processing_time = metadata['processing_time'].get(obj.key, 0)
    
    if (access_frequency >= ACCESS_FREQUENCY_THRESHOLD and
        obj.size <= SIZE_THRESHOLD and
        processing_time <= PROCESSING_TIME_THRESHOLD):
        
        # Check if there is enough space in the cache
        if cache_snapshot.size + obj.size <= cache_snapshot.capacity:
            should_admit = True
        elif key_to_be_evicted is not None:
            # Check if evicting the object will make enough space
            evicted_obj_size = cache_snapshot.cache[key_to_be_evicted].size
            if cache_snapshot.size - evicted_obj_size + obj.size <= cache_snapshot.capacity:
                should_admit = True
    
    return should_admit

def update_after_admit(cache_snapshot, obj):
    '''
    This function defines how the policy update **each** of the metadata it maintains immediately after it decides to admit an object into the cache.
    Upon admitting an object, the policy updates the access frequency, data size, and processing time for the object. It also updates the load statistics of the parallel processing units and the memory usage to reflect the new state.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just admitted into the cache.
    - Return: `None`
    '''
    # Update access frequency
    metadata['access_frequency'][obj.key] = metadata['access_frequency'].get(obj.key, 0) + 1
    
    # Update data size
    metadata['data_size'][obj.key] = obj.size
    
    # Update processing time (assuming some arbitrary processing time for the example)
    metadata['processing_time'][obj.key] = metadata['processing_time'].get(obj.key, 0) + 1
    
    # Update memory usage
    metadata['memory_usage'] = cache_snapshot.size + obj.size
    
    # Update parallel processing load (assuming some arbitrary load for the example)
    metadata['parallel_processing_load'] += 1

def update_after_not_admit(cache_snapshot, obj):
    '''
    This function defines how the policy updates **each** of the metadata it maintains immediately after it decides **not** to admit an object into the cache.
    If an object is not admitted, the policy updates the access frequency and processing time metadata to reflect the decision. It also adjusts the load statistics of the parallel processing units and memory usage to ensure accurate tracking.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just denied admission to the cache.
    - Return: `None`
    '''
    # Update access frequency
    metadata['access_frequency'][obj.key] = metadata['access_frequency'].get(obj.key, 0) + 1
    
    # Update processing time (assuming some arbitrary processing time for the example)
    metadata['processing_time'][obj.key] = metadata['processing_time'].get(obj.key, 0) + 1
    
    # Update parallel processing load (assuming some arbitrary load for the example)
    metadata['parallel_processing_load'] += 1

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy updates **each** of the metadata it maintains immediately after a cache hit.
    After a cache hit, the policy increments the access frequency for the object and updates its processing time. It also recalculates the load on parallel processing units and memory usage to maintain optimal performance and latency reduction.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    # Update access frequency
    metadata['access_frequency'][obj.key] = metadata['access_frequency'].get(obj.key, 0) + 1
    
    # Update processing time (assuming some arbitrary processing time for the example)
    metadata['processing_time'][obj.key] = metadata['processing_time'].get(obj.key, 0) + 1
    
    # Recalculate memory usage
    metadata['memory_usage'] = cache_snapshot.size
    
    # Recalculate parallel processing load (assuming some arbitrary load for the example)
    metadata['parallel_processing_load'] += 1