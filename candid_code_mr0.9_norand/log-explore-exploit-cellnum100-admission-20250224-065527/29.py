# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.

# Put tunable constant parameters below
LOAD_THRESHOLD = 0.75
LATENCY_IMPROVEMENT_THRESHOLD = 0.1

# Put the metadata specifically maintained by the policy below. The policy maintains metadata for load threshold, data shards, latency metrics, and throughput statistics. Each shard has its own load and latency metrics.
shard_loads = {}
shard_latencies = {}
shard_throughputs = {}

def get_shard(obj):
    # This function determines the shard for a given object.
    # For simplicity, we assume each object belongs to a single shard based on its key.
    return obj.key[0]  # Example: shard based on the first character of the key

def admit(cache_snapshot, obj, key_to_be_evicted):
    '''
    This function defines how the policy determines whether an object should be admitted into the cache.
    The policy admits an object if the load on the corresponding shard is below the load threshold and the expected latency improvement is significant. Throughput analysis is used to prioritize high-throughput shards.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object being requested.
        - `key_to_be_evicted`: The key of the object in the cache that may be evicted if the currently requested object is admitted and triggers an eviction. If no admission occurs or if admission does not cause an eviction, this is set to `None`.
    - Return:
        - `should_admit`: A boolean value indicating whether the requested object should be admitted into the cache. If `True`, the object is admitted; if `False`, it is not.
    '''
    shard = get_shard(obj)
    current_load = shard_loads.get(shard, 0)
    current_latency = shard_latencies.get(shard, 1)
    current_throughput = shard_throughputs.get(shard, 1)

    # Calculate the new load if the object is admitted
    new_load = current_load + obj.size / cache_snapshot.capacity

    # Check if the load is below the threshold
    if new_load > LOAD_THRESHOLD:
        return False

    # Calculate the expected latency improvement
    expected_latency_improvement = (current_latency - (current_latency * 0.9)) / current_latency

    # Check if the expected latency improvement is significant
    if expected_latency_improvement < LATENCY_IMPROVEMENT_THRESHOLD:
        return False

    # Prioritize high-throughput shards
    if current_throughput < 1:
        return False

    return True

def update_after_admit(cache_snapshot, obj):
    '''
    This function defines how the policy update **each** of the metadata it maintains immediately after it decides to admit an object into the cache.
    After admitting an object, the load and latency metrics for the corresponding shard are updated to reflect the new state. Throughput statistics are recalculated to ensure optimal performance.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just admitted into the cache.
    - Return: `None`
    '''
    shard = get_shard(obj)
    shard_loads[shard] = shard_loads.get(shard, 0) + obj.size / cache_snapshot.capacity
    shard_latencies[shard] = shard_latencies.get(shard, 1) * 0.9  # Example: latency improves by 10%
    shard_throughputs[shard] = shard_throughputs.get(shard, 1) + 1  # Example: throughput increases

def update_after_not_admit(cache_snapshot, obj):
    '''
    This function defines how the policy updates **each** of the metadata it maintains immediately after it decides **not** to admit an object into the cache.
    If an object is not admitted, the load and latency metrics for the corresponding shard are slightly adjusted to account for the missed opportunity. Throughput statistics are also updated to reflect the decision.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just denied admission to the cache.
    - Return: `None`
    '''
    shard = get_shard(obj)
    shard_latencies[shard] = shard_latencies.get(shard, 1) * 1.01  # Example: latency worsens by 1%
    shard_throughputs[shard] = shard_throughputs.get(shard, 1) - 0.1  # Example: throughput decreases slightly

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy updates **each** of the metadata it maintains immediately after a cache hit.
    Upon a cache hit, the latency metrics for the corresponding shard are updated to reflect the improved performance. The load metrics are adjusted to account for the accessed object, and throughput statistics are recalculated.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    shard = get_shard(obj)
    shard_latencies[shard] = shard_latencies.get(shard, 1) * 0.95  # Example: latency improves by 5%
    shard_throughputs[shard] = shard_throughputs.get(shard, 1) + 0.5  # Example: throughput increases