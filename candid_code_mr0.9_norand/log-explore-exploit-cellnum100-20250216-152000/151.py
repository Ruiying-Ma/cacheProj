# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
import collections

# Put tunable constant parameters below
PREFETCH_PROBABILITY_DEFAULT = 0.1
LATENCY_OPTIMIZATION_SCORE_DEFAULT = 1.0

# Put the metadata specifically maintained by the policy below. The policy maintains metadata for each cache entry including access frequency, last access time, prefetch probability, and memory footprint. Additionally, it keeps a global prefetch queue and a latency optimization score for each entry.
metadata = {}
prefetch_queue = collections.deque()
global_latency_optimization_score = 0

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy chooses the eviction victim based on a composite score that considers low access frequency, old last access time, low prefetch probability, and high memory footprint. Entries with the lowest latency optimization score are prioritized for eviction.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    min_score = float('inf')
    
    for key, cached_obj in cache_snapshot.cache.items():
        meta = metadata[key]
        score = (meta['access_frequency'] * 0.25 + 
                 (cache_snapshot.access_count - meta['last_access_time']) * 0.25 + 
                 meta['prefetch_probability'] * 0.25 + 
                 cached_obj.size * 0.25)
        
        if score < min_score:
            min_score = score
            candid_obj_key = key
    
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    Upon a cache hit, the access frequency and last access time of the entry are updated. The prefetch probability is recalculated based on recent access patterns, and the latency optimization score is adjusted to reflect the improved hit rate.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    key = obj.key
    meta = metadata[key]
    meta['access_frequency'] += 1
    meta['last_access_time'] = cache_snapshot.access_count
    meta['prefetch_probability'] = min(1.0, meta['prefetch_probability'] + 0.01)
    meta['latency_optimization_score'] = 1.0 / (meta['access_frequency'] + 1)

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the policy initializes its metadata with default values. The prefetch queue is updated to include potential future accesses related to the new object, and the global latency optimization score is recalculated to account for the new entry.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    key = obj.key
    metadata[key] = {
        'access_frequency': 1,
        'last_access_time': cache_snapshot.access_count,
        'prefetch_probability': PREFETCH_PROBABILITY_DEFAULT,
        'latency_optimization_score': LATENCY_OPTIMIZATION_SCORE_DEFAULT
    }
    prefetch_queue.append(key)
    global global_latency_optimization_score
    global_latency_optimization_score += LATENCY_OPTIMIZATION_SCORE_DEFAULT

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    After evicting an entry, the policy removes its metadata and updates the prefetch queue to remove any related prefetch entries. The global latency optimization score is recalculated to reflect the removal, ensuring the cache remains optimized for latency.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    key = evicted_obj.key
    if key in metadata:
        global global_latency_optimization_score
        global_latency_optimization_score -= metadata[key]['latency_optimization_score']
        del metadata[key]
    
    if key in prefetch_queue:
        prefetch_queue.remove(key)