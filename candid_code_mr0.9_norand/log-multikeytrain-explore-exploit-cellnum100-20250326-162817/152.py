# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
from collections import defaultdict, deque

# Put tunable constant parameters below
NUM_LEVELS = 3

# Put the metadata specifically maintained by the policy below. The policy maintains access frequency, last access time, region classification, a global time window, a prediction model for access patterns, a primary list of cached items, a mirrored list of recently accessed items, a hidden list of recently evicted items, a historical access pattern log for each cached item, and a multi-level hierarchy with unique replacement strategies for each level.
access_frequency = defaultdict(int)
last_access_time = defaultdict(int)
region_classification = defaultdict(int)
global_time_window = 100
prediction_model = defaultdict(float)
primary_list = deque()
mirrored_list = deque()
hidden_list = deque()
historical_access_log = defaultdict(list)
multi_level_cache = [deque() for _ in range(NUM_LEVELS)]

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy first identifies the region with the least recent access. Within that region, it selects the object not present in both the primary and mirrored lists. If no such object exists, it uses the prediction model to evict the object with the lowest predicted access probability. If there is still a tie, it uses the historical access pattern to evict the least recently accessed item. If there is still a tie, a random item is chosen for eviction. If the lowest level is full, the least frequently accessed or oldest item is evicted.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    # Your code below
    # Identify the region with the least recent access
    least_recent_region = min(region_classification, key=lambda k: last_access_time[k])
    
    # Select the object not present in both the primary and mirrored lists
    for key, cached_obj in cache_snapshot.cache.items():
        if key not in primary_list and key not in mirrored_list:
            if region_classification[key] == least_recent_region:
                candid_obj_key = key
                break
    
    if candid_obj_key is None:
        # Use the prediction model to evict the object with the lowest predicted access probability
        candid_obj_key = min(cache_snapshot.cache, key=lambda k: prediction_model[k])
    
    if candid_obj_key is None:
        # Use the historical access pattern to evict the least recently accessed item
        candid_obj_key = min(cache_snapshot.cache, key=lambda k: last_access_time[k])
    
    if candid_obj_key is None:
        # If there is still a tie, a random item is chosen for eviction
        candid_obj_key = next(iter(cache_snapshot.cache))
    
    if candid_obj_key is None:
        # If the lowest level is full, the least frequently accessed or oldest item is evicted
        candid_obj_key = min(multi_level_cache[0], key=lambda k: (access_frequency[k], last_access_time[k]))
    
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    Upon a cache hit, the policy updates the last access time, increments the access frequency, and updates the prediction model with the new access pattern. The accessed item is moved to the front of the primary and mirrored lists. The historical access log for the item is updated to reflect the recent access. If the item is in a lower level, it is promoted to a higher level based on its updated access frequency.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    # Your code below
    current_time = cache_snapshot.access_count
    access_frequency[obj.key] += 1
    last_access_time[obj.key] = current_time
    prediction_model[obj.key] = access_frequency[obj.key] / (current_time - last_access_time[obj.key] + 1)
    
    if obj.key in primary_list:
        primary_list.remove(obj.key)
    primary_list.appendleft(obj.key)
    
    if obj.key in mirrored_list:
        mirrored_list.remove(obj.key)
    mirrored_list.appendleft(obj.key)
    
    historical_access_log[obj.key].append(current_time)
    
    for level in range(NUM_LEVELS - 1):
        if obj.key in multi_level_cache[level]:
            multi_level_cache[level].remove(obj.key)
            multi_level_cache[level + 1].appendleft(obj.key)
            break

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the policy assigns it to a region based on initial access patterns, sets its access frequency to 1, records the current time as the last access time, and updates the prediction model to include the new object. The object is added to the front of the primary and mirrored lists. The historical access log is initialized for the new object. The object is placed in the lowest level and may be promoted to higher levels based on subsequent access patterns.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    # Your code below
    current_time = cache_snapshot.access_count
    access_frequency[obj.key] = 1
    last_access_time[obj.key] = current_time
    prediction_model[obj.key] = 1 / (current_time + 1)
    
    primary_list.appendleft(obj.key)
    mirrored_list.appendleft(obj.key)
    
    historical_access_log[obj.key] = [current_time]
    
    multi_level_cache[0].appendleft(obj.key)
    region_classification[obj.key] = 0

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    After evicting an object, the policy removes its metadata, updates the region's statistics to reflect the eviction, and adjusts the prediction model to account for the removal. The object is removed from the primary and mirrored lists and added to the hidden list. The historical access log for the evicted item is retained for future reference. The policy updates the access frequency counters and timestamps for the remaining items in the level. If the evicted item was frequently accessed, it may trigger a re-evaluation of the replacement strategy for that level.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    # Your code below
    if evicted_obj.key in primary_list:
        primary_list.remove(evicted_obj.key)
    if evicted_obj.key in mirrored_list:
        mirrored_list.remove(evicted_obj.key)
    
    hidden_list.appendleft(evicted_obj.key)
    
    del access_frequency[evicted_obj.key]
    del last_access_time[evicted_obj.key]
    del prediction_model[evicted_obj.key]
    del region_classification[evicted_obj.key]
    
    for level in range(NUM_LEVELS):
        if evicted_obj.key in multi_level_cache[level]:
            multi_level_cache[level].remove(evicted_obj.key)
            break
    
    # Update the access frequency counters and timestamps for the remaining items in the level
    for key in multi_level_cache[0]:
        access_frequency[key] -= 1
        last_access_time[key] = cache_snapshot.access_count
    
    # Re-evaluate the replacement strategy for the level if necessary
    if access_frequency[evicted_obj.key] > 1:
        # Implement re-evaluation logic here if needed
        pass