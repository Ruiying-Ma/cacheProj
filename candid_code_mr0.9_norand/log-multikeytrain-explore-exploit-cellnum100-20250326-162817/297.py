# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
from collections import defaultdict

# Put tunable constant parameters below
INITIAL_PRIORITY_LEVEL = 1

# Put the metadata specifically maintained by the policy below. The policy maintains a historical access log, a predictive model for future access patterns, access frequency, recency, size, priority level, and cache hierarchy level for each cache object. It also tracks overall access patterns to periodically adjust eviction criteria.
historical_access_log = {}
access_frequency = defaultdict(int)
recency = {}
size = {}
priority_level = {}
priority_score = {}
cache_hierarchy_level = {}
overall_access_patterns = {
    'total_accesses': 0,
    'total_hits': 0,
    'total_misses': 0
}

def calculate_priority_score(key):
    # Priority score is a combination of recency, frequency, and size
    return access_frequency[key] / (recency[key] + 1) / size[key]

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy uses the predictive model to identify cache entries that are least likely to be accessed in the near future. Among these, it prioritizes evicting entries with the lowest priority scores, which are calculated based on a combination of recency, frequency, and size. If there is a tie, the object with the largest size is evicted.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    lowest_priority_score = float('inf')
    largest_size = -1

    for key, cached_obj in cache_snapshot.cache.items():
        score = calculate_priority_score(key)
        if score < lowest_priority_score or (score == lowest_priority_score and cached_obj.size > largest_size):
            lowest_priority_score = score
            largest_size = cached_obj.size
            candid_obj_key = key
    
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    Upon a cache hit, the policy updates the historical access log, increments the frequency counter, updates the recency, and recalculates the priority score. The object may be promoted to a higher cache level if it meets the criteria. The overall access pattern metadata is also updated to reflect the hit.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    key = obj.key
    historical_access_log[key].append(cache_snapshot.access_count)
    access_frequency[key] += 1
    recency[key] = cache_snapshot.access_count
    priority_score[key] = calculate_priority_score(key)
    overall_access_patterns['total_hits'] += 1

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the policy adds an entry to the historical access log, initializes the frequency counter, sets the recency to the current time, records the size, assigns an initial priority level, and calculates an initial priority score. The object is placed in the appropriate cache level based on its priority. The overall access pattern metadata is updated to include the new object.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    key = obj.key
    historical_access_log[key] = [cache_snapshot.access_count]
    access_frequency[key] = 1
    recency[key] = cache_snapshot.access_count
    size[key] = obj.size
    priority_level[key] = INITIAL_PRIORITY_LEVEL
    priority_score[key] = calculate_priority_score(key)
    cache_hierarchy_level[key] = 1  # Assuming single level cache for simplicity
    overall_access_patterns['total_accesses'] += 1

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    Following an eviction, the policy removes the evicted entry from the historical access log, deletes its frequency counter, and adjusts the predictive model. The overall access pattern metadata is updated to reflect the eviction. The policy may adjust the priority levels of remaining objects and potentially demote objects to lower cache levels if necessary.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    key = evicted_obj.key
    del historical_access_log[key]
    del access_frequency[key]
    del recency[key]
    del size[key]
    del priority_level[key]
    del priority_score[key]
    del cache_hierarchy_level[key]
    overall_access_patterns['total_accesses'] += 1
    overall_access_patterns['total_misses'] += 1