# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
from collections import defaultdict, deque

# Put tunable constant parameters below
K = 3  # Number of LRU queues

# Put the metadata specifically maintained by the policy below. The policy maintains k LRU queues, access frequency, last access time, region classification, priority level, and a prediction model for access patterns. It also tracks overall access patterns and a global time window.
lru_queues = [deque() for _ in range(K)]
access_frequency = defaultdict(int)
last_access_time = defaultdict(int)
region_classification = defaultdict(int)
priority_level = defaultdict(int)
prediction_model = defaultdict(float)
global_time_window = 0

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy first identifies the least recently used object in the non-empty LRU queue with the smallest subscript. If there is a tie, it selects the object with the lowest priority level within that region. If there is still a tie, it evicts the one with the lowest predicted access probability.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    # Your code below
    for i in range(K):
        if lru_queues[i]:
            # Find the least recently used object in the current queue
            lru_obj_key = lru_queues[i][0]
            # Check for ties based on priority level
            min_priority = priority_level[lru_obj_key]
            min_priority_obj_key = lru_obj_key
            for key in lru_queues[i]:
                if priority_level[key] < min_priority:
                    min_priority = priority_level[key]
                    min_priority_obj_key = key
                elif priority_level[key] == min_priority:
                    # Check for ties based on predicted access probability
                    if prediction_model[key] < prediction_model[min_priority_obj_key]:
                        min_priority_obj_key = key
            candid_obj_key = min_priority_obj_key
            break
    
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    Increment the access frequency and frequency count, update the last access time, and adjust the priority level based on the new frequency count and overall access patterns. Move the hit object to the most-recently-used end of the next higher LRU queue if not already in the highest queue. Update the prediction model with the new access pattern.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    # Your code below
    access_frequency[obj.key] += 1
    last_access_time[obj.key] = cache_snapshot.access_count
    priority_level[obj.key] = access_frequency[obj.key]  # Simplified priority adjustment

    # Move the object to the next higher LRU queue if not already in the highest queue
    for i in range(K):
        if obj.key in lru_queues[i]:
            lru_queues[i].remove(obj.key)
            if i < K - 1:
                lru_queues[i + 1].append(obj.key)
            else:
                lru_queues[i].append(obj.key)
            break

    # Update the prediction model with the new access pattern
    prediction_model[obj.key] = access_frequency[obj.key] / (cache_snapshot.access_count + 1)

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    Set the inserted object's recency as the current timestamp and put it at the most-recently-used end of L1. Assign it to a region based on initial access patterns, set its access frequency and frequency count to 1, record the current time as the last access time, and assign an initial priority level. Update the prediction model to include the new object.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    # Your code below
    last_access_time[obj.key] = cache_snapshot.access_count
    lru_queues[0].append(obj.key)
    region_classification[obj.key] = 0  # Simplified region classification
    access_frequency[obj.key] = 1
    priority_level[obj.key] = 1
    prediction_model[obj.key] = 1 / (cache_snapshot.access_count + 1)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    Remove the evicted object from the queue it resides in and its metadata. Update the region's statistics to reflect the eviction and adjust the prediction model to account for the removal. Update overall access patterns and adjust the priority levels of remaining objects if necessary.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    # Your code below
    for i in range(K):
        if evicted_obj.key in lru_queues[i]:
            lru_queues[i].remove(evicted_obj.key)
            break

    del access_frequency[evicted_obj.key]
    del last_access_time[evicted_obj.key]
    del region_classification[evicted_obj.key]
    del priority_level[evicted_obj.key]
    del prediction_model[evicted_obj.key]

    # Update the region's statistics and prediction model
    # Simplified: No specific region statistics maintained
    # Adjust the priority levels of remaining objects if necessary
    # Simplified: No specific adjustment needed