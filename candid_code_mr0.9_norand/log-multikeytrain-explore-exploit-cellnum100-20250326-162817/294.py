# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.

# Put tunable constant parameters below
# For simplicity, we will use some constants to represent the weights and other parameters
INITIAL_FREQUENCY = 1
INITIAL_HIERARCHICAL_LEVEL = 0
INITIAL_PRIORITY_LEVEL = 0

# Put the metadata specifically maintained by the policy below. The policy maintains a circular pointer, access frequency, last access timestamp, dynamic weight, workload characteristic indicator, recency, hierarchical level, probabilistic eviction score, global LFU counter, LRU queue, FIFO queue, priority level, size, and overall access pattern metadata.
metadata = {
    'circular_pointer': 0,
    'access_frequency': {},
    'last_access_timestamp': {},
    'dynamic_weight': {},
    'workload_characteristic_indicator': 0,
    'recency': {},
    'hierarchical_level': {},
    'probabilistic_eviction_score': {},
    'global_LFU_counter': 0,
    'LRU_queue': [],
    'FIFO_queue': [],
    'priority_level': {},
    'size': {},
    'overall_access_pattern_metadata': {}
}

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy starts from the current pointer position and moves cyclically, resetting frequencies to 0 until it finds an object with zero frequency. It then evaluates items at the lowest hierarchical level, selecting the item with the highest probabilistic eviction score. If tied, it uses the LRU queue to evict the least-recently-used item. If still tied, it evicts the object with the lowest frequency, then the lowest priority level, and finally the largest size.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    cache_keys = list(cache_snapshot.cache.keys())
    n = len(cache_keys)
    
    # Start from the current pointer position
    for i in range(n):
        idx = (metadata['circular_pointer'] + i) % n
        key = cache_keys[idx]
        
        # Reset frequency to 0 if it is non-zero
        if metadata['access_frequency'][key] > 0:
            metadata['access_frequency'][key] = 0
        else:
            # Found an object with zero frequency
            candid_obj_key = key
            break
    
    if candid_obj_key is None:
        # Evaluate items at the lowest hierarchical level
        min_hierarchical_level = min(metadata['hierarchical_level'].values())
        candidates = [k for k, v in metadata['hierarchical_level'].items() if v == min_hierarchical_level]
        
        # Select the item with the highest probabilistic eviction score
        max_eviction_score = max(metadata['probabilistic_eviction_score'][k] for k in candidates)
        candidates = [k for k in candidates if metadata['probabilistic_eviction_score'][k] == max_eviction_score]
        
        if len(candidates) > 1:
            # Use the LRU queue to evict the least-recently-used item
            for key in metadata['LRU_queue']:
                if key in candidates:
                    candid_obj_key = key
                    break
        
        if candid_obj_key is None:
            # Evict the object with the lowest frequency
            min_frequency = min(metadata['access_frequency'][k] for k in candidates)
            candidates = [k for k in candidates if metadata['access_frequency'][k] == min_frequency]
            
            if len(candidates) > 1:
                # Evict the object with the lowest priority level
                min_priority_level = min(metadata['priority_level'][k] for k in candidates)
                candidates = [k for k in candidates if metadata['priority_level'][k] == min_priority_level]
                
                if len(candidates) > 1:
                    # Evict the object with the largest size
                    max_size = max(metadata['size'][k] for k in candidates)
                    candidates = [k for k in candidates if metadata['size'][k] == max_size]
                    
                    candid_obj_key = candidates[0]
                else:
                    candid_obj_key = candidates[0]
            else:
                candid_obj_key = candidates[0]
    
    # Update the circular pointer
    metadata['circular_pointer'] = (metadata['circular_pointer'] + 1) % n
    
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    Upon a hit, the policy sets the object's frequency to 1, updates the last access timestamp, increments the frequency counter, recalculates the dynamic weight, updates recency, adjusts the hierarchical level if necessary, recalculates the probabilistic eviction score, increases the global LFU counter, moves the object to the most-recently-used end of the LRU queue, and updates the overall access pattern metadata.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    key = obj.key
    metadata['access_frequency'][key] = 1
    metadata['last_access_timestamp'][key] = cache_snapshot.access_count
    metadata['global_LFU_counter'] += 1
    metadata['dynamic_weight'][key] = calculate_dynamic_weight(obj)
    metadata['recency'][key] = cache_snapshot.access_count
    metadata['probabilistic_eviction_score'][key] = calculate_probabilistic_eviction_score(obj)
    
    # Move the object to the most-recently-used end of the LRU queue
    if key in metadata['LRU_queue']:
        metadata['LRU_queue'].remove(key)
    metadata['LRU_queue'].append(key)
    
    # Update overall access pattern metadata
    update_overall_access_pattern_metadata()

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the policy sets the frequency to 1, initializes the last access timestamp, sets the frequency counter to 1, calculates the initial dynamic weight, updates the workload characteristic indicator, initializes recency, assigns the object to the appropriate hierarchical level, calculates its initial probabilistic eviction score, places it at the current pointer location, adds it to the most-recently-used end of the LRU queue and the rear of the FIFO queue, and updates the overall access pattern metadata.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    key = obj.key
    metadata['access_frequency'][key] = INITIAL_FREQUENCY
    metadata['last_access_timestamp'][key] = cache_snapshot.access_count
    metadata['global_LFU_counter'] += 1
    metadata['dynamic_weight'][key] = calculate_dynamic_weight(obj)
    metadata['recency'][key] = cache_snapshot.access_count
    metadata['hierarchical_level'][key] = INITIAL_HIERARCHICAL_LEVEL
    metadata['probabilistic_eviction_score'][key] = calculate_probabilistic_eviction_score(obj)
    metadata['priority_level'][key] = INITIAL_PRIORITY_LEVEL
    metadata['size'][key] = obj.size
    
    # Place it at the current pointer location
    metadata['circular_pointer'] = (metadata['circular_pointer'] + 1) % len(cache_snapshot.cache)
    
    # Add it to the most-recently-used end of the LRU queue and the rear of the FIFO queue
    metadata['LRU_queue'].append(key)
    metadata['FIFO_queue'].append(key)
    
    # Update overall access pattern metadata
    update_overall_access_pattern_metadata()

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    Following an eviction, the policy removes the metadata of the evicted object, adjusts the workload characteristic indicator based on the current cache state and access patterns, may adjust the hierarchical levels of remaining items, removes the object from the LRU queue and FIFO queue, updates the overall access pattern metadata, adjusts the priority levels of remaining objects, and potentially demotes objects to lower cache levels if necessary.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    key = evicted_obj.key
    
    # Remove the metadata of the evicted object
    del metadata['access_frequency'][key]
    del metadata['last_access_timestamp'][key]
    del metadata['dynamic_weight'][key]
    del metadata['recency'][key]
    del metadata['hierarchical_level'][key]
    del metadata['probabilistic_eviction_score'][key]
    del metadata['priority_level'][key]
    del metadata['size'][key]
    
    # Remove the object from the LRU queue and FIFO queue
    metadata['LRU_queue'].remove(key)
    metadata['FIFO_queue'].remove(key)
    
    # Adjust the workload characteristic indicator
    metadata['workload_characteristic_indicator'] = calculate_workload_characteristic_indicator()
    
    # Adjust the hierarchical levels of remaining items if necessary
    adjust_hierarchical_levels()
    
    # Update overall access pattern metadata
    update_overall_access_pattern_metadata()

def calculate_dynamic_weight(obj):
    # Placeholder function to calculate dynamic weight
    return 1

def calculate_probabilistic_eviction_score(obj):
    # Placeholder function to calculate probabilistic eviction score
    return 1

def update_overall_access_pattern_metadata():
    # Placeholder function to update overall access pattern metadata
    pass

def calculate_workload_characteristic_indicator():
    # Placeholder function to calculate workload characteristic indicator
    return 1

def adjust_hierarchical_levels():
    # Placeholder function to adjust hierarchical levels
    pass