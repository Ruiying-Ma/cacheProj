# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
import time

# Put tunable constant parameters below
ALPHA = 0.5  # Weight for recency in composite score
BETA = 0.3   # Weight for access frequency in composite score
GAMMA = 0.2  # Weight for priority score in composite score

# Put the metadata specifically maintained by the policy below. The policy maintains access frequency, last access time, region classification, global time window, prediction model for access patterns, primary and mirrored lists of cached items, hidden list of recently evicted items, historical access pattern log, multi-level hierarchy, two LRU queues (T1 and T2), two FIFO ghost queues (B1 and B2), priority scores, contextual relevance scores, and overall workload characteristics using a machine learning model.
metadata = {
    'access_frequency': {},  # {key: frequency}
    'last_access_time': {},  # {key: last_access_time}
    'priority_score': {},    # {key: priority_score}
    'contextual_relevance': {},  # {key: contextual_relevance}
    'primary_list': [],      # List of keys in primary list
    'mirrored_list': [],     # List of keys in mirrored list
    'hidden_list': [],       # List of keys in hidden list
    'historical_log': {},    # {key: [access_times]}
    'T1': [],                # LRU queue T1
    'T2': [],                # LRU queue T2
    'B1': [],                # FIFO ghost queue B1
    'B2': [],                # FIFO ghost queue B2
}

def calculate_composite_score(key):
    recency = time.time() - metadata['last_access_time'].get(key, 0)
    frequency = metadata['access_frequency'].get(key, 0)
    priority = metadata['priority_score'].get(key, 0)
    contextual = metadata['contextual_relevance'].get(key, 0)
    return ALPHA * recency + BETA * frequency + GAMMA * priority + contextual

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy calculates a composite score for each object based on access frequency, recency, priority score, and contextual relevance. It identifies the region with the least recent access and selects the object with the lowest composite score within that region, prioritizing T1 first, then T2 if T1 is empty. If a tie persists, it uses the prediction model and historical access patterns to break the tie. The object is moved to the hidden list and to the rear of B1 or B2.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    # Your code below
    if metadata['T1']:
        region = metadata['T1']
    else:
        region = metadata['T2']
    
    min_score = float('inf')
    for key in region:
        score = calculate_composite_score(key)
        if score < min_score:
            min_score = score
            candid_obj_key = key
    
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    Upon a cache hit, the policy updates the last access time, increments the access frequency, recalculates priority and contextual relevance scores, and updates the prediction model. The accessed item is moved to the front of the primary and mirrored lists and to the most-recently-used end of T2. The historical access log is updated, and if the item is in a lower level, it is promoted to a higher level.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    # Your code below
    key = obj.key
    metadata['last_access_time'][key] = time.time()
    metadata['access_frequency'][key] = metadata['access_frequency'].get(key, 0) + 1
    metadata['priority_score'][key] = calculate_composite_score(key)
    metadata['contextual_relevance'][key] = 0  # Update based on your model

    if key in metadata['T1']:
        metadata['T1'].remove(key)
    if key in metadata['T2']:
        metadata['T2'].remove(key)
    
    metadata['T2'].append(key)
    metadata['primary_list'].insert(0, key)
    metadata['mirrored_list'].insert(0, key)
    metadata['historical_log'].setdefault(key, []).append(time.time())

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the policy assigns it to a region, sets initial access frequency, recency, priority, and contextual relevance scores, and updates the prediction model. The object is added to the front of the primary and mirrored lists and to the most-recently-used end of T1 or T2 if it was in B1 or B2. The historical access log is initialized, and the object is placed in the lowest level, with potential promotion based on access patterns.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    # Your code below
    key = obj.key
    metadata['last_access_time'][key] = time.time()
    metadata['access_frequency'][key] = 1
    metadata['priority_score'][key] = 0  # Initial priority score
    metadata['contextual_relevance'][key] = 0  # Initial contextual relevance

    if key in metadata['B1']:
        metadata['B1'].remove(key)
        metadata['T2'].append(key)
    elif key in metadata['B2']:
        metadata['B2'].remove(key)
        metadata['T2'].append(key)
    else:
        metadata['T1'].append(key)
    
    metadata['primary_list'].insert(0, key)
    metadata['mirrored_list'].insert(0, key)
    metadata['historical_log'][key] = [time.time()]

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    Following an eviction, the policy removes the object's metadata, updates region statistics, and adjusts the prediction model. The object is moved to the hidden list and to the rear of B1 or B2. The historical access log is retained, and the access frequency counters and timestamps for remaining items are updated. The machine learning model updates overall workload characteristics and access patterns.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    # Your code below
    key = evicted_obj.key
    if key in metadata['T1']:
        metadata['T1'].remove(key)
        metadata['B1'].append(key)
    elif key in metadata['T2']:
        metadata['T2'].remove(key)
        metadata['B2'].append(key)
    
    metadata['hidden_list'].append(key)
    del metadata['last_access_time'][key]
    del metadata['access_frequency'][key]
    del metadata['priority_score'][key]
    del metadata['contextual_relevance'][key]
    # Update prediction model and workload characteristics