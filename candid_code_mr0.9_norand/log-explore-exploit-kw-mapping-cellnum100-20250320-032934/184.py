# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
import time

# Put tunable constant parameters below
LRU_WEIGHT = 0.4
LFU_WEIGHT = 0.4
CONTEXTUAL_WEIGHT = 0.2

# Put the metadata specifically maintained by the policy below. The policy maintains metadata including access frequency, last access time, and a dynamic weight for each strategy (LRU, LFU, random). It also tracks contextual relevance scores based on recent workload patterns.
metadata = {
    'access_frequency': {},  # {obj.key: frequency}
    'last_access_time': {},  # {obj.key: last_access_time}
    'contextual_relevance': {},  # {obj.key: relevance_score}
    'weights': {
        'LRU': LRU_WEIGHT,
        'LFU': LFU_WEIGHT,
        'CONTEXTUAL': CONTEXTUAL_WEIGHT
    }
}

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy calculates a composite score for each cache entry using a weighted combination of LRU, LFU, and contextual relevance. The entry with the lowest composite score is chosen for eviction, with weights dynamically adjusted based on current workload patterns.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    min_score = float('inf')
    
    for key, cached_obj in cache_snapshot.cache.items():
        lru_score = cache_snapshot.access_count - metadata['last_access_time'][key]
        lfu_score = metadata['access_frequency'][key]
        contextual_score = metadata['contextual_relevance'][key]
        
        composite_score = (metadata['weights']['LRU'] * lru_score +
                           metadata['weights']['LFU'] * lfu_score +
                           metadata['weights']['CONTEXTUAL'] * contextual_score)
        
        if composite_score < min_score:
            min_score = composite_score
            candid_obj_key = key
    
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    Upon a cache hit, the access frequency and last access time of the hit entry are updated. The contextual relevance score is recalculated based on the current workload context, and the weights for each strategy are adjusted to reflect recent access patterns.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    key = obj.key
    metadata['access_frequency'][key] += 1
    metadata['last_access_time'][key] = cache_snapshot.access_count
    metadata['contextual_relevance'][key] = calculate_contextual_relevance(cache_snapshot, obj)
    adjust_weights(cache_snapshot)

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the policy initializes its access frequency, last access time, and contextual relevance score. The weights for each strategy are recalibrated based on the updated cache state and recent workload patterns.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    key = obj.key
    metadata['access_frequency'][key] = 1
    metadata['last_access_time'][key] = cache_snapshot.access_count
    metadata['contextual_relevance'][key] = calculate_contextual_relevance(cache_snapshot, obj)
    adjust_weights(cache_snapshot)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    Following an eviction, the policy updates the weights for each strategy to reflect the new cache composition and recent access patterns. The contextual relevance scores of remaining entries are recalculated to ensure they align with the current workload context.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    key = evicted_obj.key
    if key in metadata['access_frequency']:
        del metadata['access_frequency'][key]
    if key in metadata['last_access_time']:
        del metadata['last_access_time'][key]
    if key in metadata['contextual_relevance']:
        del metadata['contextual_relevance'][key]
    
    adjust_weights(cache_snapshot)
    for key in cache_snapshot.cache:
        metadata['contextual_relevance'][key] = calculate_contextual_relevance(cache_snapshot, cache_snapshot.cache[key])

def calculate_contextual_relevance(cache_snapshot, obj):
    '''
    This function calculates the contextual relevance score for an object based on the current workload context.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object for which to calculate the contextual relevance score.
    - Return:
        - `relevance_score`: The calculated contextual relevance score.
    '''
    # Placeholder for actual contextual relevance calculation logic
    return 1  # This should be replaced with actual logic

def adjust_weights(cache_snapshot):
    '''
    This function adjusts the weights for each strategy based on the current workload patterns.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
    - Return: `None`
    '''
    # Placeholder for actual weight adjustment logic
    # This should be replaced with actual logic to adjust weights based on workload patterns
    pass