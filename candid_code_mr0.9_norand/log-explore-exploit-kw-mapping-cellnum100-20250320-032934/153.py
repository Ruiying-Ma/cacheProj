# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
import heapq
from collections import defaultdict

# Put tunable constant parameters below
PRIORITY_WEIGHT_RECENCY = 0.5
PRIORITY_WEIGHT_FREQUENCY = 0.5
USAGE_THRESHOLD = 10

# Put the metadata specifically maintained by the policy below. Each cached item maintains a timestamp of its last access, an access frequency counter, a priority score (weighted sum of recency and frequency), a tier level indicator, a context relevance score predicted by a machine learning model, and a fixed location. A global schedule predicts future access patterns and an ordered list of access times is maintained.
metadata = {
    'timestamps': {},  # obj.key -> last access timestamp
    'access_frequency': {},  # obj.key -> access frequency counter
    'priority_scores': {},  # obj.key -> priority score
    'tier_levels': {},  # obj.key -> tier level
    'context_relevance': {},  # obj.key -> context relevance score
    'fixed_locations': {},  # obj.key -> fixed location
    'global_schedule': [],  # list of (predicted access time, obj.key)
    'access_times': []  # list of (access time, obj.key)
}

def calculate_priority_score(recency, frequency):
    return PRIORITY_WEIGHT_RECENCY * recency + PRIORITY_WEIGHT_FREQUENCY * frequency

def predict_context_relevance(obj):
    # Placeholder for machine learning model prediction
    return 1.0

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy evicts the item with the lowest combined priority score and context relevance score, starting from the lowest tier and level. If multiple items have the same combined score, the item with the lowest usage counter and oldest entry in the fixed location is evicted. The global schedule is cross-referenced to ensure items predicted to be accessed soon are retained.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    min_score = float('inf')
    min_tier = float('inf')
    min_level = float('inf')
    min_usage = float('inf')
    oldest_time = float('inf')

    for key, cached_obj in cache_snapshot.cache.items():
        priority_score = metadata['priority_scores'][key]
        context_relevance = metadata['context_relevance'][key]
        combined_score = priority_score + context_relevance
        tier_level = metadata['tier_levels'][key]
        usage_counter = metadata['access_frequency'][key]
        fixed_location = metadata['fixed_locations'][key]
        last_access_time = metadata['timestamps'][key]

        if combined_score < min_score or \
           (combined_score == min_score and tier_level < min_tier) or \
           (combined_score == min_score and tier_level == min_tier and usage_counter < min_usage) or \
           (combined_score == min_score and tier_level == min_tier and usage_counter == min_usage and last_access_time < oldest_time):
            min_score = combined_score
            min_tier = tier_level
            min_usage = usage_counter
            oldest_time = last_access_time
            candid_obj_key = key

    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    Upon a cache hit, the item's timestamp is updated to the current time, its access frequency counter is incremented, its priority score is recalculated, its context relevance score is updated using the machine learning model, and it may be promoted to a higher tier and level if its usage counter exceeds a threshold. The object's position in the ordered list of access times is updated.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    current_time = cache_snapshot.access_count
    key = obj.key

    metadata['timestamps'][key] = current_time
    metadata['access_frequency'][key] += 1
    recency = current_time - metadata['timestamps'][key]
    frequency = metadata['access_frequency'][key]
    metadata['priority_scores'][key] = calculate_priority_score(recency, frequency)
    metadata['context_relevance'][key] = predict_context_relevance(obj)

    if metadata['access_frequency'][key] > USAGE_THRESHOLD:
        metadata['tier_levels'][key] += 1

    metadata['access_times'].append((current_time, key))

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, its timestamp is set to the current time, its access frequency counter is initialized to 1, its priority score is calculated, it is assigned to the lowest tier and level, and its initial context relevance score is calculated using the machine learning model. The object is placed in the appropriate fixed location, and the global schedule and ordered list of access times are updated.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    current_time = cache_snapshot.access_count
    key = obj.key

    metadata['timestamps'][key] = current_time
    metadata['access_frequency'][key] = 1
    recency = current_time - metadata['timestamps'][key]
    frequency = metadata['access_frequency'][key]
    metadata['priority_scores'][key] = calculate_priority_score(recency, frequency)
    metadata['tier_levels'][key] = 0
    metadata['context_relevance'][key] = predict_context_relevance(obj)
    metadata['fixed_locations'][key] = len(metadata['fixed_locations'])

    metadata['access_times'].append((current_time, key))
    heapq.heappush(metadata['global_schedule'], (current_time, key))

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    Following an eviction, the global schedule is adjusted to remove the evicted item from future predictions, the priority scores of remaining items are recalculated if necessary, the usage counters of all remaining items are reset, their context relevance scores are potentially recalculated, and their tier levels are adjusted based on the updated usage counters and relevance scores. The fixed location is marked as available for new entries, and the ordered list of access times is updated.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    evicted_key = evicted_obj.key

    # Remove evicted item from metadata
    del metadata['timestamps'][evicted_key]
    del metadata['access_frequency'][evicted_key]
    del metadata['priority_scores'][evicted_key]
    del metadata['tier_levels'][evicted_key]
    del metadata['context_relevance'][evicted_key]
    del metadata['fixed_locations'][evicted_key]

    # Remove evicted item from global schedule
    metadata['global_schedule'] = [(time, key) for time, key in metadata['global_schedule'] if key != evicted_key]
    heapq.heapify(metadata['global_schedule'])

    # Reset usage counters and recalculate priority scores and context relevance scores
    for key in cache_snapshot.cache:
        metadata['access_frequency'][key] = 0
        recency = cache_snapshot.access_count - metadata['timestamps'][key]
        frequency = metadata['access_frequency'][key]
        metadata['priority_scores'][key] = calculate_priority_score(recency, frequency)
        metadata['context_relevance'][key] = predict_context_relevance(cache_snapshot.cache[key])

        if metadata['access_frequency'][key] > USAGE_THRESHOLD:
            metadata['tier_levels'][key] += 1

    # Update ordered list of access times
    metadata['access_times'] = [(time, key) for time, key in metadata['access_times'] if key != evicted_key]