# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
from collections import defaultdict

# Put tunable constant parameters below
ALPHA = 0.5  # Weight for unified cognitive-temporal score
BETA = 0.3   # Weight for predictive relevance score
GAMMA = 0.2  # Weight for hybrid entropy-differential encoding score
DELTA = 0.1  # Weight for semantic-temporal overlay

# Put the metadata specifically maintained by the policy below. The policy maintains a unified cognitive-temporal score (combining cognitive, temporal harmonic, and temporal fusion aspects), a predictive relevance score (merging predictive latency and predictive heuristic), a hybrid entropy-differential encoding score (capturing randomness and access pattern changes), and a semantic-temporal overlay (mapping objects to clusters with temporal trends).
metadata = {
    "cognitive_temporal_score": defaultdict(float),  # Stores unified cognitive-temporal scores for each object
    "predictive_relevance_score": defaultdict(float),  # Stores predictive relevance scores for each object
    "entropy_differential_score": defaultdict(float),  # Stores hybrid entropy-differential encoding scores for each object
    "semantic_temporal_overlay": defaultdict(str),  # Maps objects to clusters
    "last_update_time": defaultdict(int),  # Tracks the last update time for each object
}

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy selects the object with the lowest combined score derived from the unified cognitive-temporal score, predictive relevance score, hybrid entropy-differential encoding score, and semantic-temporal overlay, with ties broken by the least recent update in the hybrid entropy-differential encoding score.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    min_score = float('inf')
    for key, cached_obj in cache_snapshot.cache.items():
        combined_score = (
            ALPHA * metadata["cognitive_temporal_score"][key] +
            BETA * metadata["predictive_relevance_score"][key] +
            GAMMA * metadata["entropy_differential_score"][key] +
            DELTA * len(metadata["semantic_temporal_overlay"][key])  # Cluster size as a proxy for overlay score
        )
        if combined_score < min_score or (
            combined_score == min_score and metadata["last_update_time"][key] < metadata["last_update_time"].get(candid_obj_key, float('inf'))
        ):
            min_score = combined_score
            candid_obj_key = key
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    The unified cognitive-temporal score is incrementally updated to reflect increased recency, frequency, and user preference; the predictive relevance score is adjusted using recent access trends; the hybrid entropy-differential encoding score is recalculated to reflect updated randomness and pattern shifts; and the semantic-temporal overlay is refined to strengthen the object's cluster association and temporal alignment.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    key = obj.key
    metadata["cognitive_temporal_score"][key] += 1 / (cache_snapshot.access_count + 1)  # Incremental recency update
    metadata["predictive_relevance_score"][key] += 0.1  # Adjust based on access trends
    metadata["entropy_differential_score"][key] = abs(metadata["entropy_differential_score"][key] - 0.05)  # Recalculate randomness
    metadata["semantic_temporal_overlay"][key] += "T"  # Strengthen temporal alignment
    metadata["last_update_time"][key] = cache_snapshot.access_count

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    The unified cognitive-temporal score is initialized using the object's initial access context and time; the predictive relevance score is seeded with contextual hints or default probabilities; the hybrid entropy-differential encoding score is set to a neutral value; and the semantic-temporal overlay is updated to include the new object in its most likely cluster with an initial temporal trend.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    key = obj.key
    metadata["cognitive_temporal_score"][key] = 1 / (cache_snapshot.access_count + 1)  # Initialize with recency
    metadata["predictive_relevance_score"][key] = 0.5  # Default probability
    metadata["entropy_differential_score"][key] = 0.5  # Neutral value
    metadata["semantic_temporal_overlay"][key] = "C1"  # Assign to default cluster
    metadata["last_update_time"][key] = cache_snapshot.access_count

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    The unified cognitive-temporal score weights are dynamically adjusted based on observed eviction outcomes; the predictive relevance score is recalibrated to improve future predictions; the hybrid entropy-differential encoding score is normalized across remaining objects; and the semantic-temporal overlay is restructured to redistribute relevance and temporal trends within the affected cluster.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    evicted_key = evicted_obj.key
    for key in cache_snapshot.cache:
        metadata["entropy_differential_score"][key] /= sum(metadata["entropy_differential_score"].values())  # Normalize scores
    cluster = metadata["semantic_temporal_overlay"].get(evicted_key, "C1")
    for key in metadata["semantic_temporal_overlay"]:
        if metadata["semantic_temporal_overlay"][key] == cluster:
            metadata["semantic_temporal_overlay"][key] += "R"  # Redistribute relevance
    metadata["cognitive_temporal_score"][evicted_key] = 0  # Reset evicted object's score