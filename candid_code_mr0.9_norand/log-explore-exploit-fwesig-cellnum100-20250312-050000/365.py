# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
import math

# Put tunable constant parameters below
INITIAL_ENTROPY = 1.0  # High entropy for new objects
INITIAL_TEMPORAL_WEIGHT = 1.0  # Neutral temporal weight
INITIAL_GRADIENT = 1.0  # Moderate gradient for QGA
ENTROPY_DECAY = 0.1  # Decay rate for entropy after a hit
TEMPORAL_INCREMENT = 1.0  # Increment for RTD after a hit
GRADIENT_AMPLIFICATION = 1.2  # Amplification factor for QGA after a hit
PDM_DECAY = 0.9  # Decay factor for PDM diffusion after eviction

# Put the metadata specifically maintained by the policy below. The policy maintains a Predictive Diffusion Matrix (PDM) to model access patterns, a Contextual Entropy Mapping (CEM) to measure uncertainty in access likelihood, a Recursive Temporal Dynamics (RTD) counter to track time-based recurrences, and a Quantum Gradient Amplification (QGA) factor to prioritize high-probability future accesses.
PDM = {}  # Predictive Diffusion Matrix: {key: {related_key: weight}}
CEM = {}  # Contextual Entropy Mapping: {key: entropy}
RTD = {}  # Recursive Temporal Dynamics: {key: temporal_weight}
QGA = {}  # Quantum Gradient Amplification: {key: gradient}

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy selects the eviction victim by identifying the object with the lowest combined score derived from the PDM's predicted access probability, the CEM's entropy value, the RTD's temporal recurrence weight, and the QGA's amplified gradient for future access likelihood.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    min_score = float('inf')

    for key, cached_obj in cache_snapshot.cache.items():
        pdm_score = sum(PDM.get(key, {}).values())  # Sum of related weights
        entropy = CEM.get(key, INITIAL_ENTROPY)
        temporal_weight = RTD.get(key, INITIAL_TEMPORAL_WEIGHT)
        gradient = QGA.get(key, INITIAL_GRADIENT)

        # Calculate combined score
        combined_score = pdm_score + entropy - temporal_weight - gradient

        # Find the object with the lowest score
        if combined_score < min_score:
            min_score = combined_score
            candid_obj_key = key

    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    Upon a cache hit, the PDM is updated to reinforce the predicted access pattern for the object, the CEM reduces entropy for the accessed object, the RTD increments its recurrence weight, and the QGA amplifies the gradient for the object's future access probability.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    key = obj.key

    # Update PDM: Reinforce access pattern
    if key not in PDM:
        PDM[key] = {}
    for related_key in cache_snapshot.cache:
        if related_key != key:
            PDM[key][related_key] = PDM[key].get(related_key, 0) + 1

    # Update CEM: Reduce entropy
    CEM[key] = max(0, CEM.get(key, INITIAL_ENTROPY) - ENTROPY_DECAY)

    # Update RTD: Increment temporal weight
    RTD[key] = RTD.get(key, INITIAL_TEMPORAL_WEIGHT) + TEMPORAL_INCREMENT

    # Update QGA: Amplify gradient
    QGA[key] = QGA.get(key, INITIAL_GRADIENT) * GRADIENT_AMPLIFICATION

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the PDM initializes predictions based on recent access patterns, the CEM assigns a high entropy value to reflect initial uncertainty, the RTD starts with a neutral temporal weight, and the QGA initializes a moderate gradient to allow rapid adaptation.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    key = obj.key

    # Initialize PDM for the new object
    PDM[key] = {}

    # Initialize CEM with high entropy
    CEM[key] = INITIAL_ENTROPY

    # Initialize RTD with neutral temporal weight
    RTD[key] = INITIAL_TEMPORAL_WEIGHT

    # Initialize QGA with moderate gradient
    QGA[key] = INITIAL_GRADIENT

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    After eviction, the PDM diffuses the removed object's influence across related patterns, the CEM recalibrates entropy for remaining objects, the RTD adjusts temporal weights to reflect the absence of the evicted object, and the QGA redistributes amplification factors to prioritize remaining objects.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    evicted_key = evicted_obj.key

    # Diffuse PDM influence of the evicted object
    if evicted_key in PDM:
        for related_key, weight in PDM[evicted_key].items():
            if related_key in PDM:
                PDM[related_key] = {k: v * PDM_DECAY for k, v in PDM[related_key].items()}
        del PDM[evicted_key]

    # Recalibrate CEM for remaining objects
    for key in cache_snapshot.cache:
        CEM[key] = max(0, CEM.get(key, INITIAL_ENTROPY) - ENTROPY_DECAY)

    # Adjust RTD for remaining objects
    for key in cache_snapshot.cache:
        RTD[key] = max(0, RTD.get(key, INITIAL_TEMPORAL_WEIGHT) - TEMPORAL_INCREMENT)

    # Redistribute QGA amplification factors
    for key in cache_snapshot.cache:
        QGA[key] = QGA.get(key, INITIAL_GRADIENT) * GRADIENT_AMPLIFICATION