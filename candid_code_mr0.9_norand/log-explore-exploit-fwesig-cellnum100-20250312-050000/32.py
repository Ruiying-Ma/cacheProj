# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
from collections import deque
from math import exp

# Put tunable constant parameters below
PRIORITY_WEIGHT = 1.0
SEMANTIC_DRIFT_WEIGHT = -1.0
LATENCY_PROFILE_WEIGHT = 1.0
PREDICTED_ACCESS_PROB_WEIGHT = 1.0
DEFAULT_PRIORITY = 1
DEFAULT_SEMANTIC_DRIFT = 1.0
DEFAULT_LATENCY_PROFILE = 1.0
DEFAULT_PREDICTED_ACCESS_PROB = 0.5

# Put the metadata specifically maintained by the policy below. The policy maintains a rotation index, access latency counters, priority tags, a sequential eviction queue, a Bloom filter for recently accessed keys, semantic drift scores, latency profiles, and a predictive model for future access patterns.
rotation_index = 0
access_latency_counters = {}
priority_tags = {}
sequential_eviction_queue = deque()
bloom_filter = set()
semantic_drift_scores = {}
latency_profiles = {}
predicted_access_probs = {}

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy calculates a combined score for each block as a weighted sum of its priority tag (higher is better), semantic drift score (lower is better), latency profile (higher is better), and predicted future access probability (higher is better). The block with the lowest combined score is evicted. In case of a tie, the least recently rotated block in the sequential eviction queue is chosen.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    global sequential_eviction_queue

    # Calculate combined scores for all objects in the cache
    scores = {}
    for key, cached_obj in cache_snapshot.cache.items():
        priority = priority_tags.get(key, DEFAULT_PRIORITY)
        semantic_drift = semantic_drift_scores.get(key, DEFAULT_SEMANTIC_DRIFT)
        latency_profile = latency_profiles.get(key, DEFAULT_LATENCY_PROFILE)
        predicted_access_prob = predicted_access_probs.get(key, DEFAULT_PREDICTED_ACCESS_PROB)
        
        # Weighted sum of scores
        score = (PRIORITY_WEIGHT * priority +
                 SEMANTIC_DRIFT_WEIGHT * semantic_drift +
                 LATENCY_PROFILE_WEIGHT * latency_profile +
                 PREDICTED_ACCESS_PROB_WEIGHT * predicted_access_prob)
        scores[key] = score

    # Find the object with the lowest score
    min_score = min(scores.values())
    candidates = [key for key, score in scores.items() if score == min_score]

    # Resolve ties using the sequential eviction queue
    for key in sequential_eviction_queue:
        if key in candidates:
            candid_obj_key = key
            break

    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    The access latency counter for the block is reset, its priority tag is incremented, and it is moved to the end of the sequential eviction queue. The Bloom filter is updated to reinforce the presence of the accessed key, the semantic drift score is recalibrated based on recent access patterns, and the predictive model is updated to improve future access forecasts.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    global access_latency_counters, priority_tags, sequential_eviction_queue, bloom_filter, semantic_drift_scores, predicted_access_probs

    key = obj.key

    # Reset access latency counter
    access_latency_counters[key] = 0

    # Increment priority tag
    priority_tags[key] = priority_tags.get(key, DEFAULT_PRIORITY) + 1

    # Move to the end of the sequential eviction queue
    if key in sequential_eviction_queue:
        sequential_eviction_queue.remove(key)
    sequential_eviction_queue.append(key)

    # Update Bloom filter
    bloom_filter.add(key)

    # Recalibrate semantic drift score
    semantic_drift_scores[key] = max(0, semantic_drift_scores.get(key, DEFAULT_SEMANTIC_DRIFT) - 0.1)

    # Update predictive model (simplified as increasing predicted access probability)
    predicted_access_probs[key] = min(1.0, predicted_access_probs.get(key, DEFAULT_PREDICTED_ACCESS_PROB) + 0.1)

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    The rotation index is updated to point to the next block, the new block is assigned a default priority tag, its access latency counter is initialized, and it is added to the end of the sequential eviction queue. The Bloom filter is updated to include the new key, the semantic drift score is initialized based on the object's initial relevance, and the latency profile and predictive model are updated to reflect the new cache state.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    global rotation_index, access_latency_counters, priority_tags, sequential_eviction_queue, bloom_filter, semantic_drift_scores, latency_profiles, predicted_access_probs

    key = obj.key

    # Update rotation index
    rotation_index = (rotation_index + 1) % cache_snapshot.capacity

    # Assign default priority tag
    priority_tags[key] = DEFAULT_PRIORITY

    # Initialize access latency counter
    access_latency_counters[key] = 0

    # Add to the end of the sequential eviction queue
    sequential_eviction_queue.append(key)

    # Update Bloom filter
    bloom_filter.add(key)

    # Initialize semantic drift score
    semantic_drift_scores[key] = DEFAULT_SEMANTIC_DRIFT

    # Update latency profile and predictive model
    latency_profiles[key] = DEFAULT_LATENCY_PROFILE
    predicted_access_probs[key] = DEFAULT_PREDICTED_ACCESS_PROB

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    The rotation index skips to the next block, the evicted block's metadata is cleared, and the sequential eviction queue is updated to remove the evicted block. The Bloom filter is updated to remove the evicted key, the semantic drift scores of remaining objects are adjusted to account for the removal, and the predictive model is retrained to adapt to the new cache composition.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    global rotation_index, access_latency_counters, priority_tags, sequential_eviction_queue, bloom_filter, semantic_drift_scores, latency_profiles, predicted_access_probs

    evicted_key = evicted_obj.key

    # Skip to the next block in the rotation index
    rotation_index = (rotation_index + 1) % cache_snapshot.capacity

    # Clear metadata for the evicted block
    access_latency_counters.pop(evicted_key, None)
    priority_tags.pop(evicted_key, None)
    semantic_drift_scores.pop(evicted_key, None)
    latency_profiles.pop(evicted_key, None)
    predicted_access_probs.pop(evicted_key, None)

    # Update the sequential eviction queue
    if evicted_key in sequential_eviction_queue:
        sequential_eviction_queue.remove(evicted_key)

    # Update Bloom filter
    bloom_filter.discard(evicted_key)

    # Adjust semantic drift scores of remaining objects
    for key in semantic_drift_scores:
        semantic_drift_scores[key] += 0.1

    # Retrain predictive model (simplified as reducing predicted access probabilities slightly)
    for key in predicted_access_probs:
        predicted_access_probs[key] = max(0, predicted_access_probs[key] - 0.05)