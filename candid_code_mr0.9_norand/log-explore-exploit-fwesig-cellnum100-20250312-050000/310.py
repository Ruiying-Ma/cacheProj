# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
import math

# Put tunable constant parameters below
ALPHA = 0.7  # Weight for recency in PRS calculation
BETA = 0.3   # Weight for frequency in PRS calculation
GAMMA = 0.5  # Weight for semantic similarity in PRS calculation
DELTA = 0.1  # Adjustment factor for AEF recalibration
EPSILON = 1e-6  # Small constant to avoid division by zero

# Put the metadata specifically maintained by the policy below. The policy maintains a Predictive Resonance Score (PRS) for each object, which combines access frequency, recency, and semantic similarity to other cached objects. It also tracks a Temporal Precision Map (TPM) to predict future access patterns and an Adaptive Equilibrium Factor (AEF) to balance short-term and long-term cache utility.
metadata = {
    "PRS": {},  # Predictive Resonance Score for each object (key -> score)
    "TPM": {},  # Temporal Precision Map (key -> predicted next access time)
    "AEF": 1.0,  # Adaptive Equilibrium Factor
    "access_frequency": {},  # Access frequency for each object (key -> count)
    "last_access_time": {},  # Last access time for each object (key -> time)
    "semantic_similarity": {},  # Semantic similarity matrix (key1 -> {key2 -> similarity})
}

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy evicts the object with the lowest PRS, adjusted by the AEF to account for temporal trends. If multiple candidates have similar scores, the Semantic Flux Cascade is used to prioritize eviction of objects with weaker semantic relationships to the rest of the cache.
    '''
    candid_obj_key = None
    min_score = float('inf')

    for key, cached_obj in cache_snapshot.cache.items():
        # Calculate adjusted PRS
        prs = metadata["PRS"].get(key, 0)
        adjusted_prs = prs * metadata["AEF"]

        # Use Semantic Flux Cascade if scores are similar
        if math.isclose(adjusted_prs, min_score, abs_tol=EPSILON):
            # Calculate semantic flux (sum of similarities to other objects)
            semantic_flux = sum(metadata["semantic_similarity"].get(key, {}).values())
            if semantic_flux < metadata["semantic_similarity"].get(candid_obj_key, {}).get(candid_obj_key, float('inf')):
                candid_obj_key = key
        elif adjusted_prs < min_score:
            min_score = adjusted_prs
            candid_obj_key = key

    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    '''
    key = obj.key
    current_time = cache_snapshot.access_count

    # Update PRS based on temporal proximity to predicted access patterns
    predicted_time = metadata["TPM"].get(key, current_time)
    temporal_proximity = 1 / (abs(predicted_time - current_time) + EPSILON)
    metadata["PRS"][key] = metadata["PRS"].get(key, 0) + ALPHA * temporal_proximity

    # Update access frequency and last access time
    metadata["access_frequency"][key] = metadata["access_frequency"].get(key, 0) + 1
    metadata["last_access_time"][key] = current_time

    # Recalibrate AEF
    metadata["AEF"] += DELTA * (1 - metadata["AEF"])

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    '''
    key = obj.key
    current_time = cache_snapshot.access_count

    # Initialize PRS using semantic similarity and predicted access frequency
    semantic_score = sum(metadata["semantic_similarity"].get(key, {}).values())
    predicted_frequency = metadata["TPM"].get(key, 1)
    metadata["PRS"][key] = GAMMA * semantic_score + BETA * predicted_frequency

    # Update access frequency and last access time
    metadata["access_frequency"][key] = 1
    metadata["last_access_time"][key] = current_time

    # Adjust AEF
    metadata["AEF"] -= DELTA * metadata["AEF"]

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    '''
    evicted_key = evicted_obj.key

    # Recalibrate PRS for remaining objects
    for key in cache_snapshot.cache:
        metadata["PRS"][key] *= (1 - DELTA)

    # Update TPM to refine future predictions
    for key in metadata["TPM"]:
        if key == evicted_key:
            del metadata["TPM"][key]

    # Adjust AEF
    metadata["AEF"] += DELTA * (1 - metadata["AEF"])