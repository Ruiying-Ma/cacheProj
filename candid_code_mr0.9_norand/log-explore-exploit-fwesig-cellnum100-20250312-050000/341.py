# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
from collections import defaultdict

# Put tunable constant parameters below
BASELINE_FUSION_SCORE = 1.0
PRIORITY_TIER_INCREMENT = 1
LATENCY_BASELINE = 1.0

# Put the metadata specifically maintained by the policy below. The policy maintains a dynamic cascade of priority tiers, a probabilistic fusion score for each object, contextual access patterns derived from recent requests, and latency dynamics tracking the time cost of fetching objects from the backing store.
priority_tiers = defaultdict(int)  # Maps object keys to their priority tiers
fusion_scores = defaultdict(lambda: BASELINE_FUSION_SCORE)  # Maps object keys to their fusion scores
contextual_access_patterns = defaultdict(int)  # Maps object keys to their last access time
latency_dynamics = defaultdict(lambda: LATENCY_BASELINE)  # Maps object keys to their latency dynamics

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy selects the eviction victim by probabilistically fusing the object's priority tier, its contextual relevance score, and its latency dynamics, favoring objects with lower scores while ensuring diversity in eviction decisions.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    # Your code below
    min_score = float('inf')
    for key, cached_obj in cache_snapshot.cache.items():
        # Calculate the eviction score
        score = (
            priority_tiers[key] +
            fusion_scores[key] +
            latency_dynamics[key]
        )
        # Favor objects with lower scores
        if score < min_score:
            min_score = score
            candid_obj_key = key
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    On a cache hit, the object's priority tier is dynamically adjusted upward, its probabilistic fusion score is recalculated to reflect increased relevance, and its contextual access pattern is updated to capture the temporal locality of the hit.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    # Your code below
    key = obj.key
    # Adjust priority tier upward
    priority_tiers[key] += PRIORITY_TIER_INCREMENT
    # Recalculate fusion score to reflect increased relevance
    fusion_scores[key] = BASELINE_FUSION_SCORE / (1 + priority_tiers[key])
    # Update contextual access pattern
    contextual_access_patterns[key] = cache_snapshot.access_count

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, its priority tier is initialized based on its contextual derivation, its probabilistic fusion score is seeded with a baseline value, and its latency dynamics are recorded to inform future decisions.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    # Your code below
    key = obj.key
    # Initialize priority tier
    priority_tiers[key] = 0
    # Seed fusion score with baseline value
    fusion_scores[key] = BASELINE_FUSION_SCORE
    # Record latency dynamics
    latency_dynamics[key] = LATENCY_BASELINE
    # Update contextual access pattern
    contextual_access_patterns[key] = cache_snapshot.access_count

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    After evicting an object, the policy recalibrates the priority tiers of remaining objects in the cascade, adjusts their probabilistic fusion scores to account for the removal, and updates contextual patterns to reflect the new cache state.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    # Your code below
    evicted_key = evicted_obj.key
    # Remove metadata for the evicted object
    if evicted_key in priority_tiers:
        del priority_tiers[evicted_key]
    if evicted_key in fusion_scores:
        del fusion_scores[evicted_key]
    if evicted_key in contextual_access_patterns:
        del contextual_access_patterns[evicted_key]
    if evicted_key in latency_dynamics:
        del latency_dynamics[evicted_key]
    # Recalibrate metadata for remaining objects
    for key in cache_snapshot.cache.keys():
        # Adjust fusion scores to account for the removal
        fusion_scores[key] *= 1.1  # Slightly increase fusion scores
        # Update contextual patterns to reflect the new cache state
        contextual_access_patterns[key] = cache_snapshot.access_count