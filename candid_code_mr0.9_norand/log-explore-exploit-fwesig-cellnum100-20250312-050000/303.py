# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
from collections import defaultdict

# Put tunable constant parameters below
TEMPORAL_LENSING_FACTOR = 1.1  # Factor to adjust PCS based on recent trends
SEMANTIC_FLUX_BASELINE = 1.0   # Neutral baseline for Semantic Flux
RECURSIVE_OPTIMIZATION_INTERVAL = 10  # Interval for triggering recursive optimization

# Put the metadata specifically maintained by the policy below. The policy maintains a Predictive Convergence Score (PCS) for each object, which estimates future access likelihood based on past access patterns. It also tracks Semantic Flux, a measure of how the object's relevance changes over time, and Temporal Lensing, which adjusts the PCS based on recent temporal access trends. Recursive Optimization is used to periodically refine these scores by analyzing patterns across all cached objects.
metadata = {
    "pcs": defaultdict(float),  # Predictive Convergence Score for each object
    "semantic_flux": defaultdict(float),  # Semantic Flux for each object
    "last_access_time": {},  # Last access time for each object
    "access_count": 0  # Global access count to track time
}

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy evicts the object with the lowest combined PCS and Semantic Flux score, adjusted by Temporal Lensing. If multiple candidates have similar scores, the one with the least recent access is chosen.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    min_score = float('inf')
    min_last_access_time = float('inf')

    for key, cached_obj in cache_snapshot.cache.items():
        pcs = metadata["pcs"][key]
        semantic_flux = metadata["semantic_flux"][key]
        last_access_time = metadata["last_access_time"].get(key, 0)

        # Calculate the combined score
        combined_score = pcs + semantic_flux

        # Choose the object with the lowest score, breaking ties by least recent access
        if (combined_score < min_score or 
            (combined_score == min_score and last_access_time < min_last_access_time)):
            min_score = combined_score
            min_last_access_time = last_access_time
            candid_obj_key = key

    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    Upon a cache hit, the PCS of the accessed object is increased based on the Temporal Lensing factor, and its Semantic Flux is recalibrated to reflect its current relevance. Recursive Optimization is triggered to adjust scores of related objects.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    key = obj.key
    metadata["pcs"][key] *= TEMPORAL_LENSING_FACTOR
    metadata["semantic_flux"][key] = SEMANTIC_FLUX_BASELINE
    metadata["last_access_time"][key] = cache_snapshot.access_count

    # Trigger Recursive Optimization periodically
    if cache_snapshot.access_count % RECURSIVE_OPTIMIZATION_INTERVAL == 0:
        recursive_optimization(cache_snapshot)

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, its PCS is initialized using a predictive model based on access patterns of similar objects, and its Semantic Flux is set to a neutral baseline. Temporal Lensing is applied to prioritize recent trends.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    key = obj.key
    metadata["pcs"][key] = obj.size / cache_snapshot.capacity  # Example predictive model
    metadata["semantic_flux"][key] = SEMANTIC_FLUX_BASELINE
    metadata["last_access_time"][key] = cache_snapshot.access_count

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    After eviction, the Recursive Optimization process is triggered to redistribute PCS and Semantic Flux among remaining objects, ensuring the cache adapts dynamically to the removal.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    evicted_key = evicted_obj.key
    # Remove metadata for the evicted object
    metadata["pcs"].pop(evicted_key, None)
    metadata["semantic_flux"].pop(evicted_key, None)
    metadata["last_access_time"].pop(evicted_key, None)

    # Trigger Recursive Optimization
    recursive_optimization(cache_snapshot)

def recursive_optimization(cache_snapshot):
    '''
    This function performs Recursive Optimization to refine PCS and Semantic Flux scores.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
    - Return: `None`
    '''
    total_pcs = sum(metadata["pcs"].values())
    total_flux = sum(metadata["semantic_flux"].values())

    for key in cache_snapshot.cache.keys():
        # Normalize PCS and Semantic Flux
        if total_pcs > 0:
            metadata["pcs"][key] /= total_pcs
        if total_flux > 0:
            metadata["semantic_flux"][key] /= total_flux