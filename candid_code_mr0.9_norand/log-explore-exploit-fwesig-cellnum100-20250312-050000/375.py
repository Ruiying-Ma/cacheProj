# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
from collections import defaultdict, deque

# Put tunable constant parameters below
INITIAL_DRIFT_SCORE = 1.0
EDGE_WEIGHT_INCREMENT = 1.0
EDGE_WEIGHT_DECAY = 0.1
CLUSTER_RELEVANCE_DECAY = 0.05

# Put the metadata specifically maintained by the policy below. The policy maintains a temporal entanglement graph (TEG) where nodes represent cached objects and edges represent temporal correlations between accesses. Each node also stores a predictive drift score, which estimates the likelihood of future access based on historical patterns. Additionally, clusters of nodes are dynamically formed using cluster optimization to group related objects, and a data assimilation score is maintained for each cluster to measure its overall relevance.
TEG = defaultdict(lambda: {"edges": defaultdict(float), "drift_score": INITIAL_DRIFT_SCORE})
clusters = defaultdict(set)  # Maps cluster IDs to sets of object keys
cluster_scores = defaultdict(float)  # Maps cluster IDs to their data assimilation scores
recent_accesses = deque(maxlen=10)  # Tracks recently accessed object keys for temporal proximity

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy selects the eviction victim by identifying the cluster with the lowest data assimilation score. Within that cluster, the object with the lowest predictive drift score and weakest temporal entanglement (fewest or weakest edges in the TEG) is chosen for eviction.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    # Identify the cluster with the lowest data assimilation score
    lowest_score_cluster = min(cluster_scores, key=cluster_scores.get)
    
    # Within that cluster, find the object with the lowest drift score and weakest entanglement
    min_drift_score = float('inf')
    min_entanglement = float('inf')
    for obj_key in clusters[lowest_score_cluster]:
        drift_score = TEG[obj_key]["drift_score"]
        entanglement = sum(TEG[obj_key]["edges"].values())
        if drift_score < min_drift_score or (drift_score == min_drift_score and entanglement < min_entanglement):
            min_drift_score = drift_score
            min_entanglement = entanglement
            candid_obj_key = obj_key
    
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    On a cache hit, the predictive drift score of the accessed object is increased based on its temporal proximity to previous accesses. The temporal entanglement graph is updated to strengthen edges between the accessed object and recently accessed objects. The data assimilation score of the cluster containing the object is recalculated to reflect the increased relevance.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    obj_key = obj.key
    # Increase the drift score
    TEG[obj_key]["drift_score"] += 1.0
    
    # Strengthen edges to recently accessed objects
    for recent_key in recent_accesses:
        if recent_key != obj_key:
            TEG[obj_key]["edges"][recent_key] += EDGE_WEIGHT_INCREMENT
            TEG[recent_key]["edges"][obj_key] += EDGE_WEIGHT_INCREMENT
    
    # Update the cluster's data assimilation score
    for cluster_id, cluster_objects in clusters.items():
        if obj_key in cluster_objects:
            cluster_scores[cluster_id] += 1.0
            break
    
    # Update recent accesses
    recent_accesses.append(obj_key)

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the policy initializes its predictive drift score based on observed patterns of similar objects. The object is added to the temporal entanglement graph with initial weak edges to recently accessed objects. The cluster optimization process is triggered to determine if the new object should form a new cluster or join an existing one, and the data assimilation score of the affected cluster(s) is updated.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    obj_key = obj.key
    # Initialize drift score
    TEG[obj_key]["drift_score"] = INITIAL_DRIFT_SCORE
    
    # Add weak edges to recently accessed objects
    for recent_key in recent_accesses:
        TEG[obj_key]["edges"][recent_key] += EDGE_WEIGHT_DECAY
        TEG[recent_key]["edges"][obj_key] += EDGE_WEIGHT_DECAY
    
    # Cluster optimization: Add to an existing cluster or form a new one
    best_cluster = None
    best_similarity = 0
    for cluster_id, cluster_objects in clusters.items():
        similarity = sum(TEG[obj_key]["edges"].get(key, 0) for key in cluster_objects)
        if similarity > best_similarity:
            best_similarity = similarity
            best_cluster = cluster_id
    
    if best_cluster is not None:
        clusters[best_cluster].add(obj_key)
        cluster_scores[best_cluster] += best_similarity
    else:
        new_cluster_id = len(clusters) + 1
        clusters[new_cluster_id].add(obj_key)
        cluster_scores[new_cluster_id] = best_similarity
    
    # Update recent accesses
    recent_accesses.append(obj_key)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    After evicting an object, its node and edges are removed from the temporal entanglement graph. The cluster optimization process is triggered to adjust clusters if necessary, and the data assimilation score of the affected cluster(s) is recalculated to reflect the removal.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    evicted_key = evicted_obj.key
    # Remove the node and its edges from the TEG
    for neighbor_key in TEG[evicted_key]["edges"]:
        del TEG[neighbor_key]["edges"][evicted_key]
    del TEG[evicted_key]
    
    # Adjust clusters and recalculate scores
    for cluster_id, cluster_objects in list(clusters.items()):
        if evicted_key in cluster_objects:
            cluster_objects.remove(evicted_key)
            if not cluster_objects:
                del clusters[cluster_id]
                del cluster_scores[cluster_id]
            else:
                cluster_scores[cluster_id] = sum(
                    TEG[key]["drift_score"] for key in cluster_objects
                ) - CLUSTER_RELEVANCE_DECAY * len(cluster_objects)
            break