# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
import math

# Put tunable constant parameters below
COGNITIVE_WEIGHT = 0.4
TEMPORAL_WEIGHT = 0.3
LATENCY_WEIGHT = 0.2
ENTROPY_WEIGHT = 0.1

# Put the metadata specifically maintained by the policy below. The policy maintains a cognitive score for each object (based on access patterns and user behavior), a temporal harmonic score (capturing periodic access trends), a predictive latency score (estimating future access delays), and an entropy score (measuring randomness in access patterns).
metadata = {
    # Stores metadata for each object by its key
    # Example structure:
    # "key": {
    #     "cognitive_score": float,
    #     "temporal_score": float,
    #     "latency_score": float,
    #     "entropy_score": float,
    #     "last_access_time": int
    # }
}

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy selects the object with the lowest combined score, calculated as a weighted sum of the cognitive score, temporal harmonic score, predictive latency score, and entropy score, ensuring a balance between predictability and randomness.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    min_combined_score = float('inf')

    for key, cached_obj in cache_snapshot.cache.items():
        scores = metadata[key]
        combined_score = (
            COGNITIVE_WEIGHT * scores["cognitive_score"] +
            TEMPORAL_WEIGHT * scores["temporal_score"] +
            LATENCY_WEIGHT * scores["latency_score"] +
            ENTROPY_WEIGHT * scores["entropy_score"]
        )
        if combined_score < min_combined_score:
            min_combined_score = combined_score
            candid_obj_key = key

    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    The cognitive score is incremented to reflect user preference, the temporal harmonic score is updated based on the time since the last access, the predictive latency score is adjusted using recent latency trends, and the entropy score is recalculated to reflect the updated access pattern.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    key = obj.key
    current_time = cache_snapshot.access_count
    scores = metadata[key]

    # Increment cognitive score
    scores["cognitive_score"] += 1

    # Update temporal harmonic score
    time_since_last_access = current_time - scores["last_access_time"]
    scores["temporal_score"] = 1 / (1 + time_since_last_access)

    # Adjust predictive latency score (simplified as a decay function)
    scores["latency_score"] *= 0.9

    # Recalculate entropy score (simplified as inverse of cognitive score)
    scores["entropy_score"] = 1 / (1 + scores["cognitive_score"])

    # Update last access time
    scores["last_access_time"] = current_time

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    The cognitive score is initialized based on the object's initial access context, the temporal harmonic score is seeded with the current time, the predictive latency score is set using the estimated latency of the first access, and the entropy score is initialized to a neutral value.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    key = obj.key
    current_time = cache_snapshot.access_count

    metadata[key] = {
        "cognitive_score": 1,  # Initial preference
        "temporal_score": 1 / (1 + current_time),  # Seeded with current time
        "latency_score": 1.0,  # Initial latency estimate
        "entropy_score": 0.5,  # Neutral value
        "last_access_time": current_time
    }

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    The metadata of the evicted object is archived for potential future use, and the weights for cognitive, temporal harmonic, predictive latency, and entropy scores are dynamically adjusted to improve future eviction decisions based on observed outcomes.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    evicted_key = evicted_obj.key

    # Archive metadata of evicted object (for simplicity, we just remove it here)
    if evicted_key in metadata:
        del metadata[evicted_key]

    # Dynamically adjust weights (simplified as no-op for now)
    # In a real implementation, this could involve analyzing eviction outcomes
    # and adjusting weights to improve future decisions.