# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
from collections import defaultdict, deque

# Put tunable constant parameters below
PREDICTIVE_INDEX_DECAY = 0.9  # Decay factor for Predictive Index
SEMANTIC_DRIFT_WEIGHT = 0.1   # Weight for Semantic Drift adjustment
GRADIENT_AMPLIFICATION_DECAY = 0.8  # Decay factor for Gradient Amplification
RECURSIVE_TIMELINE_MAX_LENGTH = 5  # Maximum length of the Recursive Timeline

# Put the metadata specifically maintained by the policy below. The policy maintains a Predictive Index (PI) for each object, which estimates future access probability based on past access patterns. It also tracks Semantic Drift (SD) to measure how the object's usage context changes over time, a Gradient Amplification (GA) score to prioritize objects with rapidly increasing access trends, and a Recursive Timeline (RT) to store a compact history of access timestamps for temporal pattern analysis.
metadata = {
    "PI": defaultdict(float),  # Predictive Index for each object
    "SD": defaultdict(float),  # Semantic Drift for each object
    "GA": defaultdict(float),  # Gradient Amplification for each object
    "RT": defaultdict(deque),  # Recursive Timeline for each object
}

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy selects the eviction victim by combining the Predictive Index, Semantic Drift, and Gradient Amplification scores into a composite score. Objects with low PI, high SD, and low GA are prioritized for eviction. If scores are tied, the Recursive Timeline is used to break ties by favoring objects with less recent or less frequent access patterns.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    min_score = float('inf')

    for key, cached_obj in cache_snapshot.cache.items():
        # Composite score: lower PI, higher SD, lower GA
        score = (
            (1 - metadata["PI"][key]) +
            metadata["SD"][key] +
            (1 - metadata["GA"][key])
        )
        # Use Recursive Timeline to break ties
        if score < min_score or (
            score == min_score and (
                not metadata["RT"][key] or metadata["RT"][key][-1] < metadata["RT"][candid_obj_key][-1]
            )
        ):
            min_score = score
            candid_obj_key = key

    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    Upon a cache hit, the Predictive Index is updated to increase the probability of future access, the Semantic Drift is recalculated to reflect the current context, the Gradient Amplification score is adjusted based on the rate of recent accesses, and the Recursive Timeline is updated with the latest access timestamp.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    key = obj.key
    current_time = cache_snapshot.access_count

    # Update Predictive Index
    metadata["PI"][key] = metadata["PI"][key] * PREDICTIVE_INDEX_DECAY + 1

    # Update Semantic Drift
    metadata["SD"][key] = abs(metadata["PI"][key] - metadata["SD"][key]) * SEMANTIC_DRIFT_WEIGHT

    # Update Gradient Amplification
    if metadata["RT"][key]:
        time_diff = current_time - metadata["RT"][key][-1]
        metadata["GA"][key] = metadata["GA"][key] * GRADIENT_AMPLIFICATION_DECAY + 1 / (time_diff + 1)

    # Update Recursive Timeline
    metadata["RT"][key].append(current_time)
    if len(metadata["RT"][key]) > RECURSIVE_TIMELINE_MAX_LENGTH:
        metadata["RT"][key].popleft()

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the Predictive Index is initialized based on the object's initial access context, the Semantic Drift is set to a neutral baseline, the Gradient Amplification score is initialized to reflect the insertion's temporal trend, and the Recursive Timeline is seeded with the current timestamp.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    key = obj.key
    current_time = cache_snapshot.access_count

    # Initialize Predictive Index
    metadata["PI"][key] = 1.0

    # Initialize Semantic Drift
    metadata["SD"][key] = 0.0

    # Initialize Gradient Amplification
    metadata["GA"][key] = 0.0

    # Seed Recursive Timeline
    metadata["RT"][key] = deque([current_time])

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    After eviction, the policy recalibrates the Predictive Index of remaining objects to account for the removed object's influence, adjusts the Semantic Drift to reflect the updated cache context, recalculates Gradient Amplification scores to normalize trends, and prunes the Recursive Timeline to maintain a compact history.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    evicted_key = evicted_obj.key

    # Recalibrate Predictive Index
    for key in cache_snapshot.cache:
        metadata["PI"][key] *= PREDICTIVE_INDEX_DECAY

    # Adjust Semantic Drift
    for key in cache_snapshot.cache:
        metadata["SD"][key] = abs(metadata["PI"][key] - metadata["SD"][key]) * SEMANTIC_DRIFT_WEIGHT

    # Recalculate Gradient Amplification
    for key in cache_snapshot.cache:
        if metadata["RT"][key]:
            time_diff = cache_snapshot.access_count - metadata["RT"][key][-1]
            metadata["GA"][key] = metadata["GA"][key] * GRADIENT_AMPLIFICATION_DECAY + 1 / (time_diff + 1)

    # Prune Recursive Timeline
    for key in cache_snapshot.cache:
        if len(metadata["RT"][key]) > RECURSIVE_TIMELINE_MAX_LENGTH:
            metadata["RT"][key] = deque(list(metadata["RT"][key])[-RECURSIVE_TIMELINE_MAX_LENGTH:])