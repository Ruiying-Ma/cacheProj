# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
from collections import defaultdict, deque

# Put tunable constant parameters below
PREDICTIVE_COHESION_WEIGHT = 0.4
TEMPORAL_FUSION_WEIGHT = 0.4
CONTEXTUAL_MODULATION_WEIGHT = 0.2
LATENCY_GRADIENT_NEUTRAL = 0
SEQUENTIAL_MAPPING_INDEX_START = 0

# Put the metadata specifically maintained by the policy below. The policy maintains a hybrid score called the Predictive Temporal Fusion Score (PTFS), which combines predictive cohesion, temporal fusion, and contextual modulation. It also tracks dynamic clusters of related objects, a recursive cascade hierarchy of access contexts, latency gradients, and sequential mapping indices for access patterns.
metadata = {
    "ptfs": {},  # Maps object keys to their PTFS scores
    "clusters": defaultdict(deque),  # Maps cluster IDs to lists of object keys
    "latency_gradients": {},  # Maps object keys to their latency gradients
    "sequential_mapping_indices": {},  # Maps object keys to their sequential mapping indices
    "cascade_hierarchy": defaultdict(set),  # Maps object keys to related object keys
    "access_times": {},  # Maps object keys to their last access time
}

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    '''
    candid_obj_key = None
    # Identify the least recently accessed cluster
    least_recent_cluster = None
    least_recent_time = float('inf')
    for cluster_id, obj_keys in metadata["clusters"].items():
        if obj_keys:
            first_obj_key = obj_keys[0]
            if metadata["access_times"].get(first_obj_key, float('inf')) < least_recent_time:
                least_recent_time = metadata["access_times"][first_obj_key]
                least_recent_cluster = cluster_id

    # Within the least recently accessed cluster, find the object with the lowest PTFS
    if least_recent_cluster is not None:
        min_ptfs = float('inf')
        for obj_key in metadata["clusters"][least_recent_cluster]:
            ptfs = metadata["ptfs"].get(obj_key, 0)
            latency_gradient = metadata["latency_gradients"].get(obj_key, LATENCY_GRADIENT_NEUTRAL)
            contextual_modulation = CONTEXTUAL_MODULATION_WEIGHT  # Default weight
            adjusted_ptfs = ptfs + latency_gradient + contextual_modulation
            if adjusted_ptfs < min_ptfs:
                min_ptfs = adjusted_ptfs
                candid_obj_key = obj_key

    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    '''
    obj_key = obj.key
    # Update PTFS
    predictive_cohesion = PREDICTIVE_COHESION_WEIGHT
    temporal_fusion = TEMPORAL_FUSION_WEIGHT
    contextual_modulation = CONTEXTUAL_MODULATION_WEIGHT
    metadata["ptfs"][obj_key] = metadata["ptfs"].get(obj_key, 0) + (
        predictive_cohesion + temporal_fusion + contextual_modulation
    )

    # Update latency gradient
    metadata["latency_gradients"][obj_key] = LATENCY_GRADIENT_NEUTRAL

    # Update sequential mapping index
    metadata["sequential_mapping_indices"][obj_key] = (
        metadata["sequential_mapping_indices"].get(obj_key, SEQUENTIAL_MAPPING_INDEX_START) + 1
    )

    # Update recursive cascade hierarchy
    for related_obj_key in metadata["cascade_hierarchy"].get(obj_key, set()):
        metadata["ptfs"][related_obj_key] = metadata["ptfs"].get(related_obj_key, 0) + predictive_cohesion

    # Update cluster composition
    for cluster_id, obj_keys in metadata["clusters"].items():
        if obj_key in obj_keys:
            obj_keys.remove(obj_key)
            obj_keys.append(obj_key)  # Move to the end to mark as recently accessed

    # Update access time
    metadata["access_times"][obj_key] = cache_snapshot.access_count

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    '''
    obj_key = obj.key
    # Initialize PTFS
    predictive_cohesion = PREDICTIVE_COHESION_WEIGHT
    contextual_modulation = CONTEXTUAL_MODULATION_WEIGHT
    metadata["ptfs"][obj_key] = predictive_cohesion + contextual_modulation

    # Assign to a dynamic cluster
    cluster_id = hash(obj_key) % len(metadata["clusters"]) if metadata["clusters"] else 0
    metadata["clusters"][cluster_id].append(obj_key)

    # Set latency gradient
    metadata["latency_gradients"][obj_key] = LATENCY_GRADIENT_NEUTRAL

    # Assign sequential mapping index
    metadata["sequential_mapping_indices"][obj_key] = SEQUENTIAL_MAPPING_INDEX_START

    # Update recursive cascade hierarchy
    metadata["cascade_hierarchy"][obj_key] = set()

    # Update access time
    metadata["access_times"][obj_key] = cache_snapshot.access_count

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    '''
    evicted_obj_key = evicted_obj.key
    # Recalibrate PTFS for remaining objects
    for obj_key in cache_snapshot.cache.keys():
        metadata["ptfs"][obj_key] = max(0, metadata["ptfs"].get(obj_key, 0) - CONTEXTUAL_MODULATION_WEIGHT)

    # Adjust predictive cohesion scores and contextual modulation weights
    for obj_key in cache_snapshot.cache.keys():
        metadata["ptfs"][obj_key] += PREDICTIVE_COHESION_WEIGHT

    # Update dynamic cluster composition
    for cluster_id, obj_keys in metadata["clusters"].items():
        if evicted_obj_key in obj_keys:
            obj_keys.remove(evicted_obj_key)

    # Prune recursive cascade hierarchy
    if evicted_obj_key in metadata["cascade_hierarchy"]:
        del metadata["cascade_hierarchy"][evicted_obj_key]
    for obj_key, related_keys in metadata["cascade_hierarchy"].items():
        if evicted_obj_key in related_keys:
            related_keys.remove(evicted_obj_key)

    # Rebalance sequential mapping indices
    for obj_key in cache_snapshot.cache.keys():
        metadata["sequential_mapping_indices"][obj_key] = (
            metadata["sequential_mapping_indices"].get(obj_key, SEQUENTIAL_MAPPING_INDEX_START) + 1
        )