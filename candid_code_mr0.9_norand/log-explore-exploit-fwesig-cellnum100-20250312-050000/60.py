# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.

# Put tunable constant parameters below
TEMPORAL_SCORE_WEIGHT = 1.0
PRIORITY_INVERSION_WEIGHT = 1.0
ACCESS_GRANULARITY_WEIGHT = 1.0
PREDICTIVE_EVICTION_WEIGHT = 1.0
FREQUENCY_COUNTER_WEIGHT = 1.0
LOAD_FACTOR_THRESHOLD = 0.8  # 80% of cache capacity

# Put the metadata specifically maintained by the policy below. The policy maintains a temporal score, priority inversion flag, access granularity counter, predictive eviction score, frequency counter, hashed index, traversal order list, and load factor threshold. It also tracks spillover prioritization and dynamically adjusts based on access patterns and cache load.
metadata = {
    "temporal_score": {},  # {key: score}
    "priority_inversion_flag": {},  # {key: bool}
    "access_granularity": {},  # {key: counter}
    "predictive_eviction_score": {},  # {key: score}
    "frequency_counter": {},  # {key: count}
    "hashed_index": {},  # {key: hash(key)}
    "traversal_order": [],  # [key1, key2, ...]
    "load_factor": 0.0,  # Current load factor
}

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy identifies eviction candidates by combining temporal score, priority inversion flag, access granularity, predictive eviction score, and frequency counter into a weighted formula. It prioritizes entries exceeding the load factor threshold and spillover entries based on their traversal order position. The final victim is chosen as the entry with the lowest combined score.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    min_score = float('inf')

    for key, cached_obj in cache_snapshot.cache.items():
        # Calculate the combined score for each cached object
        score = (
            TEMPORAL_SCORE_WEIGHT * metadata["temporal_score"].get(key, 0) +
            PRIORITY_INVERSION_WEIGHT * (1 if metadata["priority_inversion_flag"].get(key, False) else 0) +
            ACCESS_GRANULARITY_WEIGHT * metadata["access_granularity"].get(key, 0) +
            PREDICTIVE_EVICTION_WEIGHT * metadata["predictive_eviction_score"].get(key, 0) +
            FREQUENCY_COUNTER_WEIGHT * metadata["frequency_counter"].get(key, 0)
        )

        # Prioritize entries exceeding the load factor threshold
        if metadata["load_factor"] > LOAD_FACTOR_THRESHOLD:
            score += len(metadata["traversal_order"]) - metadata["traversal_order"].index(key)

        # Find the entry with the lowest combined score
        if score < min_score:
            min_score = score
            candid_obj_key = key

    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    On a cache hit, the temporal score is increased, the priority inversion flag is reset, the access granularity counter is updated, the predictive eviction score is recalculated, the frequency counter is incremented, and the entry's position in the traversal order list is updated to reflect recent access.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    key = obj.key
    metadata["temporal_score"][key] = metadata["temporal_score"].get(key, 0) + 1
    metadata["priority_inversion_flag"][key] = False
    metadata["access_granularity"][key] = obj.size
    metadata["predictive_eviction_score"][key] = obj.size / cache_snapshot.capacity
    metadata["frequency_counter"][key] = metadata["frequency_counter"].get(key, 0) + 1

    # Update traversal order
    if key in metadata["traversal_order"]:
        metadata["traversal_order"].remove(key)
    metadata["traversal_order"].append(key)

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the temporal score is initialized to a medium value, the priority inversion flag is set to false, the access granularity counter is initialized based on the object's size, the predictive eviction score is calculated, the frequency counter is set to 1, the hashed index is updated, the traversal order list is appended with the new entry, and the load factor is recalculated.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    key = obj.key
    metadata["temporal_score"][key] = 0.5
    metadata["priority_inversion_flag"][key] = False
    metadata["access_granularity"][key] = obj.size
    metadata["predictive_eviction_score"][key] = obj.size / cache_snapshot.capacity
    metadata["frequency_counter"][key] = 1
    metadata["hashed_index"][key] = hash(key)
    metadata["traversal_order"].append(key)
    metadata["load_factor"] = cache_snapshot.size / cache_snapshot.capacity

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    After eviction, the priority inversion flags of remaining entries are adjusted, the predictive eviction model is updated with the evicted object's metadata, the hashed index is updated to remove the evicted entry, the traversal order list is adjusted, and the load factor is recalculated to ensure balance and fairness.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    evicted_key = evicted_obj.key
    metadata["priority_inversion_flag"].pop(evicted_key, None)
    metadata["temporal_score"].pop(evicted_key, None)
    metadata["access_granularity"].pop(evicted_key, None)
    metadata["predictive_eviction_score"].pop(evicted_key, None)
    metadata["frequency_counter"].pop(evicted_key, None)
    metadata["hashed_index"].pop(evicted_key, None)
    metadata["traversal_order"].remove(evicted_key)
    metadata["load_factor"] = cache_snapshot.size / cache_snapshot.capacity