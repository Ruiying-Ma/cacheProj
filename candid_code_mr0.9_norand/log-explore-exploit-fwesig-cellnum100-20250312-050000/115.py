# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.

# Put tunable constant parameters below
HOT_TIER_THRESHOLD = 0.8  # Fraction of max frequency for hot tier promotion
WARM_TIER_THRESHOLD = 0.5  # Fraction of max frequency for warm tier promotion
NEUTRAL_ENTROPY = 0.5  # Default semantic entropy for new objects
LATENCY_DECAY = 0.9  # Factor to reduce latency on hit
CONTEXTUAL_THRESHOLD_ADJUSTMENT = 0.05  # Adjustment factor for contextual threshold

# Put the metadata specifically maintained by the policy below. The policy maintains metadata for cache alignment, access latency, storage stratification (hot, warm, cold tiers), probabilistic gradient scores, semantic entropy scores, an adaptive latency map, and a dynamic contextual threshold. It integrates sequential access patterns with workload trends to optimize cache behavior.
metadata = {
    "access_latency": {},  # Maps obj.key to its access latency
    "probabilistic_gradient_score": {},  # Maps obj.key to its gradient score
    "semantic_entropy": {},  # Maps obj.key to its semantic entropy
    "tier": {},  # Maps obj.key to its tier ('hot', 'warm', 'cold')
    "contextual_threshold": 1.0,  # Dynamic contextual threshold
    "alignment_metadata": {},  # Tracks sequential patterns (e.g., last accessed key)
}

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy selects the eviction victim by first identifying blocks in the cold tier with the lowest probabilistic gradient score. Among these, it prioritizes blocks with the highest semantic entropy and access latency, ensuring minimal disruption to sequential patterns and workload predictability.
    '''
    cold_tier_objects = [
        key for key, tier in metadata["tier"].items() if tier == "cold"
    ]
    if not cold_tier_objects:
        return None  # No cold tier objects to evict

    # Sort cold tier objects by gradient score (ascending), then by entropy (descending), then by latency (descending)
    cold_tier_objects.sort(
        key=lambda key: (
            metadata["probabilistic_gradient_score"].get(key, float("inf")),
            -metadata["semantic_entropy"].get(key, 0),
            -metadata["access_latency"].get(key, float("inf")),
        )
    )
    return cold_tier_objects[0]  # Return the key of the eviction candidate

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    '''
    key = obj.key

    # Update access latency to reflect reduced latency
    metadata["access_latency"][key] *= LATENCY_DECAY

    # Promote block to a hotter tier if its frequency increases
    max_frequency = max(metadata["probabilistic_gradient_score"].values(), default=1)
    if metadata["probabilistic_gradient_score"][key] >= HOT_TIER_THRESHOLD * max_frequency:
        metadata["tier"][key] = "hot"
    elif metadata["probabilistic_gradient_score"][key] >= WARM_TIER_THRESHOLD * max_frequency:
        metadata["tier"][key] = "warm"

    # Adjust alignment metadata for sequential patterns
    metadata["alignment_metadata"]["last_accessed"] = key

    # Increase probabilistic gradient score
    metadata["probabilistic_gradient_score"][key] += 1

    # Recalibrate contextual threshold
    metadata["contextual_threshold"] += CONTEXTUAL_THRESHOLD_ADJUSTMENT

    # Update semantic entropy score to reflect improved predictability
    metadata["semantic_entropy"][key] *= LATENCY_DECAY

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    '''
    key = obj.key

    # Initialize access latency and probabilistic gradient score
    metadata["access_latency"][key] = cache_snapshot.access_count
    metadata["probabilistic_gradient_score"][key] = 1

    # Assign to the cold tier
    metadata["tier"][key] = "cold"

    # Evaluate alignment with sequential patterns for potential promotion
    last_accessed = metadata["alignment_metadata"].get("last_accessed")
    if last_accessed and last_accessed == key:
        metadata["tier"][key] = "warm"

    # Set semantic entropy to a neutral value
    metadata["semantic_entropy"][key] = NEUTRAL_ENTROPY

    # Adjust the contextual threshold to account for the new object
    metadata["contextual_threshold"] -= CONTEXTUAL_THRESHOLD_ADJUSTMENT

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    '''
    evicted_key = evicted_obj.key

    # Recalibrate stratification thresholds for hot, warm, and cold tiers
    max_frequency = max(metadata["probabilistic_gradient_score"].values(), default=1)
    for key in metadata["tier"]:
        if metadata["probabilistic_gradient_score"][key] >= HOT_TIER_THRESHOLD * max_frequency:
            metadata["tier"][key] = "hot"
        elif metadata["probabilistic_gradient_score"][key] >= WARM_TIER_THRESHOLD * max_frequency:
            metadata["tier"][key] = "warm"
        else:
            metadata["tier"][key] = "cold"

    # Adjust alignment metadata for remaining blocks
    if metadata["alignment_metadata"].get("last_accessed") == evicted_key:
        metadata["alignment_metadata"]["last_accessed"] = None

    # Remove the evicted block from the adaptive latency map
    metadata["access_latency"].pop(evicted_key, None)

    # Recalibrate the contextual threshold
    metadata["contextual_threshold"] += CONTEXTUAL_THRESHOLD_ADJUSTMENT

    # Slightly adjust semantic entropy scores of remaining objects
    for key in metadata["semantic_entropy"]:
        metadata["semantic_entropy"][key] *= LATENCY_DECAY