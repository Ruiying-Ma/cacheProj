# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
import math

# Put tunable constant parameters below
PRIORITY_WEIGHT = 0.4
DATA_LOCALITY_WEIGHT = 0.2
BURST_BUFFERING_WEIGHT = 0.1
SEMANTIC_DRIFT_WEIGHT = 0.1
LATENCY_PROFILE_WEIGHT = 0.1
PREDICTED_ACCESS_WEIGHT = 0.1

# Put the metadata specifically maintained by the policy below. The policy maintains metadata for cache alignment, priority levels, data locality, burst buffering, a Bloom filter for recent keys, semantic drift scores, latency profiles, and a predictive model for future access patterns. It also tracks a combined relevance score for each object based on these factors.
metadata = {
    "priority_levels": {},  # Maps obj.key to its priority level
    "data_locality": {},  # Maps obj.key to a set of related keys
    "burst_buffering": {},  # Maps obj.key to burst buffering metadata
    "bloom_filter": set(),  # A set of recently accessed keys
    "semantic_drift_scores": {},  # Maps obj.key to its semantic drift score
    "latency_profiles": {},  # Maps obj.key to its latency profile
    "predicted_access": {},  # Maps obj.key to predicted future access probability
}

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy calculates a composite eviction score for each cache line using a weighted combination of priority level, data locality, burst buffering, semantic drift score, latency profile, and predicted future access probability. The cache line with the lowest composite score is chosen for eviction, ensuring minimal disruption to both short-term and long-term cache efficiency.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    min_score = float('inf')

    for key, cached_obj in cache_snapshot.cache.items():
        # Calculate composite eviction score
        priority_score = metadata["priority_levels"].get(key, 0)
        locality_score = len(metadata["data_locality"].get(key, set()))
        burst_score = metadata["burst_buffering"].get(key, 0)
        drift_score = metadata["semantic_drift_scores"].get(key, 0)
        latency_score = metadata["latency_profiles"].get(key, 0)
        predicted_score = metadata["predicted_access"].get(key, 0)

        composite_score = (
            PRIORITY_WEIGHT * priority_score +
            DATA_LOCALITY_WEIGHT * locality_score +
            BURST_BUFFERING_WEIGHT * burst_score +
            SEMANTIC_DRIFT_WEIGHT * drift_score +
            LATENCY_PROFILE_WEIGHT * latency_score +
            PREDICTED_ACCESS_WEIGHT * predicted_score
        )

        # Find the object with the lowest composite score
        if composite_score < min_score:
            min_score = composite_score
            candid_obj_key = key

    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    On a cache hit, the policy increases the priority level of the accessed line, updates data locality relationships, adjusts burst buffering metadata, reinforces the Bloom filter for the accessed key, recalibrates the semantic drift score, and updates the predictive model to refine future access forecasts.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    key = obj.key
    # Increase priority level
    metadata["priority_levels"][key] = metadata["priority_levels"].get(key, 0) + 1
    # Update data locality relationships
    for other_key in cache_snapshot.cache:
        if other_key != key:
            metadata["data_locality"].setdefault(key, set()).add(other_key)
    # Adjust burst buffering metadata
    metadata["burst_buffering"][key] = metadata["burst_buffering"].get(key, 0) + 1
    # Reinforce the Bloom filter
    metadata["bloom_filter"].add(key)
    # Recalibrate semantic drift score
    metadata["semantic_drift_scores"][key] = max(0, metadata["semantic_drift_scores"].get(key, 0) - 1)
    # Update predictive model
    metadata["predicted_access"][key] = metadata["predicted_access"].get(key, 0) + 0.1

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the policy aligns it to the nearest memory block boundary, assigns a default priority level, updates data locality metadata, initializes burst buffering metadata, adds the key to the Bloom filter, initializes the semantic drift score, sets the latency profile, and updates the predictive model to reflect the new cache state.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    key = obj.key
    # Assign default priority level
    metadata["priority_levels"][key] = 1
    # Update data locality metadata
    metadata["data_locality"][key] = set()
    # Initialize burst buffering metadata
    metadata["burst_buffering"][key] = 0
    # Add the key to the Bloom filter
    metadata["bloom_filter"].add(key)
    # Initialize semantic drift score
    metadata["semantic_drift_scores"][key] = 0
    # Set latency profile
    metadata["latency_profiles"][key] = 0
    # Update predictive model
    metadata["predicted_access"][key] = 0.5

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    After eviction, the policy recalibrates priority levels of remaining cache lines, removes the evicted line from data locality relationships, adjusts burst buffering metadata, removes the evicted key from the Bloom filter, updates semantic drift scores of remaining objects, adjusts latency profiles, and retrains the predictive model to adapt to the new cache composition.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    evicted_key = evicted_obj.key
    # Recalibrate priority levels
    for key in metadata["priority_levels"]:
        metadata["priority_levels"][key] = max(0, metadata["priority_levels"][key] - 1)
    # Remove the evicted line from data locality relationships
    metadata["data_locality"].pop(evicted_key, None)
    for key in metadata["data_locality"]:
        metadata["data_locality"][key].discard(evicted_key)
    # Adjust burst buffering metadata
    metadata["burst_buffering"].pop(evicted_key, None)
    # Remove the evicted key from the Bloom filter
    metadata["bloom_filter"].discard(evicted_key)
    # Update semantic drift scores of remaining objects
    for key in metadata["semantic_drift_scores"]:
        metadata["semantic_drift_scores"][key] += 1
    # Adjust latency profiles
    metadata["latency_profiles"].pop(evicted_key, None)
    # Retrain the predictive model
    metadata["predicted_access"].pop(evicted_key, None)