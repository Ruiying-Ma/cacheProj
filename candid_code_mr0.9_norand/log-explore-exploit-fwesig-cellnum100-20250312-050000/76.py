# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
import numpy as np
from collections import defaultdict
from scipy.stats import entropy

# Put tunable constant parameters below
GRADIENT_DECAY = 0.9  # Decay factor for gradient updates
ENTROPY_THRESHOLD = 0.1  # Threshold for entropy collapse detection

# Put the metadata specifically maintained by the policy below. The policy maintains a gradient map for each cache object, representing its access frequency trend over time, a predictive regression model to forecast future access probabilities, an entropy score to measure access unpredictability, and dynamic partitions to group objects with similar access patterns.
gradient_map = defaultdict(lambda: 0)  # Tracks access frequency trends for each object
regression_model = {}  # Maps object keys to predicted future access probabilities
partitions = defaultdict(list)  # Groups objects into dynamic partitions
partition_entropy = {}  # Tracks entropy scores for each partition

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy selects the eviction victim by identifying the object with the lowest predicted future access probability (from the regression model) within the partition that has the highest entropy collapse, ensuring adaptability to changing access patterns.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    # Identify the partition with the highest entropy collapse
    max_entropy_partition = max(partition_entropy, key=partition_entropy.get, default=None)
    if max_entropy_partition is not None:
        # Within the partition, find the object with the lowest predicted future access probability
        min_prob = float('inf')
        for obj_key in partitions[max_entropy_partition]:
            if obj_key in regression_model and regression_model[obj_key] < min_prob:
                min_prob = regression_model[obj_key]
                candid_obj_key = obj_key
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    Upon a cache hit, the gradient map for the accessed object is updated to reflect the new access trend, the regression model is retrained with the latest access data, and the entropy score of the corresponding partition is recalculated.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    # Update the gradient map for the accessed object
    gradient_map[obj.key] = GRADIENT_DECAY * gradient_map[obj.key] + 1

    # Update the regression model for the accessed object
    regression_model[obj.key] = gradient_map[obj.key] / cache_snapshot.access_count

    # Recalculate the entropy score for the partition the object belongs to
    for partition, obj_keys in partitions.items():
        if obj.key in obj_keys:
            access_probs = [regression_model[key] for key in obj_keys if key in regression_model]
            partition_entropy[partition] = entropy(access_probs)
            break

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the gradient map is initialized for the object, the regression model is updated to include the new object, and the object is assigned to a dynamic partition based on its initial access pattern.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    # Initialize the gradient map for the new object
    gradient_map[obj.key] = 1

    # Update the regression model for the new object
    regression_model[obj.key] = gradient_map[obj.key] / cache_snapshot.access_count

    # Assign the object to a dynamic partition based on its initial access pattern
    # For simplicity, assign to a new partition if no suitable partition exists
    assigned_partition = None
    for partition, obj_keys in partitions.items():
        if len(obj_keys) > 0:
            # Check similarity in access patterns (e.g., based on gradient values)
            avg_gradient = np.mean([gradient_map[key] for key in obj_keys])
            if abs(avg_gradient - gradient_map[obj.key]) < ENTROPY_THRESHOLD:
                assigned_partition = partition
                break
    if assigned_partition is None:
        assigned_partition = len(partitions) + 1
    partitions[assigned_partition].append(obj.key)

    # Recalculate the entropy score for the assigned partition
    access_probs = [regression_model[key] for key in partitions[assigned_partition] if key in regression_model]
    partition_entropy[assigned_partition] = entropy(access_probs)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    After evicting an object, its gradient map is removed, the regression model is updated to exclude the object, and the entropy score of the partition it belonged to is recalculated to reflect the removal.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    # Remove the gradient map for the evicted object
    if evicted_obj.key in gradient_map:
        del gradient_map[evicted_obj.key]

    # Remove the evicted object from the regression model
    if evicted_obj.key in regression_model:
        del regression_model[evicted_obj.key]

    # Remove the evicted object from its partition and recalculate entropy
    for partition, obj_keys in partitions.items():
        if evicted_obj.key in obj_keys:
            obj_keys.remove(evicted_obj.key)
            if len(obj_keys) > 0:
                access_probs = [regression_model[key] for key in obj_keys if key in regression_model]
                partition_entropy[partition] = entropy(access_probs)
            else:
                del partition_entropy[partition]
            break