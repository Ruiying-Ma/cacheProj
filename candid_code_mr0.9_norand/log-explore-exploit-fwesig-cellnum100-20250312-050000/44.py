# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.

# Put tunable constant parameters below
DEFAULT_LATENCY_SCORE = 100
DEFAULT_PREDICTIVE_SCORE = 50
ALIGNMENT_BASE = 16  # Assume alignment is based on 16-byte boundaries

# Put the metadata specifically maintained by the policy below. The policy maintains metadata for each cache line, including alignment score (based on cache alignment), latency score (based on access latency thresholds), stratification level (categorizing data into hot, warm, and cold tiers), and a predictive score (based on access patterns and heuristics).
metadata = {}

def calculate_alignment_score(obj):
    """Calculate alignment score based on the object's key hash."""
    return hash(obj.key) % ALIGNMENT_BASE

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy chooses the eviction victim by first selecting the lowest stratification level (cold tier), then within that tier, the cache line with the lowest combined alignment and predictive scores, and finally breaking ties using the highest latency score.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    min_stratification = float('inf')
    min_combined_score = float('inf')
    max_latency_score = float('-inf')

    for key, cached_obj in cache_snapshot.cache.items():
        obj_metadata = metadata[key]
        stratification = obj_metadata['stratification']
        alignment_score = obj_metadata['alignment_score']
        predictive_score = obj_metadata['predictive_score']
        latency_score = obj_metadata['latency_score']
        combined_score = alignment_score + predictive_score

        # Select based on stratification level
        if stratification < min_stratification:
            min_stratification = stratification
            min_combined_score = combined_score
            max_latency_score = latency_score
            candid_obj_key = key
        # If stratification is the same, select based on combined score
        elif stratification == min_stratification:
            if combined_score < min_combined_score:
                min_combined_score = combined_score
                max_latency_score = latency_score
                candid_obj_key = key
            # If combined score is the same, select based on latency score
            elif combined_score == min_combined_score:
                if latency_score > max_latency_score:
                    max_latency_score = latency_score
                    candid_obj_key = key

    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    On a cache hit, the stratification level of the accessed line is promoted (e.g., cold to warm, warm to hot), the alignment score is recalculated based on recent access patterns, and the predictive score is updated using a lightweight heuristic model to anticipate future accesses.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    obj_metadata = metadata[obj.key]

    # Promote stratification level
    obj_metadata['stratification'] = min(obj_metadata['stratification'] + 1, 2)  # Max level is hot (2)

    # Recalculate alignment score
    obj_metadata['alignment_score'] = calculate_alignment_score(obj)

    # Update predictive score (lightweight heuristic: increase by 10)
    obj_metadata['predictive_score'] += 10

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the policy initializes its stratification level to cold, calculates its alignment score based on its memory address, sets its latency score to a default threshold, and assigns an initial predictive score based on the insertion context (e.g., sequential or random access).
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    metadata[obj.key] = {
        'stratification': 0,  # Cold tier
        'alignment_score': calculate_alignment_score(obj),
        'latency_score': DEFAULT_LATENCY_SCORE,
        'predictive_score': DEFAULT_PREDICTIVE_SCORE
    }

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    After evicting a cache line, the policy adjusts the stratification thresholds dynamically based on the current cache usage, recalibrates the predictive model using the evicted line's metadata, and updates alignment scoring parameters to better reflect recent access patterns.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    evicted_metadata = metadata.pop(evicted_obj.key, None)

    # Adjust stratification thresholds dynamically (e.g., based on cache usage)
    cache_usage_ratio = cache_snapshot.size / cache_snapshot.capacity
    if cache_usage_ratio > 0.8:
        # If cache is heavily used, lower thresholds for promotion
        for key in metadata:
            metadata[key]['stratification'] = max(metadata[key]['stratification'] - 1, 0)
    elif cache_usage_ratio < 0.5:
        # If cache is lightly used, increase thresholds for promotion
        for key in metadata:
            metadata[key]['stratification'] = min(metadata[key]['stratification'] + 1, 2)

    # Recalibrate predictive model using evicted line's metadata
    if evicted_metadata:
        for key in metadata:
            metadata[key]['predictive_score'] = max(metadata[key]['predictive_score'] - 5, 0)

    # Update alignment scoring parameters (e.g., based on recent patterns)
    for key in metadata:
        metadata[key]['alignment_score'] = calculate_alignment_score(cache_snapshot.cache[key])