# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.

# Put tunable constant parameters below
PROB_GRADIENT_INCREMENT = 0.1  # Increment for probabilistic gradient score on hit
SEMANTIC_ENTROPY_ADJUSTMENT = 0.05  # Adjustment for semantic entropy on hit
INITIAL_PROB_GRADIENT = 1.0  # Initial probabilistic gradient score for new objects
INITIAL_LATENCY = 1.0  # Initial latency for new objects
NEUTRAL_ENTROPY = 0.5  # Neutral semantic entropy for new objects
THRESHOLD_ADJUSTMENT = 0.01  # Adjustment for contextual threshold

# Put the metadata specifically maintained by the policy below. The policy maintains a probabilistic gradient score for each cache object, a contextual threshold value that adapts based on workload patterns, an adaptive latency map to track access latency trends, and a semantic entropy score to measure the unpredictability of access patterns for each object.
probabilistic_gradient = {}  # Maps object keys to their probabilistic gradient scores
adaptive_latency = {}  # Maps object keys to their adaptive latency
semantic_entropy = {}  # Maps object keys to their semantic entropy scores
contextual_threshold = NEUTRAL_ENTROPY  # Initial contextual threshold

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy selects the eviction victim by identifying objects with the lowest probabilistic gradient score, provided their semantic entropy is below the contextual threshold. If multiple candidates exist, the object with the highest adaptive latency is evicted.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    # Your code below
    candidates = [
        key for key, cached_obj in cache_snapshot.cache.items()
        if semantic_entropy[key] < contextual_threshold
    ]
    if not candidates:
        # If no candidates meet the threshold, fallback to all objects
        candidates = list(cache_snapshot.cache.keys())

    # Find the candidate with the lowest probabilistic gradient score
    min_gradient = min(probabilistic_gradient[key] for key in candidates)
    min_gradient_candidates = [
        key for key in candidates if probabilistic_gradient[key] == min_gradient
    ]

    # Among those, find the one with the highest adaptive latency
    candid_obj_key = max(
        min_gradient_candidates, key=lambda key: adaptive_latency[key]
    )
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    On a cache hit, the probabilistic gradient score of the accessed object is increased slightly, the contextual threshold is recalibrated based on recent access patterns, the adaptive latency map is updated to reflect reduced latency for the object, and the semantic entropy score is adjusted to reflect the predictability of the access.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    # Your code below
    key = obj.key
    probabilistic_gradient[key] += PROB_GRADIENT_INCREMENT
    adaptive_latency[key] = max(0, adaptive_latency[key] - 1)  # Reduce latency
    semantic_entropy[key] = max(0, semantic_entropy[key] - SEMANTIC_ENTROPY_ADJUSTMENT)
    global contextual_threshold
    contextual_threshold = max(
        NEUTRAL_ENTROPY,
        contextual_threshold - THRESHOLD_ADJUSTMENT
    )

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, its probabilistic gradient score is initialized based on recent workload trends, the contextual threshold is adjusted to account for the new object, the adaptive latency map is updated to include the object's initial latency, and its semantic entropy score is set to a neutral value.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    # Your code below
    key = obj.key
    probabilistic_gradient[key] = INITIAL_PROB_GRADIENT
    adaptive_latency[key] = INITIAL_LATENCY
    semantic_entropy[key] = NEUTRAL_ENTROPY
    global contextual_threshold
    contextual_threshold = min(
        1.0, contextual_threshold + THRESHOLD_ADJUSTMENT
    )

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    After evicting an object, the contextual threshold is recalibrated to reflect the reduced cache size, the adaptive latency map is updated to remove the evicted object, and the semantic entropy scores of remaining objects are slightly adjusted to account for the change in cache dynamics.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    # Your code below
    evicted_key = evicted_obj.key
    probabilistic_gradient.pop(evicted_key, None)
    adaptive_latency.pop(evicted_key, None)
    semantic_entropy.pop(evicted_key, None)
    global contextual_threshold
    contextual_threshold = max(
        NEUTRAL_ENTROPY,
        contextual_threshold - THRESHOLD_ADJUSTMENT
    )
    for key in semantic_entropy:
        semantic_entropy[key] = min(
            1.0, semantic_entropy[key] + SEMANTIC_ENTROPY_ADJUSTMENT
        )