# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
from collections import defaultdict

# Put tunable constant parameters below
DEFAULT_SCORE = 1.0
DEFAULT_LATENCY = 1.0
DEFAULT_ENTROPY = 0.5
LOAD_PRESSURE_THRESHOLD = 0.8

# Put the metadata specifically maintained by the policy below. The policy maintains a unified heuristic-probabilistic score for each object, a hybrid predictive-contextual map for access patterns, a quantum-adaptive latency tracker for synchronization and trends, a semantic entropy index for unpredictability, and a dynamic load-pressure threshold to balance cache resources.
metadata = {
    "scores": defaultdict(lambda: DEFAULT_SCORE),  # Unified heuristic-probabilistic scores
    "access_patterns": defaultdict(list),  # Hybrid predictive-contextual map
    "latencies": defaultdict(lambda: DEFAULT_LATENCY),  # Quantum-adaptive latency tracker
    "entropies": defaultdict(lambda: DEFAULT_ENTROPY),  # Semantic entropy index
    "load_pressure_threshold": LOAD_PRESSURE_THRESHOLD,  # Dynamic load-pressure threshold
}

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy selects the eviction victim by combining the lowest unified heuristic-probabilistic score with the hybrid predictive-contextual map to identify objects with low future access probability. If multiple candidates exist, the object with the highest quantum-adaptive latency and semantic entropy below the dynamic load-pressure threshold is evicted.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    min_score = float('inf')
    candidates = []

    # Step 1: Identify objects with the lowest unified heuristic-probabilistic score
    for key, cached_obj in cache_snapshot.cache.items():
        score = metadata["scores"][key]
        if score < min_score:
            min_score = score
            candidates = [key]
        elif score == min_score:
            candidates.append(key)

    # Step 2: Among candidates, select the one with the highest latency and entropy below the load-pressure threshold
    max_combined_metric = -float('inf')
    for key in candidates:
        latency = metadata["latencies"][key]
        entropy = metadata["entropies"][key]
        if entropy < metadata["load_pressure_threshold"]:
            combined_metric = latency + entropy
            if combined_metric > max_combined_metric:
                max_combined_metric = combined_metric
                candid_obj_key = key

    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    On a cache hit, the unified heuristic-probabilistic score is incrementally adjusted based on recent access patterns, the hybrid predictive-contextual map is refined to improve future predictions, the quantum-adaptive latency tracker is updated to reflect reduced latency, the semantic entropy index is recalibrated to reflect improved predictability, and the dynamic load-pressure threshold is adjusted to balance cache pressure.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    key = obj.key

    # Incrementally adjust the unified heuristic-probabilistic score
    metadata["scores"][key] += 1

    # Refine the hybrid predictive-contextual map
    metadata["access_patterns"][key].append(cache_snapshot.access_count)

    # Update the quantum-adaptive latency tracker
    metadata["latencies"][key] *= 0.9  # Reduce latency to reflect improved access time

    # Recalibrate the semantic entropy index
    metadata["entropies"][key] *= 0.9  # Reduce entropy to reflect improved predictability

    # Adjust the dynamic load-pressure threshold
    metadata["load_pressure_threshold"] = min(
        1.0, cache_snapshot.size / cache_snapshot.capacity
    )

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the unified heuristic-probabilistic score is initialized based on predicted access frequency and workload trends, the hybrid predictive-contextual map is updated to include the new object, the quantum-adaptive latency tracker is initialized with the object's initial latency, the semantic entropy index is set to a neutral value, and the dynamic load-pressure threshold is recalibrated to reflect the updated cache state.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    key = obj.key

    # Initialize the unified heuristic-probabilistic score
    metadata["scores"][key] = DEFAULT_SCORE

    # Update the hybrid predictive-contextual map
    metadata["access_patterns"][key] = [cache_snapshot.access_count]

    # Initialize the quantum-adaptive latency tracker
    metadata["latencies"][key] = DEFAULT_LATENCY

    # Set the semantic entropy index to a neutral value
    metadata["entropies"][key] = DEFAULT_ENTROPY

    # Recalibrate the dynamic load-pressure threshold
    metadata["load_pressure_threshold"] = min(
        1.0, cache_snapshot.size / cache_snapshot.capacity
    )

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    After eviction, the hybrid predictive-contextual map is pruned to remove references to the evicted object, the quantum-adaptive latency tracker is recalibrated to account for the reduced cache size, the semantic entropy index of remaining objects is slightly adjusted to reflect the change in cache dynamics, and the dynamic load-pressure threshold is updated to ensure even resource distribution.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    evicted_key = evicted_obj.key

    # Prune the hybrid predictive-contextual map
    if evicted_key in metadata["access_patterns"]:
        del metadata["access_patterns"][evicted_key]

    # Recalibrate the quantum-adaptive latency tracker
    if evicted_key in metadata["latencies"]:
        del metadata["latencies"][evicted_key]

    # Adjust the semantic entropy index of remaining objects
    for key in metadata["entropies"]:
        metadata["entropies"][key] *= 1.05  # Slightly increase entropy to reflect change

    # Update the dynamic load-pressure threshold
    metadata["load_pressure_threshold"] = min(
        1.0, cache_snapshot.size / cache_snapshot.capacity
    )