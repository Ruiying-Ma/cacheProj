# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
from collections import deque, defaultdict
import math

# Put tunable constant parameters below
DEFAULT_PRIORITY_TAG = 1
DEFAULT_TEMPORAL_ACCESS_SCORE = 0
DEFAULT_ACCESS_LATENCY = 0
DEFAULT_SEMANTIC_DRIFT_SCORE = 0
DEFAULT_LATENCY_PROFILE = 1
DEFAULT_PREDICTIVE_FETCH_SCORE = 0
COHERENCY_SENSITIVE_WEIGHT = 10
COMBINED_SCORE_WEIGHTS = {
    "priority_tag": 1,
    "semantic_drift_score": 1,
    "latency_profile": 1,
    "temporal_access_score": 1,
    "predictive_fetch_score": 1,
}

# Put the metadata specifically maintained by the policy below. The policy maintains a rotation index, hierarchical tags for grouping related entries, access latency counters, temporal access scores, priority tags, predictive fetch scores, a sequential eviction queue, a Bloom filter for recently accessed keys, semantic drift scores, latency profiles, coherency flags, and a predictive model for future access patterns.
rotation_index = 0
hierarchical_tags = defaultdict(set)  # Maps group tags to sets of object keys
access_latency_counters = defaultdict(int)
temporal_access_scores = defaultdict(int)
priority_tags = defaultdict(lambda: DEFAULT_PRIORITY_TAG)
predictive_fetch_scores = defaultdict(lambda: DEFAULT_PREDICTIVE_FETCH_SCORE)
sequential_eviction_queue = deque()
bloom_filter = set()
semantic_drift_scores = defaultdict(lambda: DEFAULT_SEMANTIC_DRIFT_SCORE)
latency_profiles = defaultdict(lambda: DEFAULT_LATENCY_PROFILE)
coherency_flags = defaultdict(bool)
predictive_model = {}  # Placeholder for predictive model metadata

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    '''
    global rotation_index

    # Identify the least likely group to be accessed soon
    group_scores = {}
    for group, keys in hierarchical_tags.items():
        group_scores[group] = sum(predictive_fetch_scores[key] for key in keys) / (len(keys) or 1)
    least_likely_group = min(group_scores, key=group_scores.get, default=None)

    # Calculate combined scores for entries in the group
    candidates = hierarchical_tags.get(least_likely_group, cache_snapshot.cache.keys())
    combined_scores = {}
    for key in candidates:
        combined_scores[key] = (
            COMBINED_SCORE_WEIGHTS["priority_tag"] * priority_tags[key] +
            COMBINED_SCORE_WEIGHTS["semantic_drift_score"] * semantic_drift_scores[key] +
            COMBINED_SCORE_WEIGHTS["latency_profile"] * latency_profiles[key] +
            COMBINED_SCORE_WEIGHTS["temporal_access_score"] * temporal_access_scores[key] +
            COMBINED_SCORE_WEIGHTS["predictive_fetch_score"] * predictive_fetch_scores[key]
        )
        if coherency_flags[key]:
            combined_scores[key] += COHERENCY_SENSITIVE_WEIGHT

    # Find the entry with the lowest combined score
    min_score = math.inf
    candid_obj_key = None
    for key, score in combined_scores.items():
        if score < min_score or (score == min_score and sequential_eviction_queue.index(key) < sequential_eviction_queue.index(candid_obj_key)):
            min_score = score
            candid_obj_key = key

    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    '''
    key = obj.key

    # Reset and increment access latency counter and temporal access score
    access_latency_counters[key] = 0
    temporal_access_scores[key] += 1

    # Increment priority tag
    priority_tags[key] += 1

    # Update predictive fetch score
    predictive_fetch_scores[key] = temporal_access_scores[key] / (cache_snapshot.access_count or 1)

    # Reinforce hierarchical tag as active
    for group, keys in hierarchical_tags.items():
        if key in keys:
            hierarchical_tags[group].add(key)

    # Move to the end of the sequential eviction queue
    if key in sequential_eviction_queue:
        sequential_eviction_queue.remove(key)
    sequential_eviction_queue.append(key)

    # Update Bloom filter
    bloom_filter.add(key)

    # Recalibrate semantic drift score
    semantic_drift_scores[key] = abs(temporal_access_scores[key] - priority_tags[key])

    # Adjust latency profile
    latency_profiles[key] = access_latency_counters[key] + 1

    # Check and update coherency flag
    coherency_flags[key] = True

    # Update predictive model (placeholder logic)
    predictive_model[key] = predictive_fetch_scores[key]

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    '''
    global rotation_index
    key = obj.key

    # Update rotation index
    rotation_index = (rotation_index + 1) % len(cache_snapshot.cache)

    # Assign default priority tag
    priority_tags[key] = DEFAULT_PRIORITY_TAG

    # Initialize access latency counter and temporal access score
    access_latency_counters[key] = DEFAULT_ACCESS_LATENCY
    temporal_access_scores[key] = DEFAULT_TEMPORAL_ACCESS_SCORE

    # Calculate predictive fetch score
    predictive_fetch_scores[key] = DEFAULT_PREDICTIVE_FETCH_SCORE

    # Add to the end of the sequential eviction queue
    sequential_eviction_queue.append(key)

    # Update Bloom filter
    bloom_filter.add(key)

    # Initialize semantic drift score
    semantic_drift_scores[key] = DEFAULT_SEMANTIC_DRIFT_SCORE

    # Update latency profile and predictive model
    latency_profiles[key] = DEFAULT_LATENCY_PROFILE
    predictive_model[key] = predictive_fetch_scores[key]

    # Set hierarchical tag
    hierarchical_tags["default"].add(key)

    # Set coherency flag
    coherency_flags[key] = False

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    '''
    global rotation_index
    evicted_key = evicted_obj.key

    # Skip to the next block in the rotation index
    rotation_index = (rotation_index + 1) % len(cache_snapshot.cache)

    # Clear evicted block's metadata
    access_latency_counters.pop(evicted_key, None)
    temporal_access_scores.pop(evicted_key, None)
    priority_tags.pop(evicted_key, None)
    predictive_fetch_scores.pop(evicted_key, None)
    semantic_drift_scores.pop(evicted_key, None)
    latency_profiles.pop(evicted_key, None)
    coherency_flags.pop(evicted_key, None)

    # Update sequential eviction queue
    if evicted_key in sequential_eviction_queue:
        sequential_eviction_queue.remove(evicted_key)

    # Update Bloom filter
    bloom_filter.discard(evicted_key)

    # Adjust semantic drift scores and predictive fetch scores of related entries
    for key in cache_snapshot.cache.keys():
        semantic_drift_scores[key] = abs(temporal_access_scores[key] - priority_tags[key])
        predictive_fetch_scores[key] = temporal_access_scores[key] / (cache_snapshot.access_count or 1)

    # Deprioritize hierarchical tag of the evicted group if underutilized
    for group, keys in hierarchical_tags.items():
        if evicted_key in keys:
            keys.remove(evicted_key)
            if not keys:
                hierarchical_tags.pop(group)

    # Recalibrate latency profile
    for key in cache_snapshot.cache.keys():
        latency_profiles[key] = access_latency_counters[key] + 1

    # Clear coherency flag
    coherency_flags[evicted_key] = False

    # Retrain predictive model (placeholder logic)
    predictive_model.pop(evicted_key, None)