# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
import collections
import time

# Put tunable constant parameters below
WEIGHT_ACCESS_FREQUENCY = 1.0
WEIGHT_RECENCY = 1.0
WEIGHT_INSERTION_TIME = 1.0
WEIGHT_LOCALITY_SCORE = 1.0
WEIGHT_PRIORITY_SCORE = 1.0
WEIGHT_CONNECTION_SCORE = 1.0

# Put the metadata specifically maintained by the policy below. The policy maintains access frequency, recency timestamp, insertion time, locality score, priority score, connection score, and a graph with nodes and edges representing cached items and access patterns. It also uses FIFO and LRU queues for organization.
metadata = {
    'access_frequency': collections.defaultdict(int),
    'recency_timestamp': {},
    'insertion_time': {},
    'locality_score': {},
    'priority_score': {},
    'connection_score': {},
    'graph': collections.defaultdict(set),
    'fifo_queue': collections.deque(),
    'lru_queue': collections.OrderedDict()
}

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy selects the eviction victim based on a combined weighted score of access frequency, recency, insertion time, locality score, priority score, and connection score. If multiple objects have the same score, the least recently accessed object is evicted. The policy also considers the queue structure, evicting from SQ or T2 as necessary.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    min_score = float('inf')
    
    for key, cached_obj in cache_snapshot.cache.items():
        score = (
            WEIGHT_ACCESS_FREQUENCY * metadata['access_frequency'][key] +
            WEIGHT_RECENCY * (cache_snapshot.access_count - metadata['recency_timestamp'][key]) +
            WEIGHT_INSERTION_TIME * (cache_snapshot.access_count - metadata['insertion_time'][key]) +
            WEIGHT_LOCALITY_SCORE * metadata['locality_score'][key] +
            WEIGHT_PRIORITY_SCORE * metadata['priority_score'][key] +
            WEIGHT_CONNECTION_SCORE * metadata['connection_score'][key]
        )
        
        if score < min_score or (score == min_score and metadata['recency_timestamp'][key] < metadata['recency_timestamp'][candid_obj_key]):
            min_score = score
            candid_obj_key = key
    
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    Upon a cache hit, the policy increments the access frequency, updates the recency timestamp, adjusts the locality score based on the accessing node's proximity, recalculates the priority score, and updates the connection score. The object may be moved to a higher priority queue or level based on its new scores.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    key = obj.key
    metadata['access_frequency'][key] += 1
    metadata['recency_timestamp'][key] = cache_snapshot.access_count
    # Update locality score, priority score, and connection score as needed
    # For simplicity, we assume these scores are updated based on some predefined logic
    metadata['locality_score'][key] += 1
    metadata['priority_score'][key] += 1
    metadata['connection_score'][key] += 1
    # Move the object to the end of the LRU queue
    if key in metadata['lru_queue']:
        metadata['lru_queue'].move_to_end(key)

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the policy sets the initial access frequency to 1, records the current time as the insertion time, sets the recency timestamp to the current time, calculates the initial locality score, sets the initial priority score, and initializes the connection score. The object is placed in the appropriate queue and level, and a new node is added to the graph.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    key = obj.key
    metadata['access_frequency'][key] = 1
    metadata['recency_timestamp'][key] = cache_snapshot.access_count
    metadata['insertion_time'][key] = cache_snapshot.access_count
    metadata['locality_score'][key] = 1
    metadata['priority_score'][key] = 1
    metadata['connection_score'][key] = 1
    metadata['fifo_queue'].append(key)
    metadata['lru_queue'][key] = obj
    metadata['graph'][key] = set()

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    After evicting an object, the policy removes all associated metadata, updates the graph by removing the corresponding node and edges, and recalculates the connection scores of remaining nodes. The locality and priority scores of remaining objects are also recalculated to ensure a balanced eviction strategy.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    key = evicted_obj.key
    del metadata['access_frequency'][key]
    del metadata['recency_timestamp'][key]
    del metadata['insertion_time'][key]
    del metadata['locality_score'][key]
    del metadata['priority_score'][key]
    del metadata['connection_score'][key]
    del metadata['lru_queue'][key]
    metadata['fifo_queue'].remove(key)
    del metadata['graph'][key]
    for k in metadata['graph']:
        metadata['graph'][k].discard(key)
    # Recalculate connection scores and other scores as needed
    for k in metadata['graph']:
        metadata['connection_score'][k] = len(metadata['graph'][k])
        # Update locality and priority scores based on some predefined logic
        metadata['locality_score'][k] = len(metadata['graph'][k])
        metadata['priority_score'][k] = len(metadata['graph'][k])