# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
import collections
import time

# Put tunable constant parameters below
WEIGHT_ACCESS_FREQUENCY = 1.0
WEIGHT_RECENCY = 0.5
WEIGHT_INSERTION_TIME = 0.2
WEIGHT_LOCALITY_SCORE = 0.3
WEIGHT_PRIORITY_SCORE = 0.4
WEIGHT_CONNECTION_SCORE = 0.1

# Put the metadata specifically maintained by the policy below. The policy maintains access frequency, recency timestamp, insertion time, locality score, priority score, and a graph with nodes and edges representing cached items and access patterns. It also uses FIFO and LRU queues for organization.

metadata = {
    'access_frequency': collections.defaultdict(int),
    'recency_timestamp': collections.defaultdict(int),
    'insertion_time': collections.defaultdict(int),
    'locality_score': collections.defaultdict(float),
    'priority_score': collections.defaultdict(float),
    'connection_score': collections.defaultdict(float),
    'graph': collections.defaultdict(set),
    'fifo_queue': collections.deque(),
    'lru_queue': collections.deque()
}

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy selects the eviction victim based on a combined weighted score of access frequency, recency, insertion time, locality score, priority score, and connection score. If multiple objects have the same score, the least recently accessed object is evicted. The policy also considers the queue structure, evicting from SQ or T2 as necessary.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    # Your code below
    min_score = float('inf')
    
    for key, cache_obj in cache_snapshot.cache.items():
        access_frequency = metadata['access_frequency'][key]
        recency = cache_snapshot.access_count - metadata['recency_timestamp'][key]
        insertion_time = cache_snapshot.access_count - metadata['insertion_time'][key]
        locality_score = metadata['locality_score'][key]
        priority_score = metadata['priority_score'][key]
        connection_score = metadata['connection_score'][key]
        
        combined_score = (WEIGHT_ACCESS_FREQUENCY * access_frequency + 
                          WEIGHT_RECENCY * recency + 
                          WEIGHT_INSERTION_TIME * insertion_time + 
                          WEIGHT_LOCALITY_SCORE * locality_score + 
                          WEIGHT_PRIORITY_SCORE * priority_score + 
                          WEIGHT_CONNECTION_SCORE * connection_score)
        
        if combined_score < min_score:
            min_score = combined_score
            candid_obj_key = key
        elif combined_score == min_score and metadata['recency_timestamp'][key] < metadata['recency_timestamp'][candid_obj_key]:
            candid_obj_key = key
    
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    Upon a cache hit, the policy increments the access frequency, updates the recency timestamp, adjusts the locality score based on the accessing node's proximity, recalculates the priority score, and updates the connection score. The object may be moved to a higher priority queue or level based on its new scores.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    # Your code below
    key = obj.key
    metadata['access_frequency'][key] += 1
    metadata['recency_timestamp'][key] = cache_snapshot.access_count
    
    # Adjust locality and priority scores as needed. Here 'locality_score' and 'priority_score' require more context, example below may need more data.
    metadata['locality_score'][key] = 1 / (1 + metadata['access_frequency'][key])
    metadata['priority_score'][key] += 0.1  # This is a placeholder for actual priority score calculation.
    
    # Update connection score and graph if needed
    for connected_key in metadata['graph'][key]:
        metadata['connection_score'][connected_key] += 0.1  # This is an arbitrary adjustment example.
    
    # Move to higher priority if needed, using fifo or lru queues.
    if key in metadata['fifo_queue']:
        # For simplicity of the example, move to lru_queue
        metadata['fifo_queue'].remove(key)
        metadata['lru_queue'].append(key)

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the policy sets the initial access frequency to 1, records the current time as the insertion time, sets the recency timestamp to the current time, calculates the initial locality score, sets the initial priority score, and initializes the connection score. The object is placed in the appropriate queue and level, and a new node is added to the graph.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    # Your code below
    key = obj.key
    metadata['access_frequency'][key] = 1
    metadata['recency_timestamp'][key] = cache_snapshot.access_count
    metadata['insertion_time'][key] = cache_snapshot.access_count
    metadata['locality_score'][key] = 0.0  # Default starting value
    metadata['priority_score'][key] = 0.0  # Default starting value
    metadata['connection_score'][key] = 0.0  # Default starting value
    metadata['fifo_queue'].append(key)
    metadata['graph'][key] = set()

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    After evicting an object, the policy removes all associated metadata, updates the graph by removing the corresponding node and edges, and recalculates the connection scores of remaining nodes. The locality and priority scores of remaining objects are also recalculated to ensure a balanced eviction strategy.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    # Your code below
    key = evicted_obj.key
    
    del metadata['access_frequency'][key]
    del metadata['recency_timestamp'][key]
    del metadata['insertion_time'][key]
    del metadata['locality_score'][key]
    del metadata['priority_score'][key]
    del metadata['connection_score'][key]
    metadata['fifo_queue'].remove(key) if key in metadata['fifo_queue'] else None
    metadata['lru_queue'].remove(key) if key in metadata['lru_queue'] else None
    
    # Remove the node and recalculate connection scores
    if key in metadata['graph']:
        for connected_key in metadata['graph'][key]:
            metadata['connection_score'][connected_key] -= 0.1  # Example adjustment
        del metadata['graph'][key]
    
    # Recalculate locality and priority scores if needed
    for existing_key in cache_snapshot.cache.keys():
        metadata['locality_score'][existing_key] = 1 / (1 + metadata['access_frequency'][existing_key])
        metadata['priority_score'][existing_key] += 0.1  # This is an arbitrary example of priority adjustment