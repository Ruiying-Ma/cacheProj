# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
import collections
import numpy as np  # For possible use in ML model

# Put tunable constant parameters below
RECENCY_WEIGHT = 0.4
FREQUENCY_WEIGHT = 0.4
ML_MODEL_WEIGHT = 0.2
RETRAIN_INTERVAL = 100  # Retrain ML model every 100 accesses

# Put the metadata specifically maintained by the policy below. The policy maintains metadata including access frequency, recency, and a machine learning model's prediction score for each cache entry. It also tracks the success rate of different eviction strategies (LRU, LFU, MRU) over time.
meta_data = {
    'recency': collections.defaultdict(int),
    'frequency': collections.defaultdict(int),
    'ml_prediction': collections.defaultdict(float),
    'strategy_success': {
        'LRU': 0,
        'LFU': 0,
        'MRU': 0,
    },
    'access_time': collections.defaultdict(int)
}

access_time = 0

# ML Model Example Placeholder (linear regression just for illustration)
def train_ml_model(data):
    # Dummy placeholder for the machine learning model training code
    return {entry[0]: 1.0 for entry in data}

def predict_ml_model(key):
    # Simple access likelihood prediction model
    return meta_data['ml_prediction'].get(key, 1.0)

def evict(cache_snapshot, obj):
    global access_time
    '''
    This function defines how the policy chooses the eviction victim.
    '''
    access_time += 1

    candid_obj_key = None
    min_score = float('inf')

    current_time = cache_snapshot.access_count

    for key, cache_obj in cache_snapshot.cache.items():
        recency_score = (current_time - meta_data['access_time'][key]) * RECENCY_WEIGHT
        frequency_score = meta_data['frequency'][key] * FREQUENCY_WEIGHT
        ml_score = predict_ml_model(key) * ML_MODEL_WEIGHT

        eviction_score = recency_score + frequency_score + ml_score

        if eviction_score < min_score:
            min_score = eviction_score
            candid_obj_key = key

    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    Update policy metadata immediately after a cache hit.
    '''
    global access_time
    access_time += 1

    key = obj.key
    meta_data['frequency'][key] += 1
    meta_data['recency'][key] = access_time
    meta_data['access_time'][key] = access_time

    # Retrain ML model periodically
    if cache_snapshot.access_count % RETRAIN_INTERVAL == 0:
        historical_data = [
            (key, meta_data['recency'][key], meta_data['frequency'][key])
            for key in cache_snapshot.cache
        ]
        ml_model = train_ml_model(historical_data)
        meta_data['ml_prediction'].update(ml_model)

def update_after_insert(cache_snapshot, obj):
    '''
    Update policy metadata immediately after inserting a new object into the cache.
    '''
    global access_time
    access_time += 1

    key = obj.key
    meta_data['frequency'][key] = 1  # Initialize access frequency
    meta_data['recency'][key] = access_time  # Initialize recency
    meta_data['access_time'][key] = access_time

    # Update ML model with new entry
    ml_model = train_ml_model([(key, meta_data['recency'][key], meta_data['frequency'][key])])
    meta_data['ml_prediction'].update(ml_model)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    Update policy metadata immediately after evicting the victim.
    '''
    global access_time
    access_time += 1

    key = evicted_obj.key
    del meta_data['frequency'][key]
    del meta_data['recency'][key]
    del meta_data['ml_prediction'][key]
    del meta_data['access_time'][key]

    # Update strategy success rates (simplified pseudocode)
    # Assuming we could track which strategy evicted_obj belonged to
    strategy_used = 'LRU'  # Placeholder, determine based on eviction logic
    if strategy_used in meta_data['strategy_success']:
        meta_data['strategy_success'][strategy_used] += 1