# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
from collections import defaultdict

# Put tunable constant parameters below
access_frequency_weight = 0.4
recency_weight = 0.4
dynamic_weight = 0.2

# Put the metadata specifically maintained by the policy below. The policy maintains access frequency, recency (timestamp of last access), contextual relevance, dynamic weight, probabilistic eviction score, and the number of copies for frequently accessed data. It also keeps a history of recent access patterns.
metadata = {
    'frequency': defaultdict(int),
    'recency': defaultdict(int),
    'contextual_relevance': defaultdict(float),
    'dynamic_weight': defaultdict(float),
    'probabilistic_eviction_score': defaultdict(float),
    'copies_count': defaultdict(int),
    'access_history': []
}

def calculate_eviction_score(key):
    freq = metadata['frequency'][key]
    recency = metadata['recency'][key]
    dyn_weight = metadata['dynamic_weight'][key]

    eviction_score = (
        (access_frequency_weight * freq) +
        (recency_weight * (1.0 / recency)) +
        (dynamic_weight * dyn_weight)
    )

    metadata['probabilistic_eviction_score'][key] = eviction_score
    return eviction_score

def evict(cache_snapshot, obj):
    candid_obj_key = None
    min_score = float('inf')

    for key in cache_snapshot.cache:
        eviction_score = calculate_eviction_score(key)
        if eviction_score < min_score:
            min_score = eviction_score
            candid_obj_key = key

    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    key = obj.key
    metadata['frequency'][key] += 1
    metadata['recency'][key] = cache_snapshot.access_count
    # Assuming we have a mechanism to calculate contextual relevance and dynamic weight
    metadata['contextual_relevance'][key] = 1.0 # Placeholder value
    metadata['dynamic_weight'][key] = 1.0 # Placeholder value
    
    calculate_eviction_score(key)
    metadata['access_history'].append(key)

def update_after_insert(cache_snapshot, obj):
    key = obj.key
    metadata['frequency'][key] = 1
    metadata['recency'][key] = cache_snapshot.access_count
    metadata['contextual_relevance'][key] = 1.0 # Initial placeholder value
    metadata['dynamic_weight'][key] = 1.0 # Initial placeholder value

    calculate_eviction_score(key)
    metadata['copies_count'][key] = 1  # Initially one copy
    metadata['access_history'].append(key)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    evicted_key = evicted_obj.key
    
    # Remove metadata of the evicted object
    if evicted_key in metadata['frequency']:
        del metadata['frequency'][evicted_key]
    if evicted_key in metadata['recency']:
        del metadata['recency'][evicted_key]
    if evicted_key in metadata['contextual_relevance']:
        del metadata['contextual_relevance'][evicted_key]
    if evicted_key in metadata['dynamic_weight']:
        del metadata['dynamic_weight'][evicted_key]
    if evicted_key in metadata['probabilistic_eviction_score']:
        del metadata['probabilistic_eviction_score'][evicted_key]
    if evicted_key in metadata['copies_count']:
        del metadata['copies_count'][evicted_key]

    # Recalculate dynamic weights and eviction scores for remaining entries
    for key in cache_snapshot.cache:
        calculate_eviction_score(key)
    
    # Remove the evicted item from history
    if evicted_key in metadata['access_history']:
        metadata['access_history'].remove(evicted_key)