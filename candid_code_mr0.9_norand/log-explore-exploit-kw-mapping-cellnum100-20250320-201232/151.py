# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.

# Put tunable constant parameters below
SEGMENT_COUNT = 4  # Number of segments in the cache
INITIAL_VALIDATION_SCORE = 1.0
INITIAL_REWARD_SCORE = 1.0
INITIAL_SENSITIVITY_LEVEL = 1.0
INITIAL_ACCESS_FREQUENCY = 0
INITIAL_HIT_COUNT = 0
INITIAL_MISS_COUNT = 0
INITIAL_RECENCY_TIMESTAMP = 0
GLOBAL_LEARNING_RATE = 0.1

# Put the metadata specifically maintained by the policy below. The policy maintains access frequency, recency, sensitivity level, validation score, reward score, hit count, miss count, recency timestamp, and a global learning rate for each cache segment and item.
cache_metadata = {
    'segments': [{} for _ in range(SEGMENT_COUNT)],
    'global_learning_rate': GLOBAL_LEARNING_RATE
}

def get_segment_index(obj_key):
    return hash(obj_key) % SEGMENT_COUNT

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy selects the eviction victim by first identifying the segment with the highest load, then choosing the item with the lowest combined validation and reward score. If multiple items have the same score, the least recently used item among them is evicted.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    # Your code below
    segments = cache_metadata['segments']
    highest_load_segment = max(segments, key=lambda seg: sum(item['size'] for item in seg.values()))
    
    lowest_score = float('inf')
    for key, metadata in highest_load_segment.items():
        combined_score = metadata['validation_score'] + metadata['reward_score']
        if combined_score < lowest_score or (combined_score == lowest_score and metadata['recency_timestamp'] < highest_load_segment[candid_obj_key]['recency_timestamp']):
            lowest_score = combined_score
            candid_obj_key = key
    
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    Upon a cache hit, the policy updates the access frequency, recency, validation score, reward score, hit count, and recency timestamp of the accessed item. The load metrics for the corresponding segment are also adjusted.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    # Your code below
    segment_index = get_segment_index(obj.key)
    metadata = cache_metadata['segments'][segment_index][obj.key]
    
    metadata['access_frequency'] += 1
    metadata['recency_timestamp'] = cache_snapshot.access_count
    metadata['validation_score'] += cache_metadata['global_learning_rate']
    metadata['reward_score'] += cache_metadata['global_learning_rate']
    metadata['hit_count'] += 1

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the policy initializes its access frequency, recency, sensitivity level, validation score, reward score, hit count, and recency timestamp. The load metrics for the segment where the object is inserted are updated.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    # Your code below
    segment_index = get_segment_index(obj.key)
    cache_metadata['segments'][segment_index][obj.key] = {
        'access_frequency': INITIAL_ACCESS_FREQUENCY,
        'recency_timestamp': cache_snapshot.access_count,
        'sensitivity_level': INITIAL_SENSITIVITY_LEVEL,
        'validation_score': INITIAL_VALIDATION_SCORE,
        'reward_score': INITIAL_REWARD_SCORE,
        'hit_count': INITIAL_HIT_COUNT,
        'miss_count': INITIAL_MISS_COUNT,
        'size': obj.size
    }

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    Following an eviction, the policy updates the load metrics for the affected segment, recalculates the validation scores for the remaining items in that segment, and adjusts the global learning rate based on the hit and miss counts of the evicted item. The metadata of the evicted item is removed from the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    # Your code below
    segment_index = get_segment_index(evicted_obj.key)
    segment = cache_metadata['segments'][segment_index]
    
    # Remove metadata of the evicted object
    del segment[evicted_obj.key]
    
    # Recalculate validation scores for remaining items in the segment
    for metadata in segment.values():
        metadata['validation_score'] = max(0, metadata['validation_score'] - cache_metadata['global_learning_rate'])
    
    # Adjust global learning rate based on the hit and miss counts of the evicted item
    total_hits = cache_snapshot.hit_count
    total_misses = cache_snapshot.miss_count
    cache_metadata['global_learning_rate'] = (total_hits + total_misses) / (total_hits + 1)