# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
import collections

# Put tunable constant parameters below
TIER_PROMOTION_THRESHOLD = 10

# Put the metadata specifically maintained by the policy below. The policy maintains a multi-tiered structure with each layer having its own metadata: access frequency, recency, and a weighted score for time-based patterns. Each item also has a priority score calculated from these factors.
class MetaData:
    def __init__(self, access_frequency, recency, time_score):
        self.access_frequency = access_frequency
        self.recency = recency
        self.time_score = time_score
        self.update_priority()
    
    def update_priority(self):
        self.priority_score = self.access_frequency + self.recency + self.time_score

object_metadata = collections.defaultdict(lambda: MetaData(0, 0, 0))
cache_tiers = {0: set(), 1: set(), 2: set()}

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy evicts items by first checking the lowest tier. Within that tier, it selects the item with the lowest priority score, which is a combination of infrequent access, low recency, and low weighted score for time-based patterns.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    lowest_priority = float('inf')
    
    for tier in sorted(cache_tiers.keys()):
        for key in cache_tiers[tier]:
            metadata = object_metadata[key]
            if metadata.priority_score < lowest_priority:
                lowest_priority = metadata.priority_score
                candid_obj_key = key

        if candid_obj_key is not None:
            break
            
    if candid_obj_key:
        del object_metadata[candid_obj_key]
        for tier in cache_tiers:
            cache_tiers[tier].discard(candid_obj_key)
    
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    Upon a cache hit, the item's access frequency and recency are updated. The weighted score for time-based patterns is recalculated, and the priority score is adjusted accordingly. The item may be promoted to a higher tier if its new priority score surpasses a threshold.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    key = obj.key
    metadata = object_metadata[key]
    metadata.access_frequency += 1
    metadata.recency = cache_snapshot.access_count
    metadata.time_score = compute_time_score(cache_snapshot, obj)  # Placeholder for custom logic
    metadata.update_priority()

    for tier in cache_tiers:
        cache_tiers[tier].discard(key)
    
    tier = min(metadata.priority_score // TIER_PROMOTION_THRESHOLD, 2)
    cache_tiers[tier].add(key)
    
def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the policy initializes its access frequency, recency, and weighted score for time-based patterns. The priority score is calculated, and the item is placed in the appropriate tier based on this score.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    key = obj.key
    object_metadata[key].access_frequency = 1
    object_metadata[key].recency = cache_snapshot.access_count
    object_metadata[key].time_score = compute_time_score(cache_snapshot, obj)  # Placeholder for custom logic
    object_metadata[key].update_priority()

    tier = min(object_metadata[key].priority_score // TIER_PROMOTION_THRESHOLD, 2)
    cache_tiers[tier].add(key)
    
def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    After evicting an item, the policy updates the metadata of the remaining items in the affected tier to reflect the change in the cache's state. This may involve recalculating priority scores and potentially promoting or demoting items between tiers.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    evicted_metadata = object_metadata.pop(evicted_obj.key, None)
    for tier in cache_tiers:
        cache_tiers[tier].discard(evicted_obj.key)
    
    # Optional: Logic to adjust neighboring object's metadata and tiers
    for key in cache_snapshot.cache:
        metadata = object_metadata[key]
        metadata.time_score = compute_time_score(cache_snapshot, cache_snapshot.cache[key])  # Placeholder for custom logic
        metadata.update_priority()

        for tier in cache_tiers:
            cache_tiers[tier].discard(key)
        
        tier = min(metadata.priority_score // TIER_PROMOTION_THRESHOLD, 2)
        cache_tiers[tier].add(key)

def compute_time_score(cache_snapshot, obj):
    '''
    Placeholder function for computing time score patterns.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to compute the time score for.
    - Return: `time_score` (int)
    '''
    return cache_snapshot.access_count - object_metadata[obj.key].recency