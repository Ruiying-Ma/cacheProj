# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
from collections import deque, defaultdict
import time

# Put tunable constant parameters below
INITIAL_PRIORITY_SCORE = 1
INITIAL_CONNECTIVITY_SCORE = 1
INITIAL_CONTEXTUAL_RELEVANCE_SCORE = 1
INITIAL_PREDICTIVE_MODEL_SCORE = 1

# Put the metadata specifically maintained by the policy below. The policy maintains access frequency, recency of access, contextual relevance scores, predictive model score, LRU queue, timestamp of last access, miss ratio tracker, current strategy indicator, and a relationship graph with nodes and edges representing cached items and their access correlations.
access_frequency = defaultdict(int)
last_access_timestamp = {}
recency = {}
priority_score = defaultdict(lambda: INITIAL_PRIORITY_SCORE)
connectivity_score = defaultdict(lambda: INITIAL_CONNECTIVITY_SCORE)
contextual_relevance_score = defaultdict(lambda: INITIAL_CONTEXTUAL_RELEVANCE_SCORE)
predictive_model_score = defaultdict(lambda: INITIAL_PREDICTIVE_MODEL_SCORE)
lru_queue = deque()
relationship_graph = defaultdict(set)
miss_ratio_tracker = []
current_strategy_indicator = "default"

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy chooses the eviction victim by combining the predictive model score, contextual relevance, access frequency, recency, priority score, connectivity score, and the current strategy's criteria. The item with the lowest combined score is evicted, prioritizing items with weaker connections, lower access frequency/recency, and fitting the current strategy.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    min_score = float('inf')
    
    for key, cached_obj in cache_snapshot.cache.items():
        combined_score = (
            predictive_model_score[key] +
            contextual_relevance_score[key] +
            access_frequency[key] +
            (cache_snapshot.access_count - last_access_timestamp[key]) +
            priority_score[key] +
            connectivity_score[key]
        )
        
        if combined_score < min_score:
            min_score = combined_score
            candid_obj_key = key
    
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    Upon a cache hit, the policy increments the frequency count, updates the last access timestamp, sets the item's recency to the current timestamp, moves it to the most-recently-used end of the LRU queue, updates the priority score, strengthens the edges between this item and other recently accessed items, recalculates the contextual relevance score, updates the predictive model score, and recalculates the miss ratio tracker to determine if a strategy switch is needed.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    access_frequency[obj.key] += 1
    last_access_timestamp[obj.key] = cache_snapshot.access_count
    recency[obj.key] = cache_snapshot.access_count
    
    if obj.key in lru_queue:
        lru_queue.remove(obj.key)
    lru_queue.append(obj.key)
    
    # Update priority score, connectivity score, and contextual relevance score
    priority_score[obj.key] += 1
    for other_key in lru_queue:
        if other_key != obj.key:
            relationship_graph[obj.key].add(other_key)
            relationship_graph[other_key].add(obj.key)
            connectivity_score[obj.key] += 1
            connectivity_score[other_key] += 1
    
    # Update predictive model score
    predictive_model_score[obj.key] += 1
    
    # Update miss ratio tracker
    miss_ratio_tracker.append(cache_snapshot.miss_count / cache_snapshot.access_count)
    
    # Determine if a strategy switch is needed
    if len(miss_ratio_tracker) > 100:
        miss_ratio_tracker.pop(0)
    if sum(miss_ratio_tracker) / len(miss_ratio_tracker) > 0.5:
        current_strategy_indicator = "aggressive"
    else:
        current_strategy_indicator = "default"

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the policy initializes the frequency count, records the current timestamp, sets the item's recency to the current timestamp, places it at the most-recently-used end of the LRU queue, initializes its priority and connectivity scores, creates edges to other recently accessed items, adjusts their weights based on access patterns, calculates the initial contextual relevance score, assigns an initial predictive model score, and updates the miss ratio tracker to reflect the new state of the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    access_frequency[obj.key] = 1
    last_access_timestamp[obj.key] = cache_snapshot.access_count
    recency[obj.key] = cache_snapshot.access_count
    lru_queue.append(obj.key)
    
    priority_score[obj.key] = INITIAL_PRIORITY_SCORE
    connectivity_score[obj.key] = INITIAL_CONNECTIVITY_SCORE
    contextual_relevance_score[obj.key] = INITIAL_CONTEXTUAL_RELEVANCE_SCORE
    predictive_model_score[obj.key] = INITIAL_PREDICTIVE_MODEL_SCORE
    
    for other_key in lru_queue:
        if other_key != obj.key:
            relationship_graph[obj.key].add(other_key)
            relationship_graph[other_key].add(obj.key)
            connectivity_score[obj.key] += 1
            connectivity_score[other_key] += 1
    
    miss_ratio_tracker.append(cache_snapshot.miss_count / cache_snapshot.access_count)
    
    if len(miss_ratio_tracker) > 100:
        miss_ratio_tracker.pop(0)
    if sum(miss_ratio_tracker) / len(miss_ratio_tracker) > 0.5:
        current_strategy_indicator = "aggressive"
    else:
        current_strategy_indicator = "default"

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    After evicting an item, the policy removes the frequency count and timestamp of the evicted item, removes the item from the LRU queue, removes the node and its edges from the relationship graph, recalculates the connectivity scores of the remaining connected items, updates the miss ratio tracker, recalibrates the predictive model using the remaining objects, and reassesses the strategy indicator to ensure optimal performance based on the current workload.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    del access_frequency[evicted_obj.key]
    del last_access_timestamp[evicted_obj.key]
    del recency[evicted_obj.key]
    del priority_score[evicted_obj.key]
    del connectivity_score[evicted_obj.key]
    del contextual_relevance_score[evicted_obj.key]
    del predictive_model_score[evicted_obj.key]
    
    if evicted_obj.key in lru_queue:
        lru_queue.remove(evicted_obj.key)
    
    for other_key in relationship_graph[evicted_obj.key]:
        relationship_graph[other_key].remove(evicted_obj.key)
        connectivity_score[other_key] -= 1
    
    del relationship_graph[evicted_obj.key]
    
    miss_ratio_tracker.append(cache_snapshot.miss_count / cache_snapshot.access_count)
    
    if len(miss_ratio_tracker) > 100:
        miss_ratio_tracker.pop(0)
    if sum(miss_ratio_tracker) / len(miss_ratio_tracker) > 0.5:
        current_strategy_indicator = "aggressive"
    else:
        current_strategy_indicator = "default"