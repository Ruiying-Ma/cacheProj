# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
import collections

# Put tunable constant parameters below
max_frequency_count = 1000  # maximum frequency count for normalization

# Put the metadata specifically maintained by the policy below. The policy maintains a doubly linked list of cached objects, a frequency counter for each object, and a machine learning model that predicts future access patterns. Each node in the list represents a cached object and includes pointers to the previous and next nodes, as well as access frequency and recency data.
class ListNode:
    def __init__(self, key, obj):
        self.key = key
        self.obj = obj
        self.prev = None
        self.next = None
        self.frequency = 1
        self.recency = 0

class DoublyLinkedList:
    def __init__(self):
        self.head = None
        self.tail = None

    def move_to_front(self, node):
        if node is self.head:
            return
        self.remove(node)
        self.add_to_front(node)

    def add_to_front(self, node):
        node.next = self.head
        node.prev = None
        if self.head:
            self.head.prev = node
        self.head = node
        if self.tail is None:
            self.tail = node

    def remove(self, node):
        if node.prev:
            node.prev.next = node.next
        if node.next:
            node.next.prev = node.prev
        if node is self.head:
            self.head = node.next
        if node is self.tail:
            self.tail = node.prev

# Initialize metadata
cache_metadata = {
    'dll': DoublyLinkedList(),
    'frequency_counter': collections.defaultdict(int),
    'access_recency': {}
}

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy probabilistically selects an eviction candidate from the least recently used (LRU) end of the list, with a higher probability assigned to nodes with lower access frequency. The machine learning model adjusts the probability distribution based on predicted future access patterns.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_node = cache_metadata['dll'].tail
    if candid_node is None:
        return None

    # Calculate the normalized probabilities based on frequency
    frequency_sum = 0
    lru_node = cache_metadata['dll'].tail
    while lru_node:
        frequency_sum += max_frequency_count - lru_node.frequency
        lru_node = lru_node.prev

    # Identify eviction candidate based on these probabilities
    lru_node = cache_metadata['dll'].tail
    accumulated_prob = 0
    while lru_node:
        accumulated_prob += (max_frequency_count - lru_node.frequency)
        if accumulated_prob >= frequency_sum // 2:
            candid_node = lru_node
            break
        lru_node = lru_node.prev

    return candid_node.key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    Upon a cache hit, the accessed node is moved to the most recently used (MRU) end of the list, and its frequency counter is incremented. The machine learning model is updated with the new access pattern data.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    node = cache_metadata['access_recency'][obj.key]
    cache_metadata['dll'].move_to_front(node)
    node.frequency += 1

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the object is added to the MRU end of the list with an initial frequency counter set to 1. The machine learning model is updated to include the new object and its initial access pattern.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    node = ListNode(obj.key, obj)
    cache_metadata['dll'].add_to_front(node)
    cache_metadata['frequency_counter'][obj.key] = node.frequency
    cache_metadata['access_recency'][obj.key] = node

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    After evicting a victim, the corresponding node is removed from the list, and its metadata is deleted. The machine learning model is updated to exclude the evicted object and adjust its predictions based on the remaining objects.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    node = cache_metadata['access_recency'].pop(evicted_obj.key, None)
    if node:
        cache_metadata['dll'].remove(node)
        del cache_metadata['frequency_counter'][evicted_obj.key]