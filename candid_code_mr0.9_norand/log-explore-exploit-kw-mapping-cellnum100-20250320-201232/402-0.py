# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.

import numpy as np

# Put tunable constant parameters below
LEARNING_RATE = 0.01
EVICTION_PROB = 0.1

# Put the metadata specifically maintained by the policy below. The policy maintains a machine learning model to predict future access probabilities, a feedback mechanism to track hit/miss rates, and real-time access pattern statistics.

# Access pattern statistics: a dictionary mapping obj.keys to a tuple containing (last access time, frequency of access)
access_pattern_stats = {}

# Machine learning model weights (for simplicity, use a simple linear regression with one feature: access frequency)
model_weights = np.array([0.0, 1.0])  # Intercept and coefficient

# Feedback mechanism: a dictionary to track hit/miss rates for each object
feedback_mechanism = {}

def predict_access_probability(frequency):
    '''Predict access probability based on current access frequency.'''
    return model_weights[0] + model_weights[1] * frequency

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy uses the machine learning model to predict access probabilities for all cached objects and evicts the one with the lowest predicted access probability, incorporating a probabilistic element to occasionally evict higher probability entries to explore new entries.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    min_predicted_prob = float('inf')

    # Iterate through all objects in the cache to determine the one with the lowest predicted probability
    for key, cached_obj in cache_snapshot.cache.items():
        frequency = access_pattern_stats.get(key, (0, 0))[1]
        predicted_prob = predict_access_probability(frequency)
        
        if predicted_prob < min_predicted_prob or (predicted_prob == min_predicted_prob and EVICTION_PROB > 0):
            min_predicted_prob = predicted_prob
            candid_obj_key = key
    
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    The policy updates the access pattern statistics to reflect the hit, adjusts the machine learning model based on the new data, and records the hit in the feedback mechanism.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    key = obj.key
    current_time = cache_snapshot.access_count
    _, frequency = access_pattern_stats.get(key, (current_time, 0))
    
    access_pattern_stats[key] = (current_time, frequency + 1)
    
    # Update the feedback mechanism
    feedback_mechanism[key] = feedback_mechanism.get(key, 0) + 1
    
    # Adjust the machine learning model
    model_weights[0] -= LEARNING_RATE * frequency
    model_weights[1] += LEARNING_RATE * frequency

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    The policy updates the access pattern statistics to include the new object, retrains the machine learning model with the new data, and initializes the feedback mechanism for the new object.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    key = obj.key
    current_time = cache_snapshot.access_count
    
    access_pattern_stats[key] = (current_time, 1)
    
    # Initialize the feedback mechanism
    feedback_mechanism[key] = 1

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    The policy updates the access pattern statistics to remove the evicted object, retrains the machine learning model excluding the evicted object, and records the eviction outcome in the feedback mechanism to adjust future eviction strategies.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    evicted_key = evicted_obj.key

    # Remove from access pattern statistics
    if evicted_key in access_pattern_stats:
        del access_pattern_stats[evicted_key]
    
    # Remove from feedback mechanism
    if evicted_key in feedback_mechanism:
        del feedback_mechanism[evicted_key]

    # Retrain the machine learning model excluding the evicted object
    # Note: In this simplified approach, model retraining is implicit in the update_after_hit method