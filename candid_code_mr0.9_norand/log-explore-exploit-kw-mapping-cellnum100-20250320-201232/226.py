# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
from collections import defaultdict, deque
import time

# Put tunable constant parameters below
k = 3  # Number of LRU queues

# Put the metadata specifically maintained by the policy below. The policy maintains k LRU queues, a dynamic priority score, relationship strength score, ordered list of items, timestamps for recency tracking, access frequency, a log of eviction reasons, and success scores for competing algorithms.
lru_queues = [deque() for _ in range(k)]
priority_scores = {}
relationship_strength_scores = {}
ordered_list = []
recency_timestamps = {}
access_frequencies = {}
eviction_log = []
success_scores = defaultdict(lambda: defaultdict(int))

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy first considers the lowest combined score of priority, relationship strength, access frequency, and recency. If there is a tie, it evaluates the success scores of competing algorithms and evicts the item with the lowest combined score. If still tied, it evicts the least recently used item from the non-empty LRU queue with the smallest subscript.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    min_combined_score = float('inf')
    candidates = []

    for key, cached_obj in cache_snapshot.cache.items():
        combined_score = (priority_scores[key] + relationship_strength_scores[key] +
                          access_frequencies[key] + (cache_snapshot.access_count - recency_timestamps[key]))
        if combined_score < min_combined_score:
            min_combined_score = combined_score
            candidates = [key]
        elif combined_score == min_combined_score:
            candidates.append(key)

    if len(candidates) > 1:
        min_success_score = float('inf')
        final_candidates = []
        for key in candidates:
            success_score = sum(success_scores[alg][key] for alg in success_scores)
            if success_score < min_success_score:
                min_success_score = success_score
                final_candidates = [key]
            elif success_score == min_success_score:
                final_candidates.append(key)
        candidates = final_candidates

    if len(candidates) > 1:
        for i in range(k):
            for key in lru_queues[i]:
                if key in candidates:
                    candid_obj_key = key
                    break
            if candid_obj_key:
                break
    else:
        candid_obj_key = candidates[0]

    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    The policy increases the access frequency, updates the recency timestamp, adjusts the relationship strength scores, moves the item to the front of the ordered list, and updates the success scores of the algorithms based on their predictions. If the item is in Li, it is moved to the most-recently-used end of Lj where j = min(i+1, k).
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    key = obj.key
    access_frequencies[key] += 1
    recency_timestamps[key] = cache_snapshot.access_count
    ordered_list.remove(key)
    ordered_list.insert(0, key)

    for i in range(k):
        if key in lru_queues[i]:
            lru_queues[i].remove(key)
            lru_queues[min(i + 1, k - 1)].append(key)
            break

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    The policy initializes the priority score, sets the relationship strength score, places the item at the front of the ordered list, sets the recency timestamp, initializes the access frequency, logs the insertion reason, updates the success scores of the algorithms, and places the item at the most-recently-used end of L1.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    key = obj.key
    priority_scores[key] = 0
    relationship_strength_scores[key] = 0
    ordered_list.insert(0, key)
    recency_timestamps[key] = cache_snapshot.access_count
    access_frequencies[key] = 1
    eviction_log.append(f"Inserted {key}")
    lru_queues[0].append(key)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    The policy removes the item's metadata, adjusts the relationship strength scores of remaining items, updates the ordered list, removes the item from its LRU queue, logs the eviction reason, updates the success scores of the algorithms, and adjusts the access frequency and recency of remaining items if necessary. If the eviction occurs in a higher level, an item from a lower level may be promoted to fill the vacancy.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    key = evicted_obj.key
    del priority_scores[key]
    del relationship_strength_scores[key]
    ordered_list.remove(key)
    del recency_timestamps[key]
    del access_frequencies[key]
    eviction_log.append(f"Evicted {key}")

    for i in range(k):
        if key in lru_queues[i]:
            lru_queues[i].remove(key)
            break

    # Adjust relationship strength scores and other metadata if necessary
    for remaining_key in cache_snapshot.cache:
        relationship_strength_scores[remaining_key] -= 1