# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
from collections import defaultdict, deque

# Put tunable constant parameters below
PRIORITY_WEIGHT = 0.3
RELATIONSHIP_WEIGHT = 0.2
VALIDATION_WEIGHT = 0.2
CONTEXTUAL_WEIGHT = 0.2
PREDICTIVE_WEIGHT = 0.1

# Put the metadata specifically maintained by the policy below. The policy maintains a dynamic priority score, relationship strength score, access frequency, recency, sensitivity level, validation score, contextual relevance score, predictive model score, and load metrics for each cache segment.
metadata = {
    'priority_score': defaultdict(float),
    'relationship_strength_score': defaultdict(float),
    'access_frequency': defaultdict(int),
    'recency': defaultdict(int),
    'sensitivity_level': defaultdict(float),
    'validation_score': defaultdict(float),
    'contextual_relevance_score': defaultdict(float),
    'predictive_model_score': defaultdict(float),
    'load_metrics': defaultdict(int),
    'ordered_list': deque(),
    'segment_levels': defaultdict(int)
}

def calculate_composite_score(key):
    return (PRIORITY_WEIGHT * metadata['priority_score'][key] +
            RELATIONSHIP_WEIGHT * metadata['relationship_strength_score'][key] +
            VALIDATION_WEIGHT * metadata['validation_score'][key] +
            CONTEXTUAL_WEIGHT * metadata['contextual_relevance_score'][key] +
            PREDICTIVE_WEIGHT * metadata['predictive_model_score'][key])

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy calculates a composite score using the priority score, relationship strength score, validation score, contextual relevance score, and predictive model score. It identifies the segment with the highest load and evicts the item with the lowest composite score within that segment. If there is a tie, it considers the access frequency and recency to evict the least recently used item among the remaining candidates.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    highest_load_segment = max(metadata['load_metrics'], key=metadata['load_metrics'].get)
    lowest_composite_score = float('inf')
    candidates = []

    for key in cache_snapshot.cache:
        if metadata['segment_levels'][key] == highest_load_segment:
            composite_score = calculate_composite_score(key)
            if composite_score < lowest_composite_score:
                lowest_composite_score = composite_score
                candidates = [key]
            elif composite_score == lowest_composite_score:
                candidates.append(key)

    if candidates:
        candid_obj_key = min(candidates, key=lambda k: (metadata['access_frequency'][k], metadata['recency'][k]))

    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    Upon a cache hit, the policy increases the access frequency, updates the recency, recalculates the validation score, contextual relevance score, and predictive model score, adjusts the relationship strength scores based on the accessed item's connections, updates the load metrics for the corresponding segment, and moves the item to the front of the ordered list. If the item is in a lower level, it may be promoted to a higher level.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    key = obj.key
    metadata['access_frequency'][key] += 1
    metadata['recency'][key] = cache_snapshot.access_count
    # Recalculate scores (dummy recalculations for illustration)
    metadata['validation_score'][key] += 0.1
    metadata['contextual_relevance_score'][key] += 0.1
    metadata['predictive_model_score'][key] += 0.1
    # Adjust relationship strength scores (dummy adjustment for illustration)
    metadata['relationship_strength_score'][key] += 0.1
    # Update load metrics
    segment = metadata['segment_levels'][key]
    metadata['load_metrics'][segment] += 1
    # Move to front of ordered list
    if key in metadata['ordered_list']:
        metadata['ordered_list'].remove(key)
    metadata['ordered_list'].appendleft(key)
    # Promote to higher level if necessary (dummy promotion for illustration)
    if segment > 0:
        metadata['segment_levels'][key] -= 1

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the policy initializes its priority score, relationship strength score, access frequency, recency, sensitivity level, validation score, contextual relevance score, and predictive model score. It updates the load metrics for the segment where the object is inserted and places the item at the front of the ordered list. The item is inserted into the appropriate level based on its initial priority score.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    key = obj.key
    # Initialize scores (dummy initializations for illustration)
    metadata['priority_score'][key] = 1.0
    metadata['relationship_strength_score'][key] = 1.0
    metadata['access_frequency'][key] = 1
    metadata['recency'][key] = cache_snapshot.access_count
    metadata['sensitivity_level'][key] = 1.0
    metadata['validation_score'][key] = 1.0
    metadata['contextual_relevance_score'][key] = 1.0
    metadata['predictive_model_score'][key] = 1.0
    # Update load metrics
    initial_segment = 0  # Assuming initial segment is 0
    metadata['load_metrics'][initial_segment] += 1
    metadata['segment_levels'][key] = initial_segment
    # Place at front of ordered list
    metadata['ordered_list'].appendleft(key)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    Following an eviction, the policy removes the evicted item's metadata, adjusts the relationship strength scores of remaining items, updates the ordered list, recalculates the validation scores, contextual relevance scores, and predictive model scores for the remaining items in the affected segment. It also updates the load metrics for the segment and, if the eviction occurs in a higher level, promotes an item from a lower level to fill the vacancy.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    evicted_key = evicted_obj.key
    segment = metadata['segment_levels'][evicted_key]
    # Remove evicted item's metadata
    for key in ['priority_score', 'relationship_strength_score', 'access_frequency', 'recency', 'sensitivity_level', 'validation_score', 'contextual_relevance_score', 'predictive_model_score', 'segment_levels']:
        if evicted_key in metadata[key]:
            del metadata[key][evicted_key]
    if evicted_key in metadata['ordered_list']:
        metadata['ordered_list'].remove(evicted_key)
    # Adjust relationship strength scores (dummy adjustment for illustration)
    for key in cache_snapshot.cache:
        metadata['relationship_strength_score'][key] -= 0.1
    # Recalculate scores (dummy recalculations for illustration)
    for key in cache_snapshot.cache:
        metadata['validation_score'][key] += 0.1
        metadata['contextual_relevance_score'][key] += 0.1
        metadata['predictive_model_score'][key] += 0.1
    # Update load metrics
    metadata['load_metrics'][segment] -= 1
    # Promote an item from a lower level if necessary (dummy promotion for illustration)
    if segment > 0:
        for key in cache_snapshot.cache:
            if metadata['segment_levels'][key] == segment - 1:
                metadata['segment_levels'][key] += 1
                break