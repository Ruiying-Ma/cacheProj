# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
from collections import deque, defaultdict
import heapq

# Put tunable constant parameters below
NEAR_CAPACITY_THRESHOLD = 0.8  # Cache is near capacity if its usage is 80% of the total capacity

# Put the metadata specifically maintained by the policy below. The policy maintains two LRU queues (T1 and T2), two FIFO ghost queues (B1 and B2), a graph with nodes and edges representing access patterns, access frequency, last access time, a predicted access score, and the stage in the usage lifecycle for each cached item.

T1 = deque()  # LRU queue for T1
T2 = deque()  # LRU queue for T2
B1 = deque()  # FIFO ghost queue for B1
B2 = deque()  # FIFO ghost queue for B2

nodes = dict()
edges = defaultdict(dict)

class CacheNode:
    def __init__(self, obj):
        self.obj = obj
        self.key = obj.key
        self.size = obj.size
        self.access_frequency = 0
        self.last_access_time = 0
        self.predicted_access_score = 0
        self.stage = 0
    
    def update(self, timestamp):
        self.access_frequency += 1
        self.last_access_time = timestamp
        self.stage += 1
        self.predicted_access_score = self.access_frequency / (timestamp - self.last_access_time + 1)
    
    def __lt__(self, other):
        if self.predicted_access_score == other.predicted_access_score:
            return self.stage < other.stage
        return self.predicted_access_score < other.predicted_access_score

def evict(cache_snapshot, obj):
    candid_obj_key = None
    # Your code below
    if cache_snapshot.size / cache_snapshot.capacity > NEAR_CAPACITY_THRESHOLD:
        # Evict based on predicted access score and stage
        min_heap = [(nodes[n].predicted_access_score, nodes[n].stage, n) for n in T1]
        min_heap.extend([(nodes[n].predicted_access_score, nodes[n].stage, n) for n in T2])
        heapq.heapify(min_heap)
        _, _, candid_obj_key = heapq.heappop(min_heap)
    else:
        # Evict based on weighted combination of LRU and LFU
        if T1:
            lru_node = min(T1, key=lambda n: cache_snapshot.access_count - nodes[n].last_access_time)
            candid_obj_key = lru_node
        else:
            lf_node = min(T2, key=lambda n: nodes[n].access_frequency)
            candid_obj_key = lf_node
        
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    # Your code below
    if obj.key in T2:
        # Move accessed item to the most-recently-used end of T2
        T2.remove(obj.key)
        T2.append(obj.key)
    nodes[obj.key].update(cache_snapshot.access_count)

def update_after_insert(cache_snapshot, obj):
    # Your code below
    if obj.key in B1 or obj.key in B2:
        if obj.key in B1:
            B1.remove(obj.key)
        else:
            B2.remove(obj.key)
        T2.append(obj.key)
    else:
        T1.append(obj.key)
    c_node = CacheNode(obj)
    c_node.update(cache_snapshot.access_count)
    nodes[obj.key] = c_node
    
    # Update edges - not fully detailed in the description, assumed to be a basic update edge process
    # Example logic to handle graph with nodes and edges
    for node_key in list(T1) + list(T2):
        if node_key == obj.key:
            continue
        edges[obj.key][node_key] = edges[node_key][obj.key] = nodes[node_key].access_frequency

def update_after_evict(cache_snapshot, obj, evicted_obj):
    # Your code below
    if evicted_obj.key in T1:
        T1.remove(evicted_obj.key)
        B1.append(evicted_obj.key)
    else:
        T2.remove(evicted_obj.key)
        B2.append(evicted_obj.key)
    
    # Remove from nodes and edges
    del nodes[evicted_obj.key]
    del edges[evicted_obj.key]
    for node_key in edges:
        if evicted_obj.key in edges[node_key]:
            del edges[node_key][evicted_obj.key]