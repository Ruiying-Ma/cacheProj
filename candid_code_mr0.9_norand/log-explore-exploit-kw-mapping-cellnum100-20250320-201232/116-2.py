# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.

import sys
from collections import defaultdict

# Put tunable constant parameters below
INITIAL_ESTIMATED_FUTURE_ACCESS_PATTERN = 1.0
DEPENDENCY_SCORE_BASE = 1.0

# Put the metadata specifically maintained by the policy below. The policy maintains a hierarchical structure of metadata, including access frequency counters, timestamps of last access, estimated future access patterns, and dependency scores for each cache line at different levels of the cache hierarchy. It also tracks a combined score that integrates access frequency, recency, and dependency score.

access_frequency = defaultdict(int)
last_access_timestamp = defaultdict(int)
estimated_future_access_pattern = defaultdict(lambda: INITIAL_ESTIMATED_FUTURE_ACCESS_PATTERN)
dependency_score = defaultdict(lambda: DEPENDENCY_SCORE_BASE)
combined_score = defaultdict(float)

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy traverses the cache hierarchy starting from the lowest level, using a combination of LRU, LFU, and the combined score to identify potential eviction candidates. It then uses estimated future access patterns to select the final eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    min_combined_score = sys.maxsize

    for key, cached_obj in cache_snapshot.cache.items():
        score = combined_score[key]
        if score < min_combined_score:
            min_combined_score = score
            candid_obj_key = key

    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    Upon a cache hit, the policy increments the access frequency counter, updates the timestamp of last access, refines the estimated future access pattern, recalculates the dependency score if necessary, and updates the combined score for the corresponding cache line.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    key = obj.key
    curr_time = cache_snapshot.access_count

    access_frequency[key] += 1
    last_access_timestamp[key] = curr_time

    # Assume estimated_future_access_pattern would involve some historical data patterns (simplified here).
    estimated_future_access_pattern[key] *= 1.1  # Arbitrary increment for future patterns

    # Recalculate combined score: For simplicity just summing up the components
    combined_score[key] = access_frequency[key] + 1 / (curr_time - last_access_timestamp[key] + 1) + dependency_score[key]

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the policy initializes the access frequency counter to 1, sets the timestamp of last access to the current time, sets an initial estimated future access pattern based on historical data, calculates the dependency score, and computes the combined score for the new cache line.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    key = obj.key
    curr_time = cache_snapshot.access_count
    
    access_frequency[key] = 1
    last_access_timestamp[key] = curr_time
    estimated_future_access_pattern[key] = INITIAL_ESTIMATED_FUTURE_ACCESS_PATTERN
    
    # Dependency score might be based on external factor/historical data; simplified here.
    dependency_score[key] = DEPENDENCY_SCORE_BASE 

    # Calculate combined score
    combined_score[key] = access_frequency[key] + 1 / (curr_time - last_access_timestamp[key] + 1) + dependency_score[key]

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    Following an eviction, the policy resets the metadata for the evicted cache line, including clearing the access frequency counter, timestamp of last access, estimated future access pattern, and dependency score. It also adjusts the hierarchical structure and updates the dependency scores and combined scores of the remaining items.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    evicted_key = evicted_obj.key

    # Reset metadata for the evicted cache line
    if evicted_key in access_frequency:
        del access_frequency[evicted_key]
        del last_access_timestamp[evicted_key]
        del estimated_future_access_pattern[evicted_key]
        del dependency_score[evicted_key]
        del combined_score[evicted_key]

    # Adjust hierarchical structure and update combined scores for remaining items
    for key in cache_snapshot.cache.keys():
        if key != evicted_key:
            # In a realistic setting, we would re-evaluate dependency scores based on cache hierarchy; simplified here.
            dependency_score[key] *= 1.05  # Arbitrary adjustment for demonstration
            combined_score[key] = access_frequency[key] + 1 / (cache_snapshot.access_count - last_access_timestamp[key] + 1) + dependency_score[key]