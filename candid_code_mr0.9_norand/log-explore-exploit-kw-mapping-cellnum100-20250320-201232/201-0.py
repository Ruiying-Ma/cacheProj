# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
import heapq
import collections

# Put tunable constant parameters below

# Constants for weights of priority calculation
FREQUENCY_WEIGHT = 0.5
RECENCY_WEIGHT = 0.3
AGE_WEIGHT = 0.2

# Put the metadata specifically maintained by the policy below. The policy maintains a multi-level structure with LFU and LRU queues, a circular pointer, frequency counters, recency timestamps, access steps, priority scores, a dependency graph, and a machine learning model for predicting future access patterns.
class Metadata:
    def __init__(self):
        self.frequency = collections.defaultdict(int)
        self.recency = collections.defaultdict(int)
        self.access_step = collections.defaultdict(int)
        self.priority = collections.defaultdict(float)
        self.dependency_graph = collections.defaultdict(set)
        self.lfu_queue = []
        self.lru_queue = collections.deque()
        self.circular_pointer = 0

metadata = Metadata()

def calculate_priority(frequency, recency, age):
    return (FREQUENCY_WEIGHT * frequency) + (RECENCY_WEIGHT * (1 / (1 + recency))) + (AGE_WEIGHT * age)

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy starts eviction by using the circular pointer to find objects with zero frequency. If none are found, it checks the lowest level cache for least recent access. If still no candidates are found, it moves to higher levels, considering age and priority scores. It then uses the dependency graph to identify objects with the least dependencies and applies a probabilistic approach influenced by the machine learning model to select the final eviction candidate.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    current_time = cache_snapshot.access_count

    # Check for zero frequency items
    for key, item in cache_snapshot.cache.items():
        if metadata.frequency[key] == 0:
            candid_obj_key = key
            break

    # If no zero frequency items, check the LRU queue
    if candid_obj_key is None:
        for key in metadata.lru_queue:
            candid_obj_key = key
            break

    # If still no candidates, look at priority score
    if candid_obj_key is None:
        min_priority = float('inf')
        for key in cache_snapshot.cache:
            priority = metadata.priority[key]
            if priority < min_priority:
                min_priority = priority
                candid_obj_key = key

    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    Upon a cache hit, the policy increases the object's frequency by 1, updates its recency timestamp and access step, recalculates its priority score, and moves it to the most-recently-used end of the LRU queue. It also updates the dependency graph and recalculates the probabilistic eviction score, feeding the new access pattern data into the machine learning model.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    key = obj.key
    current_time = cache_snapshot.access_count

    # Update frequency
    metadata.frequency[key] += 1

    # Update recency timestamp and access step
    metadata.recency[key] = current_time
    metadata.access_step[key] = current_time

    # Recalculate priority score
    age = current_time - metadata.access_step[key]
    metadata.priority[key] = calculate_priority(metadata.frequency[key], metadata.recency[key], age)

    # Move to MRU end of the LRU queue
    if key in metadata.lru_queue:
        metadata.lru_queue.remove(key)
    metadata.lru_queue.appendleft(key)

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the policy sets its frequency to 1, updates its recency timestamp, sets its age to zero, records its access step, calculates its priority score, places it at the current pointer location, and moves it to the most-recently-used end of the LRU queue. It also updates the dependency graph to include the new object and its dependencies, initializes its probabilistic eviction score, and updates the machine learning model with the new object information.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    key = obj.key
    current_time = cache_snapshot.access_count

    # Set frequency to 1
    metadata.frequency[key] = 1

    # Update recency timestamp, set age to zero and record access step
    metadata.recency[key] = current_time
    metadata.access_step[key] = current_time

    # Calculate priority score
    age = 0
    metadata.priority[key] = calculate_priority(metadata.frequency[key], metadata.recency[key], age)

    # Place it at the current pointer location and move to MRU end of the LRU queue
    metadata.lru_queue.appendleft(key)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    Following an eviction, the policy removes the object from the LFU and LRU queues, deletes its records, recalculates the priority scores of remaining objects if necessary, and adjusts the access sequence. It also removes the object from the dependency graph, updates the dependencies of remaining objects, adjusts the access frequency and recency metadata, and retrains the machine learning model with the updated cache state.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    key = evicted_obj.key

    # Remove from LFU and LRU queues
    if key in metadata.lru_queue:
        metadata.lru_queue.remove(key)

    # Delete records
    if key in metadata.frequency:
        del metadata.frequency[key]
    if key in metadata.recency:
        del metadata.recency[key]
    if key in metadata.access_step:
        del metadata.access_step[key]
    if key in metadata.priority:
        del metadata.priority[key]
    if key in metadata.dependency_graph:
        del metadata.dependency_graph[key]

    # Update dependencies of remaining objects
    for dependencies in metadata.dependency_graph.values():
        if key in dependencies:
            dependencies.remove(key)

    # Recalculate priority scores of remaining objects if necessary
    current_time = cache_snapshot.access_count
    for remaining_key in cache_snapshot.cache:
        remaining_obj = cache_snapshot.cache[remaining_key]
        age = current_time - metadata.access_step[remaining_key]
        metadata.priority[remaining_key] = calculate_priority(metadata.frequency[remaining_key], metadata.recency[remaining_key], age)