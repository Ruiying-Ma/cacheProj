# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
from collections import defaultdict, deque

# Put tunable constant parameters below
K = 3  # Number of LRU queues

# Put the metadata specifically maintained by the policy below. The policy maintains k LRU queues, a dynamic priority score for each cached item, a relationship strength score indicating connections to other cached items, and an ordered list of items. Each item also has a timestamp for recency tracking.
lru_queues = [deque() for _ in range(K)]
priority_scores = {}
connection_scores = defaultdict(float)
ordered_items = deque()
timestamps = {}
access_frequencies = defaultdict(int)

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy first considers the lowest priority score for eviction. If there is a tie, it considers the relationship strength score, evicting the item with the weakest connections. If there is still a tie, it evicts the least recently used item among the remaining candidates from the non-empty LRU queue with the smallest subscript.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    min_priority = float('inf')
    candidates = []

    for key in cache_snapshot.cache.keys():
        if priority_scores[key] < min_priority:
            min_priority = priority_scores[key]
            candidates = [key]
        elif priority_scores[key] == min_priority:
            candidates.append(key)

    if len(candidates) > 1:
        min_connection = float('inf')
        temp_candidates = []

        for key in candidates:
            if connection_scores[key] < min_connection:
                min_connection = connection_scores[key]
                temp_candidates = [key]
            elif connection_scores[key] == min_connection:
                temp_candidates.append(key)

        candidates = temp_candidates

    if len(candidates) > 1:
        for i in range(K):
            for key in lru_queues[i]:
                if key in candidates:
                    return key

    if candidates:
        candid_obj_key = candidates[0]

    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after a cache hit.
    Upon a cache hit, the policy increases the access frequency, updates the recency timestamp, adjusts the relationship strength scores based on the accessed item's connections, and moves the item to the front of the ordered list. If the item is in Li, it is moved to the most-recently-used end of Lj where j = min(i+1, k).
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    access_frequencies[obj.key] += 1
    timestamps[obj.key] = cache_snapshot.access_count
    ordered_items.remove(obj.key)
    ordered_items.appendleft(obj.key)

    for i in range(K):
        if obj.key in lru_queues[i]:
            lru_queues[i].remove(obj.key)
            lru_queues[min(i + 1, K - 1)].appendleft(obj.key)
            break

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the policy initializes its priority score, sets its relationship strength score based on initial connections, places it at the front of the ordered list, and puts it at the most-recently-used end of L1. The item's recency is set to the current timestamp.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    priority_scores[obj.key] = len(obj.key) # Example calculation for priority score
    connection_scores[obj.key] = 1.0  # Example initial connection score
    ordered_items.appendleft(obj.key)
    lru_queues[0].appendleft(obj.key)
    timestamps[obj.key] = cache_snapshot.access_count
    access_frequencies[obj.key] = 1

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    After evicting an item, the policy removes its metadata, adjusts the relationship strength scores of remaining items to reflect the removal, updates the ordered list to remove the evicted item, and removes the item from its LRU queue. If the eviction occurs in a higher level, an item from a lower level may be promoted to fill the vacancy.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    del priority_scores[evicted_obj.key]
    del connection_scores[evicted_obj.key]
    del access_frequencies[evicted_obj.key]
    del timestamps[evicted_obj.key]
    ordered_items.remove(evicted_obj.key)

    for i in range(K):
        if evicted_obj.key in lru_queues[i]:
            lru_queues[i].remove(evicted_obj.key)
            break

    for i in range(1, K):
        if lru_queues[i]:
            promoted_obj_key = lru_queues[i].pop()
            lru_queues[i-1].appendleft(promoted_obj_key)
            break