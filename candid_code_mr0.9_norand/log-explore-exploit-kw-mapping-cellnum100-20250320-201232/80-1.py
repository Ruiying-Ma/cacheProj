# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
import time

# Put tunable constant parameters below
FREQUENCY_WEIGHT = 0.4
RECENCY_WEIGHT = 0.2
DEPENDENCY_WEIGHT = 0.1
PREDICTIVE_WEIGHT = 0.2
CONTEXTUAL_WEIGHT = 0.1

# Put the metadata specifically maintained by the policy below. The policy maintains access frequency, last access time, group identifier, dependency counts, predictive scores from a machine learning model, contextual relevance scores, and layer information in a multi-layered cache structure. It also keeps global statistics on hit/miss rates and group access patterns.
metadata = {
    'access_frequency': {},
    'last_access_time': {},
    'group_identifier': {},
    'dependency_counts': {},
    'predictive_scores': {},
    'contextual_relevance_scores': {},
    'layer_information': {},
    'group_access_pattern': {},  # Tracks access patterns for groups
    'global_hit_rate': 0,
    'global_miss_rate': 0
}

def get_composite_score(key):
    frequency = metadata['access_frequency'].get(key, 0)
    recency = metadata['last_access_time'].get(key, 0)
    dependency = metadata['dependency_counts'].get(key, 0)
    predictive = metadata['predictive_scores'].get(key, 0)
    contextual = metadata['contextual_relevance_scores'].get(key, 0)
    return (
        FREQUENCY_WEIGHT * frequency +
        RECENCY_WEIGHT * (time.time() - recency) +
        DEPENDENCY_WEIGHT * dependency +
        PREDICTIVE_WEIGHT * predictive +
        CONTEXTUAL_WEIGHT * contextual
    )

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy chooses the eviction victim by first identifying the least frequently accessed group based on collective access patterns. Within that group, it evaluates a composite score derived from access frequency, recency, dependency counts, predictive score, and contextual relevance. Items in the lowest-priority layer are considered first, and within that layer, the item with the lowest composite score and fewest dependencies is evicted.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    min_access_group = min(metadata['group_access_pattern'], key=metadata['group_access_pattern'].get)
    
    min_layer = float('inf')
    min_score = float('inf')
    
    for key, cached_obj in cache_snapshot.cache.items():
        if metadata['group_identifier'].get(key) == min_access_group:
            layer = metadata['layer_information'].get(key, float('inf'))
            if layer < min_layer:
                min_layer = layer
                min_score = get_composite_score(key)
                candid_obj_key = key
            elif layer == min_layer:
                score = get_composite_score(key)
                if score < min_score:
                    min_score = score
                    candid_obj_key = key
    
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    Upon a cache hit, the policy updates the access frequency, last access time, and dependency counts of the accessed item. It recalculates its predictive score using the machine learning model and adjusts its contextual relevance score based on recent access patterns. The item's layer and group may also be adjusted if its composite score changes significantly. Global hit rate statistics and group access pattern data are updated.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    key = obj.key
    metadata['access_frequency'][key] = metadata['access_frequency'].get(key, 0) + 1
    metadata['last_access_time'][key] = cache_snapshot.access_count
    # Mock calls to machine learning model and estimation
    metadata['predictive_scores'][key] += 1  # A mock increment
    metadata['contextual_relevance_scores'][key] += 1  # A mock increment
    # Update layer and group if necessary
    composite_score = get_composite_score(key)
    metadata['layer_information'][key] = composite_score // 10  # A mock layer calculation
    metadata['group_access_pattern'][metadata['group_identifier'][key]] += 1
    metadata['global_hit_rate'] += 1

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the policy initializes its access frequency, last access time, dependency counts, predictive score, and contextual relevance score. The item is placed in the appropriate layer and group based on its initial composite score and dependency counts. Global miss rate statistics and group access pattern data are updated.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    key = obj.key
    metadata['access_frequency'][key] = 1
    metadata['last_access_time'][key] = cache_snapshot.access_count
    metadata['dependency_counts'][key] = 0  # Assume initial zero dependencies
    metadata['predictive_scores'][key] = 1  # Initial predictive score
    metadata['contextual_relevance_scores'][key] = 1  # Initial contextual relevance
    # Assign to a default group and layer
    metadata['group_identifier'][key] = 'default_group'
    metadata['layer_information'][key] = 1
    metadata['group_access_pattern']['default_group'] = metadata['group_access_pattern'].get('default_group', 0) + 1
    metadata['global_miss_rate'] += 1

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    After evicting an item, the policy updates the group access pattern data to reflect the removal and adjusts the global statistics on hit/miss rates. It recalculates the composite scores and dependency counts of remaining items in the same layer and group to ensure accurate prioritization. Layers and groups of other items may be adjusted if necessary to maintain optimal cache performance.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    key = evicted_obj.key
    group = metadata['group_identifier'].pop(key, None)
    if group:
        metadata['group_access_pattern'][group] -= 1
        if metadata['group_access_pattern'][group] == 0:
            del metadata['group_access_pattern'][group]

    del metadata['access_frequency'][key]
    del metadata['last_access_time'][key]
    del metadata['dependency_counts'][key]
    del metadata['predictive_scores'][key]
    del metadata['contextual_relevance_scores'][key]
    del metadata['layer_information'][key]
    
    # Recalculate composite scores and dependencies for objects in the same layer and group
    layer = metadata['layer_information'].get(group, 1)
    for cache_key in cache_snapshot.cache:
        if metadata['group_identifier'].get(cache_key) == group and metadata['layer_information'].get(cache_key) == layer:
            metadata['predictive_scores'][cache_key] -= 1  # Mock update
            metadata['contextual_relevance_scores'][cache_key] -= 1  # Mock update, dependent on additional dependencies
    
    metadata['global_miss_rate'] += 1