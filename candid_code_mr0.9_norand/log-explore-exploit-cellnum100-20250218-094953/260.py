# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.

# Put tunable constant parameters below
INITIAL_PREDICTIVE_SCORE = 100
LATENCY_OPTIMIZATION_FACTOR = 1.0

# Put the metadata specifically maintained by the policy below. The policy maintains a predictive score for each cache entry based on access patterns, a data retrieval index to track the frequency and recency of accesses, and a latency optimization factor to prioritize entries that reduce overall latency.
metadata = {
    'predictive_scores': {},  # {obj.key: score}
    'data_retrieval_index': {},  # {obj.key: (frequency, recency)}
    'latency_optimization_factor': {}  # {obj.key: factor}
}

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy chooses the eviction victim by selecting the entry with the lowest predictive score, which is calculated using a combination of the data retrieval index and the latency optimization factor. This ensures that the least likely to be accessed and least latency-critical entries are evicted first.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    min_score = float('inf')
    
    for key, cached_obj in cache_snapshot.cache.items():
        score = metadata['predictive_scores'][key]
        if score < min_score:
            min_score = score
            candid_obj_key = key
    
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    Upon a cache hit, the policy updates the data retrieval index to reflect the increased frequency and recency of the accessed entry. The predictive score is recalculated to account for the new access pattern, and the latency optimization factor is adjusted if the access impacts overall latency.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    key = obj.key
    frequency, _ = metadata['data_retrieval_index'].get(key, (0, 0))
    frequency += 1
    recency = cache_snapshot.access_count
    
    metadata['data_retrieval_index'][key] = (frequency, recency)
    metadata['predictive_scores'][key] = calculate_predictive_score(frequency, recency, metadata['latency_optimization_factor'][key])

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the policy initializes the data retrieval index for the new entry, assigns an initial predictive score based on heuristic analysis of similar entries, and sets a baseline latency optimization factor. The scores of other entries may be adjusted to reflect the new cache composition.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    key = obj.key
    metadata['data_retrieval_index'][key] = (0, cache_snapshot.access_count)
    metadata['latency_optimization_factor'][key] = LATENCY_OPTIMIZATION_FACTOR
    metadata['predictive_scores'][key] = INITIAL_PREDICTIVE_SCORE

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    Following an eviction, the policy removes the metadata associated with the evicted entry. It then recalculates the predictive scores and latency optimization factors for the remaining entries to ensure the cache remains optimized for future accesses.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    evicted_key = evicted_obj.key
    if evicted_key in metadata['predictive_scores']:
        del metadata['predictive_scores'][evicted_key]
    if evicted_key in metadata['data_retrieval_index']:
        del metadata['data_retrieval_index'][evicted_key]
    if evicted_key in metadata['latency_optimization_factor']:
        del metadata['latency_optimization_factor'][evicted_key]
    
    for key in cache_snapshot.cache:
        frequency, recency = metadata['data_retrieval_index'][key]
        metadata['predictive_scores'][key] = calculate_predictive_score(frequency, recency, metadata['latency_optimization_factor'][key])

def calculate_predictive_score(frequency, recency, latency_factor):
    '''
    Helper function to calculate the predictive score based on frequency, recency, and latency factor.
    '''
    return (frequency + 1) / (recency + 1) * latency_factor