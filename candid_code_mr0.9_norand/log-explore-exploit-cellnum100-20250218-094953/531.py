# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
import time

# Put tunable constant parameters below
DEFAULT_PRIORITY_SCORE = 1.0

# Put the metadata specifically maintained by the policy below. The policy maintains access frequency, recency of access, predicted future access patterns, system load metrics, last access timestamp, predicted future access time, and a priority score for each cache entry.
metadata = {
    'access_frequency': {},
    'recency_timestamp': {},
    'last_access_timestamp': {},
    'predicted_future_access_time': {},
    'priority_score': {},
    'system_load_impact': {}
}

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy chooses the eviction victim by calculating a composite score based on low access frequency, long recency of access, distant predicted future access time, high system load impact, and low priority score. The entry with the lowest composite score is evicted.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    min_composite_score = float('inf')
    
    for key, cached_obj in cache_snapshot.cache.items():
        access_frequency = metadata['access_frequency'].get(key, 0)
        recency_timestamp = metadata['recency_timestamp'].get(key, 0)
        predicted_future_access_time = metadata['predicted_future_access_time'].get(key, float('inf'))
        priority_score = metadata['priority_score'].get(key, DEFAULT_PRIORITY_SCORE)
        system_load_impact = metadata['system_load_impact'].get(key, 0)
        
        composite_score = (1 / (access_frequency + 1)) + (cache_snapshot.access_count - recency_timestamp) + predicted_future_access_time + system_load_impact - priority_score
        
        if composite_score < min_composite_score:
            min_composite_score = composite_score
            candid_obj_key = key
    
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    After a cache hit, the policy increments the access frequency, refreshes the recency timestamp and last access timestamp to the current time, updates the predicted future access pattern and predicted future access time using the latest access data, recalculates the priority score, and adjusts the system load metrics.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    key = obj.key
    current_time = cache_snapshot.access_count
    
    metadata['access_frequency'][key] = metadata['access_frequency'].get(key, 0) + 1
    metadata['recency_timestamp'][key] = current_time
    metadata['last_access_timestamp'][key] = current_time
    metadata['predicted_future_access_time'][key] = current_time + 100  # Example prediction model
    metadata['priority_score'][key] = DEFAULT_PRIORITY_SCORE  # Example recalculation
    metadata['system_load_impact'][key] = obj.size  # Example adjustment

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the policy initializes the access frequency to 1, sets the recency timestamp and last access timestamp to the current time, runs a prediction model to estimate future access patterns and predicted future access time, assigns a default priority score, and updates the system load metrics.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    key = obj.key
    current_time = cache_snapshot.access_count
    
    metadata['access_frequency'][key] = 1
    metadata['recency_timestamp'][key] = current_time
    metadata['last_access_timestamp'][key] = current_time
    metadata['predicted_future_access_time'][key] = current_time + 100  # Example prediction model
    metadata['priority_score'][key] = DEFAULT_PRIORITY_SCORE
    metadata['system_load_impact'][key] = obj.size  # Example adjustment

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    After evicting a victim, the policy recalculates the system load metrics, adjusts the predictive model to account for the removal of the evicted object, and recalibrates the priority scores and predicted future access times of remaining entries.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    evicted_key = evicted_obj.key
    
    # Remove metadata of evicted object
    if evicted_key in metadata['access_frequency']:
        del metadata['access_frequency'][evicted_key]
    if evicted_key in metadata['recency_timestamp']:
        del metadata['recency_timestamp'][evicted_key]
    if evicted_key in metadata['last_access_timestamp']:
        del metadata['last_access_timestamp'][evicted_key]
    if evicted_key in metadata['predicted_future_access_time']:
        del metadata['predicted_future_access_time'][evicted_key]
    if evicted_key in metadata['priority_score']:
        del metadata['priority_score'][evicted_key]
    if evicted_key in metadata['system_load_impact']:
        del metadata['system_load_impact'][evicted_key]
    
    # Recalculate system load metrics and adjust predictive model
    total_size = sum(obj.size for obj in cache_snapshot.cache.values())
    for key in cache_snapshot.cache:
        metadata['system_load_impact'][key] = cache_snapshot.cache[key].size / total_size  # Example recalculation
        metadata['predicted_future_access_time'][key] = cache_snapshot.access_count + 100  # Example recalibration
        metadata['priority_score'][key] = DEFAULT_PRIORITY_SCORE  # Example recalibration