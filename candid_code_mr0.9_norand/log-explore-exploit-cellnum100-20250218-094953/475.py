# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.
from collections import deque, defaultdict

# Put tunable constant parameters below
SQ_CAPACITY = 100  # Example capacity for SQ
MQ_CAPACITY = 100  # Example capacity for MQ

# Put the metadata specifically maintained by the policy below. The policy maintains an LFU queue with recency as the tie breaker, a FIFO queue called SQ, a FIFO queue called MQ, a ghost FIFO queue called GQ, a resource allocation matrix, a data synchronization point, a predictive redundancy check, and an adaptive load balancing metric.
LFU_queue = defaultdict(lambda: (0, 0))  # key -> (frequency, recency)
SQ = deque()
MQ = deque()
GQ = deque()
resource_allocation_matrix = {}
data_synchronization_point = 0
predictive_redundancy_check = {}
adaptive_load_balancing_metric = {}

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy chooses the eviction victim by first checking if SQ exceeds its capacity and moving objects to MQ if necessary. If MQ is full, it cyclically reduces the frequency of objects in MQ until an object with zero frequency is found and evicts it. If SQ is not full, it evicts the least-frequently-used and least-recently-used object from the LFU queue. The final eviction decision is influenced by the lowest combined score from the resource allocation matrix and predictive redundancy check.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    # Your code below
    if len(SQ) > SQ_CAPACITY:
        while len(SQ) > SQ_CAPACITY:
            moved_obj = SQ.popleft()
            MQ.append(moved_obj)
    
    if len(MQ) > MQ_CAPACITY:
        while len(MQ) > MQ_CAPACITY:
            for mq_obj in MQ:
                LFU_queue[mq_obj.key] = (LFU_queue[mq_obj.key][0] - 1, LFU_queue[mq_obj.key][1])
                if LFU_queue[mq_obj.key][0] == 0:
                    MQ.remove(mq_obj)
                    candid_obj_key = mq_obj.key
                    break
            if candid_obj_key:
                break
    
    if not candid_obj_key:
        lfu_key = min(LFU_queue, key=lambda k: (LFU_queue[k][0], LFU_queue[k][1]))
        candid_obj_key = lfu_key
    
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    After a cache hit, the policy increases the hit object's frequency by 1, sets its recency as the current timestamp, and adjusts its place in the LFU queue if necessary. It updates the resource allocation matrix to reflect current resource usage, adjusts the data synchronization point, recalculates the predictive redundancy check, and updates the adaptive load balancing metric.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    # Your code below
    LFU_queue[obj.key] = (LFU_queue[obj.key][0] + 1, cache_snapshot.access_count)
    resource_allocation_matrix[obj.key] = obj.size
    data_synchronization_point = cache_snapshot.access_count
    predictive_redundancy_check[obj.key] = obj.size
    adaptive_load_balancing_metric[obj.key] = obj.size

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    After inserting a new object, the policy sets the object's frequency as 1, sets its recency as the current timestamp, and places it in the appropriate queues (SQ or MQ). It updates the resource allocation matrix to include the new resource usage, sets a new data synchronization point, performs a predictive redundancy check, and adjusts the adaptive load balancing metric.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    # Your code below
    LFU_queue[obj.key] = (1, cache_snapshot.access_count)
    if len(SQ) < SQ_CAPACITY:
        SQ.append(obj)
    else:
        MQ.append(obj)
    
    resource_allocation_matrix[obj.key] = obj.size
    data_synchronization_point = cache_snapshot.access_count
    predictive_redundancy_check[obj.key] = obj.size
    adaptive_load_balancing_metric[obj.key] = obj.size

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    After evicting a victim, the policy removes the object from the LFU queue and places it at the rear of GQ. It updates the resource allocation matrix, adjusts the data synchronization point, recalculates the predictive redundancy check, and updates the adaptive load balancing metric to reflect the new cache state.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    # Your code below
    if evicted_obj.key in LFU_queue:
        del LFU_queue[evicted_obj.key]
    GQ.append(evicted_obj)
    
    if evicted_obj.key in resource_allocation_matrix:
        del resource_allocation_matrix[evicted_obj.key]
    data_synchronization_point = cache_snapshot.access_count
    if evicted_obj.key in predictive_redundancy_check:
        del predictive_redundancy_check[evicted_obj.key]
    if evicted_obj.key in adaptive_load_balancing_metric:
        del adaptive_load_balancing_metric[evicted_obj.key]