# Import anything you need below. You must not use any randomness. For example, you cannot `import random`. Also, you cannot use any function in `numpy` that uses randomness, such as the functions in `numpy.random`.

# Put tunable constant parameters below
LAST_ACCESSED_WEIGHT = 1.0
PREDICTED_FUTURE_ACCESS_WEIGHT = 1.0

# Put the metadata specifically maintained by the policy below. The policy maintains three pieces of metadata for each object: a 'use count', a 'last accessed timestamp', and a 'predicted future access timestamp' generated by an access pattern predictor.
metadata = {}

def access_pattern_predictor(obj, current_time):
    # Dummy predictor for demonstration purposes
    return current_time + 100

def evict(cache_snapshot, obj):
    '''
    This function defines how the policy chooses the eviction victim.
    The policy chooses to evict the object with the lowest combined score, calculated as: (use count + last accessed timestamp weight - predicted future access timestamp weight). Weights adjust dynamically based on recent prediction accuracy.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    lowest_score = float('inf')
    
    for key, cached_obj in cache_snapshot.cache.items():
        use_count = metadata[key]['use_count']
        last_accessed = metadata[key]['last_accessed']
        predicted_future_access = metadata[key]['predicted_future_access']
        
        score = use_count + LAST_ACCESSED_WEIGHT * last_accessed - PREDICTED_FUTURE_ACCESS_WEIGHT * predicted_future_access
        
        if score < lowest_score:
            lowest_score = score
            candid_obj_key = key
    
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the policy update the metadata it maintains immediately after a cache hit.
    Upon a hit, the 'use count' is incremented, the 'last accessed timestamp' is updated to the current time, and the predicted future access timestamp is recalculated using the access pattern predictor.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    key = obj.key
    metadata[key]['use_count'] += 1
    metadata[key]['last_accessed'] = cache_snapshot.access_count
    metadata[key]['predicted_future_access'] = access_pattern_predictor(obj, cache_snapshot.access_count)

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after inserting a new object into the cache.
    Upon insertion of a new object, initialize the 'use count' to 1, set the 'last accessed timestamp' to the current time, and generate a 'predicted future access timestamp' using the access pattern predictor.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    key = obj.key
    metadata[key] = {
        'use_count': 1,
        'last_accessed': cache_snapshot.access_count,
        'predicted_future_access': access_pattern_predictor(obj, cache_snapshot.access_count)
    }

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the policy updates the metadata it maintains immediately after evicting the victim.
    After eviction, the policy re-calibrates the weights for 'last accessed timestamp' and 'predicted future access timestamp' based on the accuracy of recent predictions and normalizes the 'use count' for all remaining objects.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    # Re-calibrate weights based on prediction accuracy
    # For simplicity, we assume a dummy recalibration process
    global LAST_ACCESSED_WEIGHT, PREDICTED_FUTURE_ACCESS_WEIGHT
    LAST_ACCESSED_WEIGHT *= 0.99
    PREDICTED_FUTURE_ACCESS_WEIGHT *= 1.01
    
    # Normalize use count for all remaining objects
    total_use_count = sum(metadata[key]['use_count'] for key in cache_snapshot.cache)
    if total_use_count > 0:
        for key in cache_snapshot.cache:
            metadata[key]['use_count'] /= total_use_count